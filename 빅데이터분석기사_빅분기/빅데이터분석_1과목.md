# 빅데이터 개요 및 활용
# 데이터의 이해
가. ==데이터의 정의 ==
데이터(data)라는 용어는 1646년 영국 문헌에 처음 등장하였으며 라틴어인 dare(주다)의 과거 분사형으로 '주어진 것'이라 의미로 사용  
1940년대 이후 컴퓨터 시대 시작과 함께 자연과학뿐만 아니라 경영학, 통계학 등 다양한 사회과학이 진일보하면서 데이터의 의미는 과거의 관념적이고 추상적인 개념에서 기술적이고 사실적인 의미로 변화됨  
데이터는 추론과 추정의 근거를 이루는 사실(옥스퍼드 대사전)  
데이터는 단순한 객체로서의 가치뿐만 아니라 다른 객체와의 상호관계속에서 가치를 갖는 것

나. ==데이터의 특성==

| 구분         | 특성                           |
| ---------- | ---------------------------- |
| **존재적** 특성 | 객관적 사실(fact, raw meterial)   |
| **당위적** 특성 | 추론, 예측, 전망, 추정을 위한 근거(basis) |
예시 ) 데이터
- 설문조사, 실험, 검사, 측정 등을 통해 데이터를 수집, 축척하고 다양한 방법으로 분석하여 간단한 마케팅 리포트부터 심도있는 논문, 미래 예측을 위한 경영전략 또는 정책을 수립하는 일련의 가치 창출과정에서 가장 기초를 이루는 것

다. ==데이터의 유형==

| 구분                             | 형태                             | ex          | 특징                                |
| ------------------------------ | ------------------------------ | ----------- | --------------------------------- |
| **정성적** 데이터(qualitative data)  | 언어, 문자 등 비정형 데이터 / **주관적** 내용  | 회사 매출 증가    | 저장, 검색, 분석에 많은 비용이 소모 됨/통계분석이 어려움 |
| **정량적** 데이터(quantitative data) | 수치, 도형, 기호 등 정형 데이터/**객관적** 내용 | 나이, 몸무게, 주가 | 정형화된 데이터로 비용 소모가 적음/통계분석이 용이함     |
라. ==지식경영의 핵심 이슈==
- **지식경영**(Knowledge Management)은 기업의 생존과 경쟁력 확보가 인적자원의 지식에 달려있다고 보고(피터 드러커) 기업이 구성원 개개인이 가진 지식의 공유를 통해 기업의 문제해결능력을 향상시키려는 경영 방식이다.
- 데이터는 지식경영의 핵심이슈인 암묵지(tacit knowledge)와 형식지(explicit knowledge)의 상호작용에 있어 중요한 역할을 한다.

| 구분       | 형태                                | ex          | 특징                    | 상호작용         |
| -------- | --------------------------------- | ----------- | --------------------- | ------------ |
| /**암묵지** | 학습, 경험을 통해 체화되 있지만 겉으로 드러나지 않는 지식 | 김장,<br>자전거  | 사회적으로 중요하지만  공유되기 어려움 | **공통화, 내면화** |
| /**형식지** | 문서, 매뉴얼처럼 형상화된 지식                 | 교과서, 비디오,DB | 전달, 공유가 용이            | **표출화, 연결화** |
참고 : 암묵지와 형식지의 상호작용 
- 암묵지 > 개인에게 축적된 내면화(internalization)된 지식 -> 조직의 지식으로 공통화(socialization)
- 형식지 : 언어, 기호, 숫자로 표출화(externalization)된 지식 -> 개인의 지식으로 연결화(combination)

마. 데이터와 정보의 관계
1) DIKW의 정의  
*DIKW의 정의를 명확히 이해, 각 개념들을 구분할 수 있도록 하기. 각 개념에 대한 예시 함께 이해*

| 구분                  | 내용                                                                            |
| ------------------- | ----------------------------------------------------------------------------- |
| ==데이터==(Data)       | 개별 데이터 자체로는 **의미가 중요하지 않은** 객관적인 사실                                           |
| ==정보==(Information) | 데이터의 가공, 처리와 데이터 간 연관관계 속에서 **의미가 도출**된 것                                     |
| ==지식==(Knowledge)   | 데이터를 통해 도출된 다양한 정보를 구조화하여 유의미한 정보를 분류하고 <br>개인적인 경험을 결합시켜 고유의 지식으로 **내재화**된 것 |
| ==지혜==(Wisdom)      | 지식의 축적과 아이디어가 결합된 **창의**적인 산물                                                 |
2) DIKW 피라미드
- DIKW 피라미드에서는 데이터, 정보, 지식을 통해 최종적으로 지혜를 얻어내는 과정을 계층구조로 설명하고 있다.
![DIKW 피라미드](https://itwiki.kr/images/e/e4/DIKW_%ED%94%BC%EB%9D%BC%EB%AF%B8%EB%93%9C.png)

- **지혜(Wisdom)** : 근본 원리에 대한 깊은 이해를 바탕으로 도출되는 ==창의적== 아이디어  
               ex) A마트의 다른 상품들도 B마트보다 쌀 것이라고 판단한다  
               
- **지식(Knowledge)** : 상호 연결된 정보 패턴을 이해하여 이를 토대로 ==예측한 결과==물  
               ex) 상대적으로 저렴한 A마트에서 연필을 사야겠다  
               
- **정보(Information)** : 데이터 가공, 상관관계간 이해로 패턴을 인식하고 그 ==의미를 부여==한 데이터  
               ex) A마트의 연필이 더 싸다  
               
- **데이터(Data)** : 존재형식 불문, 타 데이터와 상관관계가 없는 ==가공하기 전==의 순수한 수치나 기호
               ex) A마트는 100원에, B마트는 200원에 연필을 판매한다  

# 데이터베이스의 이해
가. 데이터베이스 정의

|                                 | 출처                      | 내용                                                                                                         |
| ------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------------------- |
| 1차 개념 확대 / 정형데이터 관리             | EU <데이터베이스의 법적보호에 관한 지침 | 체계적이거나 조직적으로 정리되고 전자식 또는 기타 수단으로 개별적으로 접근할 수 있는 독립된 저작물, 데이터 또는 기타 소재의 수집물                                 |
|                                 | 국내저작권법                  | 소재를 체계적으로 배열 또는 구성한 편집물로서 개별적으로 그 소재에 접근하거나 그 소재를 검색할 수 있도록 한 것                                            |
| 2차 개념 확대 / 빅데이터의 출현으로 비정형데이터 포함 | 국내컴퓨터용어사전               | 동시에 복수의 적용 업무를 지원할 수 있도록 복수 이용자의 요구에 대응해서 데이터를 받아들이고 저장, 공급하기 위하여 일정한 구조에 따라서 편성된 데이터의 집합                  |
|                                 | 국내 Wikipedia            | 관련된 레코드의 집합, 소프트웨어로는 데이터베이스관리시스템(DBMS)을 의미                                                                 |
|                                 | 국내 데이터분석 전문가 가이드        | 문자, 기호, 음성, 화상, 영상 등 상호 관련된 다수의 콘텐츠를 정보 처리 및 정보통신 기기에 의하여 체계적으로 수집/축척하여 다양한 용도와 방법으로 이용할 수 있도록 정리한 정보의 집합체 |
나. 데이터베이스의 특징
1) 일반적인 특징


| 데이터베이스     특징            | 설명                                                                                                                 |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------ |
| 통합된 데이터(integrated data) | 동일한 내용의 데이터가 중복되어 있지 않다는 것을 의미 / 데이터 중복은 관리상의 복잡한 부작용을 초래                                                          |
| 저장된 데이터(stored data)     | 자기 디스크나 자기 테이프 등과 같이 컴퓨터가 접근할 수 있는 저장 매체에 저장되는 것을 의미. 데이터베이스는 기본적으로 컴퓨터 기술을 바탕으로 한 것                               |
| 공용 데이터(shared data)      | 여러 사용자가 서로 다른 목적으로 데이터를 공동으로 이용한다는 것을 의미. 대용량화되고 구조가 복잡한 것이 보통                                                     |
| 변화되는 데이터(changed data)   | 데이터베이스에 저장된 내용은 곧 데이터베이스의 현 시점에서의 상태를 나타냄. 다만 이 상태는 새로운 데이터의 삽입, 기존 데이터의 삭제, 갱신으로 항상 변화하면서도 항상 현재의 정확한 데이터를 유지해야 함 |

2) 다양한 측면에서의 특징      *데이터베이스의 특징은 꼭 기억하기. 일반적인 특징 외에도 다양한 측면에서의 특징도 출체 가능성 높음*
> 정보의 축적 및 전달 측면
- 기계가독성 : 일정한 형식에 따라 컴퓨터 등의 정보처리기기가 읽고 쓸 수 있음.
- 검색가독성 : 다양한 방법으로 필요한 정보를 검색
- 원격조작성 : 정보통신망을 통하여 원거리에서도 즉시 온라인을 이용
> 정보 이용 측면
- 이용자의 정보 요구에 따라 다양한 정보를 신속하게 획득
- 원하는 정보를 정확하고 경제적으로 찾아낼 수 있다는 특성
> 정보 관리 측면
- 정보를 일정한 질서와 구조에 따라 정리, 저장, 검색, 관리할 수 있도록 하여 방대한 양의 정보를 체계적으로 축척하고 새로운 내용의 추가나 갱신이 용이
> 정보기술 발전 측면
- 데이터 베이스는 정보처리, 검색/관리 소프트웨어, 관련 하드웨어, 정보 전송을 위한 네트워크기술의 발전을 견인할 수 있음.
> 경제/산업 측면
- 다양한 정보를 필요에 따라 신속하게 제공/이용할 수 있는 인프라 라는 특성을 가지고 있어 경제, 산업, 사회 활동의 효율성을 제고하고 국민의 편의를 증진하는 수단으로서 의미를 가짐

다. 경영에서의 데이터베이스 활용
- 정보통신망 구축이 가속화되면서 1990년대의 기업내부 데이터베이스는 기업 경영 전반에 관한 인사, 조직, 생산, 영업 활동 등을 포함한 모든 자료를 연계하여 일관된 체계로 구축, 운영하는 경영 활동의 기반이 되는 전사 시스템으로 확대되었다.

1) 1980년대 기업내부 데이터베이스
- OLTP(On-Line Transaction Processing) :  호스트 컴퓨터와 온라인으로 접속된 여러 단말간의 처리 형태의 하나. 여러 단말에서 보내온 메시지에 따라 호스트 컴퓨터가 데이터베이스를 액세스하고, 바로 처리 결과를 돌려보내는 형태. 즉, 데이터베이스의 데이터를 수시로 갱신하는 프로세싱을 의미. 주문입력시스템, 재고관리시스템 등 현업의 거의 모든 업무는 이와 같은 성격을 띄고 있음
- OLAP(On-Line analytical Processing) : 정보 위주의 분석 처리를 의미하며, 다양한 비즈니스 관점에서 쉽고 빠르게 다차원적인 데이터에 접근하여 의사 결정에 활용할 수 있는 정보를 얻을 수 있게 해주는 기술. OLTP에서 처리된 트랜잭션 데이터를 분석해 제품의 판매 추이, 구매성향파악, 재무 회계 분석 등을 프로세싱 하는 것을 의미한다. OLTP가 데이터 갱신 위주라면, OLAP는 데이터 조회 위주라고 할 수 있다.

* OLTP와 OLAP 비교

| 구분         | OLTP        | OLAP            |
| ---------- | ----------- | --------------- |
| 데이터 구조     | 복잡          | 단순              |
| 데이터 갱신     | 동적으로 순간적    | 정적으로 주기적        |
| 응답 시간      | 수 초 이내      | 수 초에서 몇 분 사이    |
| 데이터 범위     | 수 십일 전후     | 오랜 기간 저장        |
| 데이터 성격     | 정규적인 핵심 데이터 | 비정규적인 읽기 전용 데이터 |
| 데이터 크기     | 수 기가 바이트    | 수 테라 바이트        |
| 데이터 내용     | 현재 데이터      | 요약된 데이터         |
| 데이터 특성     | 트랜잭션 중심     | 주제 중심           |
| 데이터 엑세스 빈도 | 높음          | 보통              |
| 질의 결과 예측   | 주기적이며 예측 가능 | 예측하기 어려움        |
2) 2000년대 기업내부 데이터베이스
가) CRM(Customer Relationship Management)
- '고객관계관리', 기업이 고객과 관련된 내/외부 자료를 분석/통합해 고객 중심 자원을 극대화하고, 이를 토대로 고객 특성에 맞게 마케팅 활동을 계획/지원/평가하는 과정
- CRM은 최근에 등장한 데이터베이스 마케팅의 일대일 마케팅, 관계마케팅에서 진화한 요소들을 기반으로 등장. 고객데이터의 세분화를 실시하여 신규고객 획득, 우수고객 유지, 고객가치증진, 잠재고객 활성화, 평생고객화 같은 사이클을 통하여 고객을 적극적으로 관리하고 유도

나) SCM(Supply Chain Management)
- '공급망 관리', 기업에서 원재료의 생산/유통 등 모든 공급망 단계를 최적화해 수요자가 원하는 제품을 원하는 시간과 장소에 제공하는 것.
- SCM은 부품 공급업체와 생산업체, 고객에 이르기까지 거래관계에 있는 기업들간 IT를 이용한 실시간 정보공유를 통해 시장과 사요자들의 요구에 기민하게 대응토록 지원하는 것.

세계적으로 선도적 위치에 있는 제조업체, 물류업체, 유통업체들은 SCM을 통해 거래선들과 긴밀하게 협력함으로써 그 이익을 훨씬 더 극대화하고 있다.

| 부문   | 내용                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| ---- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 제조부문 | ERP(Enterprise Resource Planning) : 인사/재무/생산 등 기업의 전 부문에 걸쳐 독립적으로 운영되던 각종 관리 시스템의 경영자원을 하나의 통합 시스템으로 재구축함으로써 생산성을 극대화하려는 경영혁신기업을 의미. ERP를 제대로 활용하기 위해서는 통합된 DB의 활용이 필수적이다 <br>BI(Business Intelligence) : 기업이 보유하고 있는 수많은 데이터를 정리하고 분석해 기업의 의사결정에 활용하는 일련의 프로세스  <br>CRM(Customer Relationship Management) : 고객관계관리. 기업이 고객과 관련된 내외부 자료를 분석/통합해 고객 중심자원을 극대화하고 이를 토대로 고객특성에 맞게 마케팅 활동을 계획/지원/평가하는 과정  <br>TE(Real-Time Enterprise) : 회사의 주요 경영정보를 통합관리하는 실시간 기업의 새로운 기업경영시스템. 전사적 자원관리, 공급망관리, 고객관계관리 등 부문별 전산화에서 한발 나아가 회사 전 부문의 정보를 하나로 통합함으로써 경영자의 빠른 의사결정을 이끌어 내려는 목적에서 만들어졌으며 기업활동이 글로벌화되고 기술의 발전으로 제품수명이 짧아지는 현실에 대응되고 있다. |
| 금융부문 | EAI(Enterprise Application Integration) : 기업 내 상호 연관된 모든 애플리케이션을 유기적으로 연동하여 필요한 정보를 중앙집중적으로 통합, 관리, 사용할 수 있는 환경을 구현하는 것으로 e-비즈니스를 위한 기본 인프라 <br>ESB(Enterprise Service Bus): 업무 시스템들 간 연계 과정에서 데이터를 전송할 수 있는 전문양식을 미들웨어 기술과 어댑터, 채널 기술이 결합된 애플리케이션 연계 솔루션 EDW(Enterprise Data Warehouse) : 기존 DW(Data Warehouse)를 전사적으로 확장한 모델로 BPR 과 CRM, BSC 같은 다양한 분석 애플리케이션들을 위한 원천이 된다. 따라서 EDW를 구축하는 것은 단순히 정보를 빠르게 전달하는 대형 시스템을 도입한다는 의미가 아니라 기업 리소스의 유기적 통합, 다원화된 관리 체계정비, 데이터의 중복 방지 등을 위해 시스템을 재설계하는 것을 나타낸다.                                                                                                                          |
| 유통부문 | KMS(Knowledge Managemwnt System) : 지식관리시스템. 기업의 환경이 물품을 주로 생산하던 산업사회에서 지적 재산의 중요성이 커지는 지식사회로 급격히 이동함에 따라, 기업 경영을 지식이라는 관점에서 새롭게 조명하는 접근 방식. <br> RELD(RF, Radio Frequency): 주파수를 이용해 ID를 식별하는 system으로 일명 전자 태그롤 불린다. 전파를 이용해 먼 거리에서 정보를 인식하는 기술로 적용 대상에 REID칩을 부착한 후 리더기를 통해 정보를 인식한다                                                                                                                                                                                                                                                                                                                                           |
라. 사회기반구조로서의 데이터베이스
 1) 개념
  - 1990년대 사회 각 부문의 정보화가 본격화되면서 데이터베이스 구축이 활발하게 추진되었다. 정부를 중심으로 무역, 통관, 물류, 조세, 국세, 조달 등 사회간접자본(SOC) 차원에서 EDI를 활용하여 부가가치통신망(VAN)을 통해 정보망이 구축되기 시작하였다.
  2) 종류
  - EDI(Electronic Data Interchange) : 주문서, 납품서, 청구서 등 무역에 필요한 가종 서류를 표준화된 양식을 통해 전자적 신호로 바꿔 컴퓨터통신망을 이용해 거래처에 전송하는 시스템
  - VAN(Value Added Nrtwork) : 부가가치통신망, 공중 전기통신사업자(ex. 한국전기통신공사)로부터 통신회선을 차용하여 독자적인 네트워크를 형성하는 것. 독자적인 네트워크로 각종 정보를 부호, 영상, 음성 등으로 교환하거나 정보를 축척하거나 또는 복수로 해서 전송하는 등 단순한 통신이 아니라 부가가치가 높은 서비스를 하는 것.
  - CALS(Commerce At Light Speed) : 전자상거래 구축을 위해 기업 내에서 비용 절감과 생산성 향상을 추구할 목적으로 시작된, 제품의 설계/개발/생산에서 유통/폐기에 이르기까지 제품의 라이프 사이클 전반에 관련된 데이터를 통합하고 공유/교환할 수 있도록 한 경영 통합 정보시스템.1980년대 초, 미 국방성의 제품의 전 생산/유통 과정에서 컴퓨터를 활용한 자동화시스템을 구축해 효육적인 군수 조달을 위해 개발된 시스템이다.

3) 분야별 사회기반 구조의 데이터베이스

| 부문      | 솔루션                              |
| ------- | -------------------------------- |
| 물류부문    | CVO / PORT-MIS / KROIS           |
| 지리/교통부문 | GIS / RS / GPS / ITS / LBS / SIM |
| 의료부문    | PACS / U헬스                       |
| 교육부문    | NEIS                             |
가. 빅데이터 정의 
- 빅데이터는 IBM이 최초로 정의하길 "통상적으로 사용되는 데이터 수집, 관리 및 처리 소프트웨어의 수용 한계를 넘어서는 크기의 데이터"라고 함으로써 초기에는 데이터 크기에 집중하여 정의함
- but, 최근에는 '대용량의 자료' 의미 뿐만 아니라 다양한 원천으로부터 '다양한 형태의 데이터를 목적에 맞게 분석함으로써 해당 분야의 필요 지식을 추출하여 전략적 의사결정에 활용하거나 문제해결에 이용하는 제반행위'를 일컬음으로써 보다 공범위한 개념을 담고 있다.

나. 데이터 양 측정을 위한 바이트 크기

![데이터 크기](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcjSisd%2FbtqDn0vQTtI%2FNATVgcfDJg4yvEHZw5g8X1%2Fimg.jpg)

다. 빅데이터의 주요 특징 // *출제빈도 높음*
> 3V
- Volume : 빅데이터의 가장 기본적인 특징. 저장되는 물리적 데이터의 양이 매우 많음을 의미 // 데이터의 규모 측면
            // Peta Byte 수준의 방대한 양 // 웹사이트, 애플리케이션 접속 정보. 기업활동의 각종 로그
            
- Variety : 틀에 짜인 듯 형식이 정해져있는 정형 데이터 뿐만 아니라 사진/오디오/영상/SNS/위치/문서 등과 같이 구조와 형태를 정할 수 없거나 또는 짜여진 틀에 넣기 어려운 비정형 데이터도 포함됨 // 데이터의 유형과 소스 측면
            // 정형, 비정형, 반정형 데이터 // 소셜 미디어 데이터, 로그파일, 클릭 스트림 데이터, 콜센터, 로그, 통신 CDR 로그, 센서 데이터
            
- Velocity : 데이터가 새로 생성되는 속도가 매우 빠르며,연속적으로 생성되는 센서 데이터들이 실시간으로 전송되어 이를 처리하고 저장하거나 분석하는 속도 또한 매우 빠르게 이루어진다. // 데이터 수집과 처리 측면
            // 실시간 생산 및 신속한 분석 유통 // 대용량 데이터 처리, 분산 처리 기술, 클라우드 컴퓨팅
> + 4V
- Value : 빅데이터를 통해 비즈니스에서 실현될 궁극적인 가치를 중점적으로 분석 
            
- Veracity : 의사결정에 이용할 시 활용 배경을 고려함으로써 신뢰성을 제고 
- Validity : 데이터가 타당한지, 정확한지 여부를 결정해야 하며, 정확성이 없으면 데이터는 규모가 크더라도 쓸모없어짐 
- Volatility : 데이터가 얼마나 오래 저장될 수 있고 타당하여 오랫동안 쓰일 수 있는지를 판단

라. 빅데이터 정의의 범주 및 효과
- 1. 3V로 요약되는 데이터 자체의 특성 변화에 초점을 맞춘 협의의 정의
- 2. 데이터 자체뿐 아니라 데이터 처리 및 분석 기술의 변화를 포함하는 정의
- 3. 빅데이터를 위한 인재 및 조직 변화까지 포함하는 광의의 정의
 
데이터 변화---------|------------기술 변화------------------|------------인재, 조직 변화 ----------  
(규모, 형태, 속도)--->----(데이터 처리, 저장, 
					분석 기술 및 아키텍쳐---------->-(Data Scientist 같은 새로운 인재 필요)  
----------------------|----클라우드 컴퓨팅 활용)------------|------(데이터 중심 조직)----------------
                            
            * 기존의 방식으로는 얻을 수 없는 통찰 및 가치 창출
            * 사업방식, 시장, 사회, 정부 등에서 변화와 혁신 주도

마. 빅데이터 분석과 전통적 데이터 분석의 차이
1) 데이터의 확장
- 조직 내부 데이터베이스 분석 중심 -> 웹 및 SNS 등의 외부 데이터를 활용한 분석
- ex. 과거 자사 매출 분석만 시향 > 요즘은 SNS상의 외부 데이터까지 분석해 자사 제품에 대한 소비자의 인식 확인 가능
2) 데이터의 다양화
- 정형 데이터 분석 중심 -> 사진, 영상, 텍스트 등의 비정형 테이터를 활용한 분석
- 블로그, 댓글, 게시판, SNS 등에서의 텍스트 분석 수요가 늘고 있음
3) 데이터의 대규모화
- 분석 대상 데이터 규모 확대

바. 빅데이터의 출현 배경
1) 3가지 차원에서의 변화
- 빅데이터 현상은 없었던 것이 새로 등장한 것이 아니라 기존의 데이터와 처리방식, 다루는 사람과 조직 차원에서 일어나는 '변화'를 말함

| 출현     배경 | 내용                                                                  |
| --------- | ------------------------------------------------------------------- |
| 산업계       | 고객 데이터 축적, 고객 데이터를 축적하여 보유함으로써 데이터에 숨어있는 가치를 발굴해 새로운 성장동력원으로 기술 확보  |
| 학계        | 거대 데이터 활용, 과학 확산, 거대 데이터를 다루는 학문 분야가 늘어나면서 필요한 기술 아키텍처 및 통계 도구들이 발전 |
| 기술발전      | 관련 기술의 발달, 디지털화, 저장 기술의 발달, 인터넷 보급, 모바일 혁명, 클라우드 컴퓨팅                |

2) ICT 발전과 동반
- 빅데이터는 정보통신기술의 발전과 더불에 출현하게 되었으며, 시기별 데이터의 유형및 특징은 아래와 같다
![시기별 데이터의 유형 및 특징](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.slideshare.net%2Fhypermin%2Fssa-01bigdata-databasetechnology201402050&psig=AOvVaw1KWtB_km_MoTusL0Cre2OX&ust=1710237232690000&source=images&cd=vfe&opi=89978449&ved=0CBIQjRxqFwoTCJCQ_pv464QDFQAAAAAdAAAAABA8z)
3) 비정형 데이터의 증가
- 트위터, 테북 등 다양한 SNS의 급격한 확산으로 인한 비정형 데이터의 증가
- 멀티미디어 콘텐츠와 콘텐츠 사용에 대한 증가
- 비정형 데이터를 트래킹, 수집할 수 있는 환경의 구축

사. 빅데이터가 만들어내는 본직적인 변화 *빅데이터의 변ㅎ화에 대해 용어, 설명, 예시 등 학습해두기*
>사전처리 > 사후처리
- 필요한 정보만 수집하고 필요하지 않은 정보를 버리는 시스템에서 가능한 한 많은 데이터를 모으고 그 데이터를 다양한 방식으로 조합해 숨은 정보를 찾아냄
> 표본조사 > 전수조사
- 데이터 수집 비용의 감소와 클라우드 컴퓨팅 기술의 발전으로 데이터 처리 비용이 감소하게 되었다. 이로 인해 표본을 조사하는 기존의 지식발견 방식에서 전수조사를 통해 샘플링이 주지 못하는 패턴이나 정보를 발견하는 방식으로 데이터 활용방법이 변화됨
> 질 > 양
- 데이터가 지속적으로 추가될 경우 양질의 정보가 오류 정보보다 많아 전체적으로 좋은 결과 산출에 긍정적인 영향을 미친다는 추론에 바탕을 둔 변화
> 인과관계 > 상관관계
- 상관관계를 통해 특정 현상의 발생 가능성이 포착되고, 그에 상응하는 행동을 하도록 추천되는 일이 점점 늘어남. 이처럼 데이터 기반의 상관관계 분석이 주는 인사이트가 인과관계에 의한 미래 예측을 점점 더 압도해 가는 시대가 도래할 것으로 전망

아. 빅데이터의 가치
- 빅데이터는 이제 크기보다 가치를 말함
- 단순히 '데이터가 많다'는 것은 '더 많은 지식과 정보가 있다'로 연결되지 않음
                > 데이터를 어떻게 수집, 분석, 활용하느냐에 따라 그 가치와 의미가 달라짐

 1) 빅데이터의 투입 가치
 - 주요 연구기관들은 빅데이터가 갖는 가능성에 기반을 둔 투입 요소로서의 가치에 의미를 두고 아래의 표와 같이 활발히 논의중

| 연구기관      | 투입 가치의 내용                                                                            |
| --------- | ------------------------------------------------------------------------------------ |
| Economist | 데이터는 기존 경제 요소인 자본, 노동력과 거의 동등한 수준의 경제적 투입자본으로 비즈니스 환경에서의 새로운 원자잭 역할을 수행함             |
| MIT Sloan | 데이터 분석 활용도가 높은 조직일수록 높은 성과 창출이 가능하고 차별적인 경쟁력을 확보할 수 있음                               |
| Gartner   | 데이터는 21세기의 원유이며, 미래의 경쟁 우위를 결정할 것임. 기업 및 조직은 데이터 경제의 시대를 이해하고. 데이터 고립에 대비해야 생존할 수 있음 |
| Mckinsey  | 빅데이터는 혁신, 경쟁력, 생산성 확보를 위한 핵심적 요소임                                                    |
2) 빅데이터의 활용 가치
- 빅데이터를 활용할 때 비용 절감, 미래 예측의 정확도 향상, 의사결정의 효율화 및 고도화, 의미있는 패턴 발견, 고객 요구사항 트렌드 신속한 파악 등에서 그 가치를 발견할 수 있다.
- 빅데이터를 효과적으로 활용하기 위해서는 장애 사항들을 해결하고, 공공 부문 인력의 역량을 강화하며, 국민 신뢰 확보를 위한 개인정보 및 프라이빗 관련 정책을 마련하는 등의 전제 조건이 필요

3) 빅데이터의 사회/경제적 가치
- 빅데이터의 도입 및 활용은 생산성 향상, 산업 경쟁력 제고, 혁신을 위한 새로운 가치를 창출
- 맥킨지가 제시한 빅데이터의 사회경제적 가치

| 구분                      | 내용                                                                 |
| ----------------------- | ------------------------------------------------------------------ |
| 고객 세분화를 통한 소비자 맟춤형 비즈니스 | 기업들이 구체적인 고객 분류를 통해 고객의 요구사항에 적합한 맟춤형 서비스 제공                       |
| 산업 투명성 향상               | 필요한 분야에 빅데이터를 적절한 시점에 제공함으로써 검색 및 처리 시간 절감                         |
| 고객 니즈 확인 및 트랜드 예측       | 거래 데이터를 디지털 형태로 축적하여 정확한 성과 데이터 수집, 자연적 발생 현상 및 실험에 의해 나타나는 성과의 분석 |
| 알고리즘을 통한 의사결정 지원        | 정교한 분석에 의해 의사결정 향상, 가치 있는 인사이트 발굴                                  |
| 제품 및 서비스, 비즈니스 모델의 혁신   | 새로운 제품 및 서비스 개발 및 개선, 새로운 비즈니스 모델 설계                               |
4) 빅데이터의 가치 산정은 어렵다
- 빅데이터는 다양한 측면에서 가치를 크게 평가받는데 비해서 여러 가지 변수로 인해서 빅데이터의 가치를 측정하는 것이 쉽지 않다
- 가치 산정이 어려운 이유

데이터 활용 방식 > 데이터 활용 방식에서는 재사용이나 재조합, 다목적용 데이터 개발 등이 일반화되면서 특정 데이터를 언제/어디서.누가 활용할지 알 수 없게 됨 ... 가치를 산정하는 것도 어려워짐
새로운 가치 창출 > 빅데이터 시대에는 데이터가 '기존에 없던 가치'를 창출함에 따라 그 가치를 측정하기가 어려워짐
분석 기술 발전 > 현재는 가치가 없는 데이터일지라도, 추후에 새로운 분석 기법이 등장한다면 거대한 가치를 지닌 데이터가 될 수도 있다

# 데이터 산업의 이해
가. 데이터 산업의 발전
- 4차 산업혁명 시대를 맞아 초연결 지능화 사회로 빠르게 진입함에 따라 핵심 인프라로 DNA(Data-Network-AI)가 강조되어 있다. 특히 데이터가 전 산업의 혁신 성장을 가속화하는 데이터 경제가 본격화되면서 다양하고 질 좋은 데이터를 보유/활용하는 비즈니스가 새로운 성장 동력으로 자리매김하게 되었다.
- 국내 굴지의 기업들도 '데이터기업'임을 천명하면서 이제 기존의 데이터 전문기업뿐만 아니라 의료, 금융,통신,유통,제조,에너지 등 다양한 산업군에서 데이터 기반의 혁신을 통해 데이터 산업의 새로운 생태계가 만들어짐
- 데이터 산업은 데이터 처리, 데이터 통합, 데이터 분석, 데이터 연결, 데이터 권리 시대 순으로 진화하고 있고, 최근 들어 데이터 분석, 데이터 연결, 데이터 권리 등이 동시에 발전하고 있다.
- 데이터 통합 시대가지 데이터의 역할은 거래를 정확하게 기록하고 거래의 자동화를 지원하는 것이었으나 데이터 분석 수준이 향상되면서 비로소 데이터가 자원으로 활용 가능하게 되었다.
  
  1) 데이터 처리 시대
  - 컴퓨터 프로그래밍 언어를 이용한 빠르고 정확한 대규모 데이터 처리가 이루어졌으며 이 시기에 데이터는 업무 처리의 대상으로만 인식
  2) 데이터 통합 시대
  - 축적되기 시작한 데이터들의 일관성을 확보하고 무결성을 유지하기 위해 데이터 모델링 및 DBMS등을 이용
  - 데이터는 데이터 통합을 통해 업무재성계(BPR), CRM, ERP 등에서도 중요한 역할을 함
  3) 데이터 분석 시대
  - 데이터가 폭발적으로 증가함으로써 대규모 데이터 보관 및 관리를 위한 하둡, 스파크 등의 빅데이터 기술이 등장하고, 복잡한 문제에 있어서 빠르고 정확한 의사결정을 수행할 수 있도록 기계에 데이터를 학습을 시키는데 인공지능 기술을 활용하고 있다
  4) 데이터 연결 시대
  - 디지털 경제의 중요한 특징은 기업/사람/사물 등 모든 것이 항상 그리고 동시에 연결되는 초연결이며, 이 상황에서 사물들은 사람을 통하지 않고서도 서로 간에 데이터를 주고 받음
  - 오픈 API를 통해 많은 기업 및 정부/공공기관들이 자신의 서비스와 데이터를 개방하고 있으며, 이로 인해 오픈 이노베이션이 가능해짐
  5) 데이터 권리 시대
  - 과거 데이터 관리에 있어서는 데이터 유출 및 개인의 동의 없는 불법적 활용이 큰 문제가 제기 되었으나 현재는 데이터 권리를 원래 주인인 개인에게 돌려주어야 한다는 마이데이터(My Data)가 중요한 이슈로 대두됨
  - 이로 인해 산업이 데이터를 중심으로 재편될 수 있다. 즉 개인 데이터를 관리해 줄 서비스와 개인 데이터를 수요자에게 팔아주는 서비스가 생겨날 수 있으며, 개인이 자신의 데이터를 기반으로 하는 비즈니스 모델을 생성할 수도 있다.
  
# 빅데이터 조직 및 인력
가. 필요성
- 빅데이터를 활용한다는 것은 '새로운 가치'를 창출하고, '일하는 방법'의 변화를 통해 보다 과학적인 기법을 활용한 의사결정으로 문제를 해결하는 것을 의미
- 또한 빅데이터는 광의의 관점에서 볼 때 인재 및 조직 변화를 포함하는 개념으로 정의됨
- 경영의 모든 요소에 있어서 데이터를 적극적으로 활용하는 빅데이터 경영 개념이 등장하면서 데이터 활용이 곧 기업의 경쟁력이 됨
- 이에 데이터 과제 발굴, 기술 검토, 전사적 차원의 업무 적용 계획 수립 등 데이터를 효과적으로 분석/활용하기 위한 기획/운영/관리를 전담할 전문 분석 조직의 필요성이 제기되고 있다.

나. 분석조직의 게요
- 데이터 분석 조직은 기업의 경쟁력 확보를 위해 데이터 분석의 가치를 발견하고, 이를 활용하여 비즈니스를 최적화하는 목표를 갖고 구성되어야 한다.
- 이를 위해 기업의 업무 전반에 걸쳐 다양한 분석 과제를 발굴해 정의하고, 데이터 분석을 통해 의미 있는 인사이트를 찾아 실행하는 역할을 수행할 수 있어야 한다.
- 다양한 분야의 지식과 경험을 가진인력과 업무 담당자 등으로 구성된 전사 또는 부서 내 조직으로 구성할 수 있다

> 분석 조직의 개요
- 목표 : 기업의 경쟁력 확보를 위해 비즈니스 질문과 이에 부합하는 가치를 찾고 비즈니스를 최적화(Optimization)
- 역할 : 전사 및 부서의 분석 업무 발굴, 전문적 기법과 분석 도구를 활용하여 기업 내 존재하는 빅데이터 속에서 Insight 전파, Action화
- 구성 : 기초통계학 및 분석 방법에 대한 지식과 분석 경험을 가지고 있는 인력으로 전사 또는 부서 내 조직으로 구성하여 운영

다. 조직 구성시 주요 고려사항
> 조직 구조
- 비즈니스 질문을 선제적으로 찾아낼 수 있는 구조인가?
- 분석 전담조직과 타 부서간 유기적인 협조와 지원이 원활한 구조인가?
- 효율적인 분석업무를 수행하기 위한 분석 조직의 내부 조직구조는?
- 전사 및 단위부서가 필요 시 접촉하며 지원할 수 있는 구조인가?
- 어떤 형태의 조직(중앙집중형, 분산형) 으로 구성하는 것이 효율적인가?

> 인력 구성
- 비즈니스 및 IT전문가의 조합으로 구성되어야 하는가?
- 어떤 경험과 어떤 스킬을 갖춘 사람으로 구성해야 하는가?
- 통계적 기법 및 분석 모델링 전문 인력을 별도로 구성해야 하는가?
- 전사 비즈니스를 커버하는 인력이 없다면?
- 전사 분석업무에 대한 적합한 인력 규모를 어느 정도인가?

![분석조직구조](https://www.google.com/url?sa=i&url=https%3A%2F%2Fm.blog.naver.com%2Fnknn2004%2F221713841295&psig=AOvVaw3tlVmfnmJcUr6j8z0KlTg3&ust=1710240246139000&source=images&cd=vfe&opi=89978449&ved=0CBIQjRxqFwoTCNj067iD7IQDFQAAAAAdAAAAABAp)
마. 분석 조직의 구성
- 전문 역량을 갖춘 각 분야의 인재들로 구성하여 분석 조직의 경쟁력을 극대화할 수 있음

분석조직(DSCoE)
Director/Manager

비즈니스 인력 : 해당 비즈니스를 잘 이해하고 분석 요소를 찾고 협의 할수 있는 능력
IT 기술 인력 : 분석에 필요한 IT 기술 동향을 파악, 필요한 기술 아키텍처를 수립할 수 있는 인력
분석전문 인력 : 고급 통계 분석기법을 이해하고 다양한 예측 모델링을 설계/검증할 수 있는 인력
변화관리 인력 : 경영층 대상으로 분석문화 확산을 위한 변화관리를 담당하는 인력
교육담당 인력 : 분석조직에게 다양한 분석기법에 대한 심도있는 교육을 할 수 있는 인력

1) 빅데이터 시스템 개발팀
- 주로 IT기술 인력이 주축이 되어 빅데이터 분석 플랫폼을 설계 및 구축하고 시스템을 운영하며 데이터의 안전성과 데이터의 품질을 책임짐
- 빅데이터 솔루션을 구매하거나 SI업체를 통해 필요한 분석 솔루션을 개발하거나 또는 커스터마이징을 통한 맞춤형 솔루션 제작을 할 수 있으며, 내부 인프라를 적극적으로 활용해 빅데이터 플랫폼을 직접 개발하는 방법이 있다.

2) 빅데이터 분석팀
- 분석전문인력을 주축으로 데이터를 가공하고 데이터를 분석하여 인사이트를 발굴하는 업무를 담당하며 통계 전문가 또는 데이터 마이닝을 할 수 있는 분석 역량이 있는 사람이 필요함
- 빅데이터 전문업체를 통해 분석 서비스를 받는 경우, 기업 내부 데이터의 접근이 어렵기 때문에 대부분 소셜 데이터를 이용한 외부 데이터 분석결과로 한정될 수 있다

3) 빅데이터 활용팀
- 분석된 정보에 가치를 부여할 수 있는 전략과 기획을 책임지는 침
- 사실상 빅데이터 활용 팀이라고 언급할 수 있는 조직을 운영하는 기업은 매우 드물며 대부분 기업의 마케팅, 영업팀, 또는 사업 개발팀 등이 빅데이터 사업화전략/기획/활용방안을 마련하기 위해 업무 공조를 하는 것이 일반적

바. 성공적 조직 운영
1) 시작은 Adhocracy
- 애드호크러시는 '특별 임시조직'으로 다양한 분야의 전문가들이 빠르고 혁신적인 기능을 활용하여 집중적으로 과제를 수행하는 고도로 유기적 조직 구조 유형
- 빅데이터 프로젝트는 소규모의 애드호크러시에서 신기술 도입 전 기술검증(POC)과정을 먼저 수행하고 그후 파일럿(Pilot)을 진행하는 것이 일반적임. 파일럿 프로젝트는 다양한 변수(데이터 보안, 사업비용, 분석 데이터의 용도, 기대 효과 등)를 체계적으로 검토하여 사업의 향후 방향성 및 개선안을 찾는 단계로 확장하게 됨
- 애드호크러시는 전문가에 의해 형식주의에 얽매이지 않고 의사결정이 내려지는 특징을 갖기 때문에 문제 해결능력과 빠른 의사결정, 창의적으로 순발력있게 대처할 수 있는 강력한 장점을 가지고 있다. 반면 전문가들의 내부 갈등 고조 가능성, 서로의 권한 또는 책임의 한계를 정의 내릴 수 없고, 자율성이 강하기 때문에 효율적인 업무 공조를 끌어내기가 힘들다.

2) 내부 조직과 외부 조직을 함께 활용
- 국내의 경우 빅데이터 프로젝트 수행 시 리더 밎 관리분야, 빅데이터 분석 역할에는 내부 조직을 적극적으로 활용하고, 빅데이터 시스템 엔지니어 및 플랫폼 개발과 운영 등의 역할에는 외부 조직을 기용하고 있는 경우가 많다.

사. 빅데이터 전문 인력
1) 데이터 사이언티스트(Data scientist)
- 주어진 데이터에서 '무엇을 이용해서 어떠한 것을 관찰할 것인가'하는 데이터 분석의 뼈대를 만드는 역할을 수행. 데이터 엔지니어링과 수학, 통계학, 고급 컴퓨팅 등 다방면에 걸쳐 복합적이고 고도화된 지식과 능력을 갖춰야 함
- 데이터의 다각적 분석을 통해 인사이트를 도출하고 이것으로 조직의 전략 방향을 제시하는 기획자이자 전략가
- 빅데이터에 대한 이록적 지식과 숙련괸 분석 기술을 바탕으로 통찰력/전달력/협업 능력을 갖춘 전문 인력
- 다양한 현장 경험을 통해 전문 지식과 노하우를 축적해야 하므로 다른 빅데이터 전문인력에 비해 아직 데이터 사이언티스트는 드뭄
- 다음과 같은 역량이 요구됨 (IT 전문성 / Analytics/비즈니스 분석)
> Hard Skill
- 빅데이터에 대한 이론적 지식 : 관련 기법에 대한 이해와 방법론 습득
- 분석 기술에 대한 숙련 : 최적의 분석 설계 및 노하우 축적
> Soft Skill
- 통찰력 있는 분석 : 창의적 사고, 호기심, 논리적 비판
- 설득력 있는 전달 : 스토리텔링, 비주얼라이제이션
- 다분야간 협력 : 커뮤니케이션

2) 알고리즈미스트(Algorithmist)
- 데이터 오용의 대응책으로 '알고리즘에 대한 접근권'을 제공하여 예측 알고리즘에 불이익을 당한 사람들을 대변할 전문가가 필요해짐
- 데이터 사이언티스트가 한 일로 인해 부당하게 피해가 발생하는 것을 막는 역할
- 알고리즘 코딩 해석을 통해 빅데이터 알고리즘에 의해 피해를 입은 사람을 구제하는 전문인력

3) 인포그래픽스 아티스트(Infodraphics Artist)
- 시각화는 데이터 분석 결과를 전달하는 마지막 단계로서 데이터의 해석 작업에 해당. 정교한 모형 및 시각화 도구가 요구됨
- 대규모 데이터를 분석하여 그 결과를 차트/지도.다이어그램/로고/일러스트레이션 등을 활용해 시각화함으로써 이해하기 쉽게 전달. 텍스트 데이터 및 수치(통계) 데이터 등을 인포그래픽스라는 형태로 시각화하는 일을 담당
---
# 빅데이터 기술 및 제도

---
# 빅데이터 플랫폼
가. 빅데이터 플랫폼의 정의 및 개념도
- 빅데이터 플랫폼은 다양한 데이터 소스로부터 수집한 데이터를 처리하고 분석하여 지식을 추출하고, 이를 기반으로 지능화된 서비스를 제공하는 데 필요한 IT 환경
- 빅데이터 플랫폼은 다양한 소스로부터 생성되는 대량의 데이터를 처리하기 위하여 데이터의 수집/저장/처리/분석/시각화(지식 가시화)를 제공

*알아두기. 최근 기출 개념
- 빅데이터 플랫폼의 구조와 클라우드 서비스
> 소프트웨어 계층
- *데이터 처리 및 분석 엔진
- 사용자 관리모듈
- *데이터 수집 및 정제 모듈
- 모니터링 모듈
- 서비스 관리 모듈
- 보안 모듈

> 플랫폼 계층
- *작업 스케줄링 모듈
- 데이터 관리 모듈
- 사용자관리 모듈
- *데이터 자원 및 할당 모듈
- 자원 관리 모듈
- 모니터링 모듈
- *프로파일링 모듈
- 서비스 관리 모듈
- 보안 모듈

> 인프라 스트럭처 계층
- *자원 배치 모듈
- 자원 관리 모듈
- 모니터링 모듈
- *노드 관리 모듈
- 서비스 관리 모듈
- 보안 모듈
- 데이터 관리 모듈
- 사용자 관리 모듈

> 클라우드 서비스 종류
- Iaas(Instructure as a Service) : 서버, 스토리지, 네트워크를 가상화 환경으로 만들어, 필요에 따라 인프라 자원을 사용할 수 있게 제공하는 서비스
- PaaS(Platform as a Service) : SaaS 개념을 개발 플랫폼으로 확장한 것. 웹에서 개발 플랫폼을 쉽게 빌려쓸 수 있는 서비스
- Saas(Software as a Service) : Iaas와 PaaS 위에 올라가는 소프트웨어. On-demand Software 라고도 함, 중앙에서 호스팅되는 소프트웨어를 웹브라우저 등 클라이언트로 이용하는 서비스

1) 데이터 수집
- 가용데이터가 확인되면 조직 내/외부의 여러 데이터 소스로부터 크롤링/웹크롤러/웹 로봇/ 오픈 API/스크린 스크래핑 등의 기술을 이용해 필요한 데이터를 수집

2) 데이터 저장
- 빅데이터 분석의 기본 인프라로 분산 파일 시스템, NoSQL, 병렬 DBMS, 클라우드 파일 저장 시스템, 네트워크 구성 저장 시스템 등이 필요

3) 데이터 분석
- 다양한 통계 처리, 데이터 마이닝/텍스트 마이닝/오피니언 마이닝/시공간 마이닝/소셜 네트워크 분석 등 다양한 분석 방법 및 머신러닝/딥러닝 기법을 적용해햐 한다.

4) 데이터 시각화
- 데이터 통찰을 위해서 또는 분석 결과를 시각화하기 위한 도구들로 마이크로소프트의 엑셀이나 스프레드 시트, R이나 파이썬의 시각화 패키지, 시각화 솔루션을 활용하여 시공간 시각화, 관계 시각화, 비교 시각화, 인포그래픽 등을 제공한다

나 .하둡 에코 시스템(Hadoop Ecosystem)
- 하둡 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 집합으로, 수집, 저장, 처리 기술과 분석, 실시간 SQL 질의 기술로 구분한다.
- 하둡 에코 시스템 기술로는 비정형 데이터 수집, 정형 데이터 수집, 분산 데이터 저장, 분산 데이터 베이스, 분산 데이터 처리, 리소스 관리, 인메모리 처리, 데이터 가공, 데이터 마이닝, 실시간 SQL 질의, 워크플로우 관리, 분산 코디네이션 등이 있다.

1) 비정형 데이터 수집
- 척와(Chuckwa) : 분산된 각 서버에서 에이전트를 실행하고, 컬랙터가 에이전트로부터 데이터를 받아 HDFS에 저장하는 기술
- 플럼(Flume) : 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동하기 위해 이벤트와 에이전트를 활용하는 기술
- 스크라이브(Scribe) : 다수의 서버로부터 실시간으로 스트리밍되는 로그 데이터를 수집하여 분산 시스템에 데이터를 저장하는 실시간 로그 수집 기술이며, 최종 데이터는 HDFS외에 다양한 저장소를 활용함

2) 정형 데이터 수집
- 스쿱(Sqoop): 대용량 데이터 전송 솔루션으로 커넥터를 사용하여 관계형 데이터 베이스시스템에서 하둡 파일 시스템으로 데이터를 수집하고나, 하둡 파일 시스템에서 관계형 데이터베이스로 데이터를 보내는 기술
- 히호(Hiho) : 스쿱 같은 대용량 데이터 전송 솔루션, 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있으며 JDBC 인터페이스 지원

3) 분산 데이터 저장
- HDFS : 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게하는 하둡 분산 파일 시스템으로 범용 하드웨어 기반 클러스터에서 실행되고 데이터 접근 패턴을 스트리밍 방식으로 지원하며, 다중 복제, 대량 파일 저장, 온라인 변경, 범용서버 기반, 자동 복구 특징이 있다.
- HDFS 구성요소

| 구성         | 특징                                     |
| ---------- | -------------------------------------- |
| 리소스 매니저    | 스케줄러 역할 수행, 클러스터 이용률 최적화 수행            |
| 노드매니저      | 노드 내의 자원 관리, 리소스 매니저에게 전달 수행 및 컨테이너 관리 |
| 애플리케이션 마스터 | 리소스 매니저와 자원의 교섭을 책임지고, 컨테이너 실행         |
| 컨테이너       | 프로그램 구동을 위한 격리 환경을 지원하는 가상화 자원         |
7) 인메모리 처리
- 아파치 스파크(Apache Spark) : 하둡 기반 대규모 데이터 분산처리 시스템. 스트리밍 데이터, 온라인 메신러닝 등 실시간으로 데이터 처리
8) 데이터 가공
- 피그(Pig) : 대용량 데이터 집합을 분석하기 위한 플랫폼으로 하둡을 이용하여 맵리듀스를 사용하기 위한 높은 수준의 스크립트 언어인 피그 라틴이라는 자체 언어 제공
- 하이브(Hive): 하둡 기반 DW솔루션으로 SQL과 매우 유사한 HiveQL이라는 쿼리를 제공

9) 데이터 마이닝
- 머하웃(Mahout) : 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈소스로 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀분석, 진화 알고리즘 등 주요 알고리즘을 지원함

10) 실시간 SQL 질의
- 임팔라(Impala) : 하둡 기반의 실시간 SQL 질의 시스템으로 데이터 조회를 위한 인터페이스로 HiveQL을 사용하며, 수초 내에 SQL 질의 결과를 확인할 수 있으며, HBase와 연동이 가능하다.
- 타조(Tajo) : 다양한 데이터 소스를 위한 하둡 기반의 ETL 기술을 이용해서 데이터 웨어하우스에 적재하는 시스템

11) 워크플로우 관리
- 우지(Oozie) : 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템

12) 분산 코디네이션
- 주키퍼(Zookeeper) : 분산 환경에서 서버들 간에 상호 조정이 필요한 다양한 서비스를 제공하는 기술. 하나의 서버에서만 서비스가 집중되지 않도록 서비스를 알맞게 분산하여 동시에 처리

# 빅데이터와 인공지능

가. 인공지능(AI : Artificial Intelligence)
- 인간의 학습능력, 추론능력/지각능력/자연언어의 이해능력 등 인간 지능의 한 단면을 컴퓨터 프로그램으로 실현한 기술
- 인공지능은 이전의 패턴이나 지도를 보지 않고도 추론을 통해 구성요소들과 사건 간의 관계를 밝혀내고 머신러닝이나 인공지능 알고리즘을 사용해서 미래에 어떤 일이 일어날지 예측할 수가 있다.
- 인공지능 기술
 1. 학습지능 : 지식을 확보하는 알고리즘을 연구
 2. 단일지능 : 시각, 청각, 언어 등 한 종류 입력을 가지고 지식을 확보
 3. 복합지능 : 여러 형태의 입력을 통합혀여 이해/판단하는 기술을 포함

| 소분류    | 세분류               | 요소 기술                                                                        |
| ------ | ----------------- | ---------------------------------------------------------------------------- |
| 학습  지능 | 머신러닝              | 베이지안 학습, 인공신경망, 딥러닝, 강화학습, 앙상블러닝, 판단근거 설명                                    |
|        | 추론/<br>지식표현       | 추론, 지식표현 및 온톨로지, 지식처리                                                        |
| 단일  지능 | 언어지능              | 언어분석, 의미이해, 대화 이해 및 생성, 자동 통역/번역, 질의응답(Q/A), 텍스트 요약/생성                       |
|        | 시각지능              | 영상 처리 및 패턴 인식, 객체 인식, 객체 탐지, 행동 이해, 장소/장면 이해, 비디오 분석 및 예측, 시공간 영상 이해, 비디오 요약 |
|        | 청각지능              | 음성분석, 음성 인식, 화자인식/적응, 음성합성, 오디오 색인 및 검색, 잡음처리 및 음원분리, 음향인식                   |
| 복합  지능 | 행동/          소셜지능 | 공간 지능, 운동 지능, 소셜 지능, 협업 지능                                                   |
|        | 상황/<br>감정이해       | 감정 이해, 사용자 의도 이해, 뇌신호인지, 센서 데이터 이해, 오감 인지, 다중 상황 판단                          |
|        | 지능형 <br>에이전트      | 에이전트 플랫폼, 에이전트 기술, 게임 지능, 모방창작 기능                                            |
|        | 범용 <br>인공지능(AGI)  | 상식 학습, 범용 문제 해결, 평생 학습, 도덕-윤리-법 지능                                           |
- 인공지능은 '모든 것이 연걸되고 보다 지능적인 사회로의 진화'로 전망되는 제 4차 산업혁명의 주역으로서 인공지능 산업에서는 데이터와 지식이 핵심적인 경쟁 원천이 됨
- 인공지능 vs 머신러닝 vs 딥러닝

> 인공지능 : 사람이 해야 할 일을 기계가 대신힐 수 있는 모든 자동화
> 머신러닝 : 명시적으로 규칙을 프로그래밍하지 않고 데이터로부터 의사결정을 위한 패턴을 기계가 스스로 학습
 - 사람이 수행하기에 복잡하거나 어려운 작업을  사람의 프로그래밍없이 대량의 데이터를 접했을 때 스스로 수정하여 원하는 결과를 얻기 위한 기술
> 딥러닝 : 인공신경망 기반의 모델. 비정형 데이터로부터 특징 추출 및 판단까지 기계가 한 번에 수행
- 머신러닝에 속하는 대표적인 방법론. 머신러닝은 학습에 필요한 데이터를 수동으로 제공해야 하지만, 딥러닝은 분류에 사용할 데이터를 스스로 학습

% 전이 학습(Transfer Learning)
- 방대한 양의 데이터로 이미 학습된 인공지능을 유사하지만 다른 분야에 적용하는 방법. 학습된 모델의 초종 출력층을 보유 중인 데이터에 대응하는 출력층으로 바꾸고, 교체한 출력층의 결합 파라미터(그리고 앞 층의 결합 파라미터)를 소량의 데이터로 다시 학습한다. 입력층에 가까운 부분의 결합 파라미터는 학습된 값으로 변화시키지 않는다.

나. 인공지능 기술의 발전
- 1950년대에 생각하는 기계를 만들고자 하는 프로젝트(앨런 튜링의 사고기계 제안)로 시작.
- 초기 30년간은 전문가의 지식을 기계에 직접 프로그래밍하여 인공지능을 구현하였으며 이는 1980년대 지식기반 전문가 시스템 형태로 산업화에 크게 기여. 하지만 전문가들조차 그들의 지식을 명확하게 규정하기 어렵고 이를 기계가 수행하도록 표현하는 것에 한계가 있음. 한편 pc등장으로 AI 빙하기(AI Winter)가 도래
- 1990년대에 AI 연구자들은 완전히 새로운 기술인 '머신러닝'을 연구. 머신러닝은 사람의 지식을 기계에 주입하는 것이 아닌 기계가 데이터로부터 스스로 지식을 습득하는 귀납적 추론 방법이 적용됨
- 이후 인테넷/웹/소셜 데이터와 머신러닝의 산업화가 이루어졌고, 최근 머신러닝은 딥러닝으로 발전하면서 딥러닝 기술은 빅데이터와 고성능컴퓨팅 기술과 결합되어 수많은 인공지능 문제를 해결하는 데 큰 기여를 하고 있다.

다. 빅데이터 비즈니스에서 인공지능 기술의 활용
- 머신러닝 알고리즘을 활용하면 이전에 알아낼 수 없었던 새로운 통찰을 얻을 수 있다
- 사람의 인지능력을 활용해서 데이터나 현상을 관찰하고 분류해야 하는 분석 작업의 경우 자동화르 통해 작업의 효율성을 향상시킬 수 있다.
- 자동화된 인지기능을 이용하면 사람보다 훨씬 빠르게 데이터를 분류, 처리하고 메타데이터로 주석을 달 수 있어 대량의 데이터를 검사, 분류하고 이를 바탕으로 의사결정을 하거나 비즈니스 가치에 직접 연결되는 후속 데이터 처리 과정에 유용하게 활용될 수 있다.
- 단순한 반복작업이 필요한 상황에서 머신러닝 및 인공지능 기술들을 통해 어느 정도 자동화가 가능
- 머신러닝 알고리즘 특히 집러닝 기반의 인공지능 알고리즘을 학습시키기 위해서 빅데이터를 활용하면 모델의 정확도와 성능을 높을 수 있다. 머신러닝은 같은 모델을 따르는 데이터가 많으면 학습된 모델이 정확해지므로 모델을 학습하기에 충분할 만큼의 데이터가 있어야 한다.
- 다양한 산업에서 인공지능이 활용되는 사례를 찾아볼 수 있다.

라. 인공지능 경쟁력의 3요소 *출제 포인트*
* 인공지능 성공 비결 = 알고리즘 (기존 신경망 한계 극복) + H/W 발달(GPU 능력 향상) + Big Data(풍부한 학습데이터)

1) 알고리즘
- 머신러닝 업계에서 오픈소스를 공개함으로써 최근 들어 학습 알고리즘은 인터넷을 통해 쉽게 구할 수 있게 되었다.
- 구글은 세계 최고 수준의 딥러닝 엔진인 텐서플로우를 공개, 그 외에 빅DL/오픈딥/카페/씨아노/토치/엠엑스넷 등 수많은 툴이 공개되면서 공급 과잉의 상태

2) 컴퓨팅 파워
- 딥러닝 또는 머신러닝에 필수 불가결한 요소로 특히 깊은 층으로 구성된 산경망을 학습하기 위해서는 높은 성능의 하드웨어가 필요
- 현재 컴퓨터 성능은 매우 빠른 속도로 발전하고 있으며 이러한 성능 발전 속도는 복잡하고 많은 양의 계산이 필요한 딥러닝이 자리잡는 데 큰 공헌을 하였다.

3) 빅데이터
- 인공지능에서 가장 핵심적인 경쟁력
- 데이터는 머신러닝이 학습하는 재료로서 최근 딥러닝이 급격하게 발전한 이유 또한 인공지능이 학습할 데이터가 풍부해졌기 때문
- 딥러닝에서는 데이터의 양과 질이 모두 중요하며 목적에 따라 정확히 라벨링 된 데이터를 얻기 위해 많은 시간과 비용을 들임. 양질의 데이터를 많이 갖고 있는 주체는 우수한 품질의 머신러닝을 실행할 수 있으며 향후 인공지능의 미래를 이끄는 리더가 될 수 있다

# 개인 정보 법/제도

가. 빅데이터 시대의 위기와 통제
1) 위기 요인  
    가) 사생활 침해
    

| 내용  | 개인정보가 포함된 데이터를 목적 외에 활용할 경우 사생활 침해를 넘어 사회/경제적 위협으로 변형될 수 있다         |
| --- | ------------------------------------------------------------------- |
| 예시  | 여행 사실을 트위트한 사람의 집을 강도가 노리는 고전적 사례 발생 -> 익명화(anonymization) 기술 발전 필요 |
	나) 책임 원칙 훼손

| 내용  | 빅데이터 기본분석과 예측기술이 발전하면서 정확도가 증가한 만큼, 분석대상이 되는 사람들은 예측 알고리즘의 희생양이 될 가능성도 증가. 민주주의 국가에서는 잠재적 위협이 아닌 명확한 결과에 대한 책임을 묻고 있어 이에 따른 원리를 훼손할 가능성이 있다 |
| --- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| 예시  | 영화 "마이너리티 리포트"에 나오는 것처럼 범죄 예측 프로그램에 의해 범행을 저지르기 전에 체포, 자신의 신용도와 무관하고 부당하게 대출이 거절됨 -> 민주주의 국가의 형사 처벌은 밤재적 위협이 아닌 명확하게 행동한 결과에 대해 책임을 묻고 있다   |
    다) 데이터 오용

| 내용  | 빅데이터는 일어난 일에 대한 데이터에 의존하기 때문에 이를 바탕으로 미래를 예측하는 것은 적지 않은 정확도를 가질 수 있지만 항상 맞을수는 없다. 또한 잘못된 지표를 사용하는 것도 빅데이터의 폐해가 될수 있음 |
| --- | -------------------------------------------------------------------------------------------------------------------- |
| 예시  | 베트남 전쟁 시 맥나마라 장군은 적군 사망자 수를 전쟁의 진척상황을 나타내는 지표로 활용 -> 적군 사망자 수는 과장돼 보고되는 경향을 보여 결과적으로 전쟁 상황을 오보하는 결과를 일으킴             |
2) 통제 방안  
	 가) 동의에서 책임으로

| 내용   | 빅데이터에 의한 사생활 침해 문제를 해결하기에는 부족한 측면이 많고 매번 개인정보 제공 동의를 하는 비효율적인 단계를 줄이고자 개인정보를 사용하는 사용자의 /책임/을 해결하는 방안을 제시(개인정보 제공자의 동의 > 개인정보 사용자의 책임) |
| ---- | ------------------------------------------------------------------------------------------------------------------------------------- |
| 기대효과 | 개인정보 유출 및 사용으로 발생하는 피해에 대해 사용자가 책임을 지게 되므로 사용주체의 적극적인 보호장치를 강구할 수 있다.                                                                 |
// 참고 소비자 프라이버시 보호 3대 권고사항
1. 기업은 상품 개발 단계에서부터 소비자 프라이버시 보호 방안을 적용하라
2. 기업은 소비자에게 공유정보 선택 옵션을 제공하라
3. 소비자에게 수집된 정보 내용 공개 및 접근권을 부여하라

    나) 결과 기반 책임 원칙 고수

| 내용     | 책임원칙 훼손 위기요인에 대한 통제 방안으로 기존의 원칙을 좀 더 보강하고 강화할 필요가 있으며, 예측 자료에 의한 불이익을 당할 가능성을 초소화하는 장치를 마련하는 것이 필요 |
| ------ | -------------------------------------------------------------------------------------------------- |
| 기대  효과 | 잘못된 예측 알고리즘을 통한 판단을 근거로 불이익을 줄 수 없으며, 이에 따른 피해 최소화 장치를 마련해야 함                                      |
	다) 알고리즘 접근 허용

| 내용     | 데이터 오용의 위기요소에 대한 대응책으로 알고리즘에 대한 접근권을 제공하여 예측 알고리즘의 부당함을 반증할 수 있는 방법을 명시해 공개할 것을 주문한다 |
| ------ | ------------------------------------------------------------------------------------ |
| 기대  효과 | 불이익을 당한 사람들을 대변할 전문가(알고리즈미스트)가 필요하게 되었다                                              |

나. 개인 정보 관련 법
	1) 개인정보보호법(시행 2020.8.5 일부개정 2020.2.4)
		- 특정 정보만으로 개인을 식별할 수 없더라도 다른 정보와의 결합으로 식별되는 경우가 있으므로 다른 정보와 얼마나 쉽게 결합할 수 있는지에 대한 결합 가능성 또한 중요한 의미를 가짐
		- 데이터 이전(transference)과 관련하여 정보주체 또는 제3자의 이익을 부당하게 침해할 우려가 있을 때를 제외하고는 개인정보를 목적 외의 용도로 이용하거나 이를 제3자에게 제공할 수 있다.
*최근 기출개념 - 개인 정보 수집 및 제공*
- 개인정보 수집 및 제공과 관련해 정보주체의 동의없이 개인 정보 수집/이용이 가능한 경우
	1. 볍률에 특별한 규정이 있거나 법령상 의무 준수를 위해 불가피한 경우
	2. 공공기관이 법령 등에서 정하는 소관업무 수행을 위해 불가피한 경우
	3. 정보주체와의 계약의 체결 및 이행을 위해 불가피하게 필요한 경우
	4. - 정보주체 또는 법정대리인이 의사표시를 할 수 없는 상태거나 주소불명 등으로 사전 동의를 받을 수 없는 경우. 명백히 정보주체 또는 제 3자의 급박한 생명, 신체, 재산의 이익을 위하여 필요하다고 인정되는 경우(이 경우 사유가 해소된 대에는 개인정보 처리 즉시 중단, 주체에게 사실과 사유, 이용내역 통지지)
	5. 개인정보처리자의 정당한 이익을 달성하기 위해 필요한 경우, 명백하게 정보주체의 권리보다 우선하는 경우
	6.  정보통신서비스 제공에 관한 계약 이행을 위해 필요한 개인정보로서 경제적/기ㅜㄹ적인 사유로 통상적인 동의를 받는 것이 뚜렷하게 곤란한 경우
	7. 정보통신서비스의 제공에 따른 요금정산을 위하여 필요한 경우
	8. 다른 법률에 특별한 규정이 있는 경우
- 개인정보 수집/제공 동의서 작성 시, 개인 정보의 제 3자 제공 시 확인해야할 사항
	1. 개인정보를 제공받는자
	2. 개인정보를 제공받는 자의 개인정보 이용 목적
	3. 제공하는 개인정보 항목
	4. 개인정보를 제공받는 자의 개인정보 보유 및 이용기간
	5. 동의를 거부할 권리가 있다는 사실 및 동의 거부에 따른 불이익이 있는 경우 그 내용

	2) 정보통신망법(시행 2020.9.10 일부개정 2020.6.9)
	- 이 법은 정보통신망의 이용을 촉진하고 정보통신서비스를 이용하는 자를 보호함과 아울러 정보통신망을 건전하고 안전하게 이용할 수 있는 환경을 조성하여 국민 생활의 향상과 공공복리의 증진에 이바지함을 목적으로 함
	- 정보통신망법과 개인정보보호법의 적용이 경합하는 경우에는 정보통신망법이 우선 적용
		-> 온라인 서비스를 제공하는 정보통신서비스제공자는 정보통신망법에 대한 검토 필요

	3) 신용정보법(시행 2020.8.5 일부개정 2020.2.4)
	- 이 법은 신용정보 관련 산업을 건전하게 육성하고 신용정보의 효율적 이용과 체계적 관리를 도모하며 신용정보의 오용/남용으로부터 사생활의 비밀 등을 적절히 보호함으로써 건전한 신용질서를 확립하고 국민경제의 발전에 이바지함을 목적으로 함
	- 신용정보회사는 신용정보를 수집하고 이를 처리할 수 있으며, 이 경우 수집 및 처리의 목적을 명확히 해야 하고, 신용 정보법 및 개인정보보호법에 따라 그 목적 달성에 필요한 최소한의 범위에서 합리적이고 공정한 수단을 사용하여 신용정보를 수집 및 처리해야 함

4) 데이터 3법
	- 개인정보보호법, 정보통신망법, 신용정보법 개정안을 일컫는 말
	- 개인정보보호에 관한 법이 소관 부처별로 나뉘어 있어 발생하는 중복 규제를 없애 4차 산업혁명 도래에 맞춰 개인과 기업이 정보를 활용할 수 있는 폭을 넓히기 위해 마련됨
	- 빅데이터 3법, 데이터 경제 3법이라고도 부르며 추가 정보의 결합 없이는 개인을 식별할 수 없도록 안전하게 처리된 가명정보의 개념을 도입하는 것이 핵심
	- 데이터 3법의 주요 개정안 내용
	
*출제포인트 : 매우 관련이 깊음! 가명정보의 개념 도입으로 개정되었다는 점!*

| 관련법     | 개정안 주요 내용                                                                                                                |
| ------- | ------------------------------------------------------------------------------------------------------------------------ |
| 개인정보보호법 | 개인정보 관련 개념을 개인정보/가명정보/익명정보로 구분한 후 가명정보를 통계작성연구, 공익적 기록보존 목적으로 처리할 수 있도록 허용한다                                             |
| 정보통신망법  | 정보통신망법에 규정된 개인정보보호 관련 사항을 개인정보보호법으로 이관한다                                                                                 |
| 신용정보법   | 가명조치한 개인신용정보로서 가명정보 개념을 도입해 빅데이터 분석 및 이용의 법적 근거를 명확히 마련한다<br>가명정보는 통계작성, 연구, 공익적 기록보존 등을 위해 신용정보 주체의 동의 없이도 이용, 제공할 수 있다 |

다. 마이데이터(본인정보 활용 지원) 사업
- 마이데이터 사업은 과기정통부 및 한국데이터산업진흥원에 의해 추진되고 있는 사업으로 정보주체 중심의 안전한 개인데이터 통합/활용기반을 마련하고 다양한 개인정보 활용 혁신서비스 발굴 및 확산을 위한 공모이다
- 개인이 자신의 데이터를 실질적으로 관리, 활용, 제 3자 제공할 수 있는 체계를 마련하기 위해 마이데이터 플랫폼 중심의 서비스 개발을 지원함. 마이데이터 플랫폼은 개별사업자 또는 개인데이터 보유기업(기관), 활용기업(기관)이 구축/운영할 수 있다
- 마이데이터 사업은 개인 데이터의 제공 채널 확대를 위한 실증서비스 지원, 분야별 민관협의체를 통한 마이데이터 활용 가이드 마련, 아이디어 공모전 등 행사, 홍보를 통한 인식 제고 등으로 구성되어 있다

## 개인정보 활용
- 다양한 융/복합 산업에서 빅데이터, AI등의 기술을 활용함으로써 데이터의 이용에 대한 수요는 급증하고 있는 가운데 개인정보 활용의 핵심인 가명정보 활용 관련 법적 근거가 마련되어 체계적인 데이터 활용 기반이 조성됨

 가. 개인정보 보호를 위한 가명정보 활용의 배경
- 4차산업혁명 시대 신성장 동력인 '데이터 활용'에 대한 시대적 요구를 반영하여 데이터 3법이 개정되어 시행되었다
- 개정된 데이터 3법에서는 가명정보 처리에 관한 특례가 신설되어 개인정보처리자가 통계작성, 과학적 연구, 공익적 기록보존 등을 위한 목적으로 개인정보를 가명처리하여 활용할 수 있는 기반이 마련됨
- 보호법 제28조의 2에 따른 동의 없는 가명정보의 처리과정에서의 오/남용을 방지하고, 데이터 산업활성화를 위한 안전한 가명정보 활용방안을 제시함으로써 데이터 활용을 활성화할 수 있다

나. 가명정보 개요
1) 가명처리의 필요성
	- 개인정보는 개인에 관한 여러 정보들이 포함되어 있는 정보로 처리 및 활용하는 과정에서 개인의 사생활 침해 등 다양한 문제가 발생할 수 있다
	- 개인정보를 안전하게 활용하기 위해 특정 개인에 대한 정보들이 노출되지 않도록 기술적 안전조치(가명처리)를 수행할 필요가 있다
	- 즉, 개인정보를 그대로 이용하게 되면 개인의 신원 및 정보들이 그대로 노출되기 때문에 특정 개인을 알아볼 수 있는 정보들을 삭제하거나 대체하는 등의 방법으로 가공한 후 사용할 필요가 있다.
	
1) 가명처리의 목적 및 대상

| 처리<br>목적    | 내용                                                                                               | 예시                                                                                                      |
| ----------- | ------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------- |
| 통계<br>작성    | - 통계는 특정 집단이나 대상 등에 관하여 작성한 수치 정보를 의미<br>- 일대일 마케팅 등을 위해 개인 식별이 필요한 통계는 해당 안 됨                   | 지자체가 연령에 다른 편의시설 확대를 위해 편의시설의 이용통계(위치/방문자수/체류시간/연령대/성별 등)를 생성 분석하여 적합한 지역에 신규 편의 시설을 선정하고자 하는 경우        |
| 과학적 연구      | - 기술의 개발과 실증, 기초연구, 응용연구 및 민간 투자 연구 등 과학적 방법을 적용하는 연구를 의미                                        | 코로나19 감염자의 생활패턴 분석을 통해 개개인에 대한 위험 경고를 해줄 수 있는 앱 개발을 위해 감염자의 생활습관/위치/감염증상/성별 등을 가명처리하여 활용하는 경우           |
| 공익적 기록<br보존 | - 공공의 이익을 위해 지속적으로 열람할 가치가 있는 정보를 기록하여 보존하는 것을 의미<br>- 민간기업, 단체 등이 일반적인 공익을 위하여 기록을 보존하는 경우도 인정됨 | 청소년 대상 온라인 상담서비스를 운영하는 민간기업이 우울증 지수, 자살충동지수가 높은 청소년의 상담정보를 기록하여 해당정보를 지역 공공상담센터와 연계하여 상담치료 목적으로 활용하는 경우 |

다. 가명처리 절차
- 가명처리는 '개인정보의 일부를 삭제하거나 일부 또는 전부를 대체하는 등의 방법으로 추가 정보없이는 특정 개인을 알아볼 수 없도록 처리하는 것'을 의미
- 가명처리 시 가명정보 자체만으로 특정 개인을 알아볼 수 있는지 여부와 추가정보 또는 다른 정보(가명정보처리자가 보유하는 정보 등)와의 결합 가능성을 고려할 필요가 이다
- 가명정보처리자가 보유한 다른 정보 등을 통해 개인이 식별 가능한 경우 가명처리가 잘못된 경우라고 할 수 있다
- 가명처리 단계별 절차도
사전준비 > 가명처리 > 적정성 검토 및 추가처리 > 사후관리

1) 사전 준비
- 가명처리 대상 및 처리수준을 정의하기 위해서는 처리 목적을 최대한 명확히 하고, 적합성 검토, 필요서류 작성 등을 수행해야 한다
- 가명처리의 목적을 명확히 하고 만약 내부적 승인이 별도로 존재할 경우에는 가명처리 수행에 관한 승인을 받기 위한 추가 설명자료 작성이나 회의 개최 등을 진행할 수 있다.
- 가명정보처리자는 가명정보를 제 3자에게 제공하는 경우 이용목적 및 방법, 재식별 위험관리 등 가명정보의 안전성 확보를 위하여 필요한 조치를 마련하도록 하는 내용을 포함한 계약을 체결할 수 있다.

2) 가명처리
- 가명정보 처리 시에도 개인정보의 초소처리원칙을 준수하여야 하며 가명처리방법을 정할 때에는 처리목적, 처리(제공)환경, 정보의 성격 등을 종합적으로 고려하여야 한다
- 구체화된 목적에 필요한 최소한의 항목만을 가명처리 대상으로 선정하고 가명처리 대상 정보(원본 등)와 분리하여야 한다
- 가명처리 대상 정보의 '항목별 위험도 측정'은 가명정보처리자가 보유하고 있는 정보 등을 기준으로 판단하여야 하므로 내부활용(제공)과 제3자 제공 시 고려해야 할 사항이 달라질 수 있다. 이때 가명정보처리자의 안전조치(접근통제, 권한관리 등) 수준 및 정보 자체의 재식별 가능성에 따라 가명처리 대상 항목을 달리 판단할 수 있다
- 처리(제공)환경과 처리목적에 부합하는 개인정보의 항목 등을 고려하여 항목별 가명처리 방법 및 수준을 먼저 정의하고, 이에 다라 가명처리를 수행하도록 한다

3) 적정성 검토  및 추가처리
- 목적 달성을 위해 적절한 수준으로 가명처리가 이루어졌는지, 재식별 가능성은 없는지 등에 대한 최종적인 판단절차를 수행한다
- 가명처리 결과가 가명정보 활용 목적달성에 적합하지 모하거나 가명처리의 수준이 부족하다고 판단한 경우 '2단계(가명처리)'를 반복하거나 부분적으로 추가적인 가명처리를 할 수 있다
- 데이터의 분포, 내용 등을 고려하여 특이정보가 있다고 판단한 경우 해당 데이터에 대한 적절한 조치를 취하도록 한다

4) 사후관리
- 검토결과 적정으로 판단된 가명정보에 대해 관련 법령에 따라 기술적/관리적/물리적 안전조치를 이행하도록 한다
- 가명정보취급자에게 금지행위, 안전조치 등에 관한 사항을 안내허여 처리하도록 한다

5) 내부결합 절차
- 내부결합은 개인정보처리자가 보유한 개인정보를 가명처리하여 생성된 가명정보 간의 결합을 의미
- 사전준비 단계에서 결합대상 정보 간 결합키로 활용될 공통속성(항목)과 결합알고리즘(암호종류+salt포함)을 선정한다
- 결합키를 제외한 정보에 대하여 각 가명처리 절차 1~3단계를 이행한 후 결합을 진행
- 결합이 완료된 정보에 대하여 가명정보처리자의 판단에 따라 외부전문가 등을 활용하여 가명처리 정차 3단계(적정성 검토)를 수행할 수 있으며 필요 시 추가 처리 등을 검토

라. 가명처리 세부 절차 *절차 숙지하기. 특히 2단계 본격적인 과정에서 행해지는 과업 순서와 내용!*
> 사전준비 > ==가명처리(대산선정->위험도 측정->가명처리 수준정의->가명처리)==(처리환경 검토-내부활용/내부제공/제3자제공 + 항목별 위험도 분석) >검토 및 추가 처리 > 활용 및 사후관리 
1) 사전 준비 : 처리 목적의 적합성 검토 및 가명처리 준비
- 가명처리를 위한 사전 준비 단계에서는 가명정보 활용 목적의 명확화와 가명처리의 적합성 검토, 가명처리를 위한 필요 서류 작성 등의 절차를 수행해야 함
2) 가명처리 : 가명처리 수준 정의 및 처리
- 세부적으로 대상선정, 위험도 측정, 가명처리 수준정의, 가명처리

	가) 대상선정
	- 사전준비 단계에서 수립한 목적을 달성하기 위해 가명처리 대상 정보로부터 가명처리에 필요한 항목을 추출
	- 목적달성에 필요한 최소 항목을 처리하는 것을 원칙으로 함
	나) 위험도 측정
	- 처리(제공)환경 검토 : 처리 목적에 따라 처리(제공)환경과 제공받는 자의 개인정보 보호수준 및 다른 정보 보유여부 등을 검토. 불특정 제3자(공개 등)에게 제공하는 경우에는 익명처리를 원칙으로 함
	- 항목별 위험도 분석 : 가명처리하여 내부 활용 또는 제공하고자 하는 항목을 대상으로 개인 식별 가능성이 높은 정보 등을 분류하여 항목별 위험도를 분석
	- 위험도 측정 : 가명정보처리자는 가명정보 활용에 따른 처리(제공)환경과 항목별 위험도 분석을 통한 검토 결과 보고서를 작성하여 관리할 수 있다
	다) 가명처리 수준 정의
	- 가명처리 수준은 '가명처리 검토 결과보고서'를 기반으로 정보의 활용 목적 달성에 필요한 수준을 고려하여 가명처리 수준을 정의
	라) 가명처리
	- '가명처리 수준 정의표'를 기반으로 가명처리 수행
	- 가명처리 단계에서 생성되는 추가정보는 원본정보 및 가명정보와 분리하여 별도로 저장하여 보관 수행
	- 가명정보 DB와 물리적으로 분리된 별도의 DB에 보관하는 것을 원칙. 만약 물리적 분리가 어려운 경우 논리적으로 분리한 별도의 DB에 보관

3) 검토 및 추가처리
- 가명처리 단계에서 수립한 '가명처리 수준 정의표'의 기준에 따라 적절히 가명처리가 되었는지 확인하고 목적달성 가능성과 특이정보를 통한 재식별 가능성 등 검토
- 가명처리의 적정성 검토 : 가명정보처리자가 정의한 가명처리 수준에 따라 적절히 가명처리가 되었는지 확인하는 것으로 개인정보처리자의 판단에 따라 외부전문가로 구성된 적정성 평가단을 구성하여 검토 가능
- 목정달성가능성 검토 : 생성한 가명정보가 초기 가명정보 활용목적을 달성할 수 있는지 여부 검토. 생성한 가명정보가 활용 목적을 달성하지 못하는 경우 '가명처리' 단계를 재수행하여 목적달성 가능한 가명처리 수준을 재정의하여 처리
- 개인정보를 가명처리하여 개인을 알아볼 수 없게 처리했더라도 '특이정보'를 통해 개인식별이 가능한 경우를 검토하여 특이정보 처리 수행

4) 활용 및 사후관리
- 개인정보처리자는 누구든지 특정 개인을 알아보기 위한 목적으로 가명정보를 처리해서는 안됨. 가명처리자체를 무효화 또는 무력화하여 원래 상태로 복원시키거나 추가 정보 또는 다른 정보(공개된 정보 포함)와의 결합 또는 대조 바교 등을 통해 정보주체가 누구인지 확인할 수 있는 상태로 회복시키기 위한 일체의 처리를 해서는 안됨
- 가명정보 처리 과정에서 개인식별가능성이 증가하는 지에 대한 여부 등을 지속적으로 모니터링 하여 안전하게 처리해야 하며, 특정 개인이 식별되는 경우 즉시 처리중지/회수/파기 등 위와 같은 위험을 제거하기 위해 적절한 조치를 수행해야 한다