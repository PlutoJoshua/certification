# 분석 방안 수립
## 데이터 분석 기획의 방향
### 데이터 분석 기획의 방향

가. 분석 기획이란?
- 실제 분석을 수행하기에 앞서 분석을 수행할 과제를 정의하고, 의도했던 결과를 도출할 수 있도록 이를 적절하게 관리할 수 있는 방안을 사전에 계획하는 일련의 작업
- 분석 과제 및 프로젝트를 직접 수행하는 것은 아니지만, 어떠한 목표(What)를 달성하기 위해(Why) 어떠한 데이터를 가지고 어떤 방식으로(How) 수행할지에 대한 일련의 계획을 수립하는 작업이기 때문에 성공적인 분석결과 도출을 위해 중요한 사전 작업이다.
나. 분석 기획 시 필요 역량
- 데이터 분석을 기획하기 위해서는 수학/통계학적 지식 및 정보 기술(IT, 해킹, 통신 기술 등) 분만 아니라 해당 비즈니스에 대한 이해와 전문성을 포함한 2가지 영역에 대해 고른 역량이 요구되며 균형잡힌 시각을 가지고 분석의 방향성 및 계획을 수립해야 한다
- 데이터 사이언티스의 3대 역량
![[Pasted image 20240312183002.png]]

다. 분석의 유형
- 분석 대상(What)과 분석의 방법(How)에 따라 4가지로 나뉨
- 북석 대상에 대해 어느정도 알고 있는지, 관련 분석 방법(기법)을 어느 정도로 잘 알고 능숙하게 다룰 수 있는지에 따라 분석의 유형을 다르게 설정할 수 있음

|       | 분석       | 대상           | (What)    |
| ----- | -------- | ------------ | --------- |
| 분석    |          | Known        | Un-Known  |
| 방법    | Known    | Optimization | Insight   |
| (How) | Un-Known | Solution     | Discovery |

- Optimization(최적화) : 분석 대상과 분석 방법을 이해함으로써 현 문제를 최적화 형태로 수행 가능
- Solution(솔루션) : 분석 대상은 알고 있지만 분석 방법을 모를 경우 솔루션을 찾아 분석 수행
- Insight(통찰) : 분석 대상에 대해서 명확히 알 수 없지만 분석 방법을 알고 있다면 인사이트 도출
- Discovery(탐색) : 분석 대상 및 방법 모두 잘 알지 못하는 경우 탐색을 통해 분석 대상 자체를 새롭게 도출

라. 목표 시점 별 기획 방안 *방향, 목표, 특징 숙지/과제중심과 장기적 마스터 플랜 방식 구분*
- 목표시점 별로는 당면한 과제를 빠르게 해결하는 '과제중심적 접근 방식'과 지속적인 분석 내재화를 위한 '장기적 마스터플랜 방식'으로 나눌 수 있다
- 마스터 플랜 방식 : 장기적인 관점에서 데이터를 바라보면서 전체 문제에 대한 정확한 정의를 내리고 효율적인 자원 배치 및 관리를 위한 방법
- 과제 중심 방식 : 좁은 범위의 특정 주제에 대해 테스트를 실행함으로써 빠르게 문제를진단하고 해결하기 위한 방법
- 따라서 분석 기획 단계에서는 두 가지 방법을 적절하게 융합하여 분석과제 정의 및 문제 해결 모두를 달성할 수 있도록 하는 것이 중요


| 당면한 분석 주제의 해결(과제 단위) |         | 지속적 분석 문화 내재화(마스터 플랜 단위) |
| -------------------- | ------- | ------------------------ |
| Spped & Test         | <1차 목표> | Accuracy & Deploy        |
| Quick & Win          | <과제 유형> | Long Term View           |
| Problem Solving      | <접근 방식> | Problem Definition       |

마. 분석 기획 시 고려 사항
![[Pasted image 20240312184312.png]]
가능한 데이터 확보 2. 유명한 유스케이스 활용 3. 장애요소들을 최소화한 구현 => 성공적 분석

1) 가용 데이터(Available data)
- 분석을 위한 가용 데이터의 혹보가 우선
- 데이터 유형에 따라서 적용 가능한 솔류션 및 분석 방법이 다르기 때문에 유형에 대한 분석 선행
2) 적절한 유즈케이스 탐색(Proper Business Use Case)
- 분석을 통해 가치가 창출될 수 있는 적절한 활용방안과 유즈케이스 탐색 필요
- 유즈케이스 : 여러 가지 일어날 수 있는 사용자 경로를 테스트 하는 것
- '바퀴를 재발명하지 마라' 라는 격언처럼 기존에 잘 구현되어 활용되고 있는 유사 분석 시나리오 및 솔루션이 있다면 시간 및 노력을 들여 새롭게 구현할 필요 없이 기존의 것들을 최대한 활용하는 것이 효율성을 높일 수 있다

3) 낮은 실행 장벽(Low Barrier Of Execution)
- 분석 수행 시 발생하는 장애요소들에 대한 사전계획 수립이 필요
- 일회성 분석으로 그치지 않고 조직 역량으로 내재화하기 위해서는 충분하고 계속적인 교츅 및 활용방안 등의 변화관리가 고려되어야 함

### 분석 마스터 플랜 수립 프레임 워크

가. 분석 마스터 플랜 수립 개요
- 데이터 기반 구축을 위해서 분석 과제를 대상으로 전략적 중요도, 비즈니스 성과 및 ROI, 분석 과제의 실행 용이성 등 다양한 기준을 고려해 적용 우선순위를 설정함
- 업무내재화 적용 수준, 분석 데이터 적용 수준, 기술 적용 수준 등 분석 적용 범위 및 방식에 대해서 종합적으로 고려해 데이터 분석 구현을 위한 로드맵 수립
![[Pasted image 20240312184936.png]]

// 참고 ISP(정보전략계획)
- 기업 및 공공기관에서는 시스템의 중장기 로드맺을 정의하기 위한 ISP를 수행
- ISP(Information Strategy Planning) : 정보기술 및 정보시스템을 전략적으로 활용하기 위해 조직의 내/외부 환경을 분석하여 기회 및 문제점을 도출하고, 사용자의 요구사항을 분석하여 시스템 구축의 우선순위를 결정하는 중장기 마스터 플린 수립 절차
- 분석 마스터 플랜(Analysis Master Plan) : 일반적인 ISP 방법론을 활용하되 데이터 분석 기획의 특성을 고려하고 기업에서 필요한 데이터 분석 과제를 빠짐없이 도출한 후 과제의 우선순위를 결정하고 단기 및 중/중기로 나누어 계획을 수립

나. 분석과제의 적용 우선순위 결정
1) 우선순위 평가 방법 및 절차
- 우선순위 평가의 경우 정의된 데이터 과제에 대한 실행 순서를 정함
- 업무별 도출된 분석과제를 우선순위 평가 기준에 따라 평가하고 과제 수행의 선/후행 관계를 고려하여 적용 순위를 조정해 최종 확정

> 분석과제 도출 > 우선순위 평가 (과제우선순위기준 수립)> 우선순위 정련(분석과제 수행의 선후관계분석을 통해 순위조정)
2) 일반적인 IT프로젝트의 우선순위 평가 예시
- ISP와 같은 일반적인 IT프로젝트 과제의 우선순위 평가를 위해서는 전략적 중요도 및 실행 용이성 등 기업에서 고려하는 중요 가치 기준에 따라 다양한 관점에서의 우선순위 기준을 수립하여 평가할 수 있다
- 전략적 필요성이 높고 현재 시급성이 높다면 전략적으로 중요도가 높은 것으로 평가되어 과제 수행 우선순위는 높게 매겨질것이다
- 투자예산을 확보할 가능성이 높고 기술 확보가 용이하고 기술의 안정성이 보장되는 부분이라면 실행 용이성이 높은 것으로 평가되어 과제 수행 우선순위는 높게 매겨질 것
![[Pasted image 20240312185722.png]]
- 데이터 기반 구축을 위해서는 분석 과제를 대상으로 전략적 중요도, 비즈니스 성과 및 ROI, 분석 과제의 실행 용이성 등의 기준을 고려해 적용 우선순위를 설정

3) ROI(Return of Investment, 투자자본수익률) 관점에서 빅데이터의 핵심특징
![[Pasted image 20240313080350.png]]
- 빅데이터의 특징을 ROI(투자대비 수익) 관점에서 '3V(Volume, Variety, Velocity) + Value = 4V'로 정의함으로써 빅데이터를 단순히 대용량의 다양한 그리고 생성속도가 빠른 데이터라는 개념이 아니라 비용요소를 투입하여 데이터 분석을 통해 목표가치를 달성할 수 있는 도구의 개념으로 볼 수 있다.
- 한편 투자비용 대비 가치, 즉 비즈니스 효과를 가장 높게 달성시켜 줄 수 있는 분석 과제를 높은 순위에 둘 수도 있다.

가) 투자비용(Investment) 요소
- 3V는 얼마나 많은 데이터를 가지고, 어떠한 데이터로 구성되어, 얼마나 빠르게 처리하여 결과를 도출하는 지에 초점을 둔 것이기 때문에 투자비용 요소에 해당된다
	1. 크기(Volume) : 데이터의 규모 및 양을 의미, 대용량 데이터를 저장/처리하고 관리하기 위해서는 새로운 투자가 필요
	2. 다양성(Variety) : 다양한 종류 및 형태의 데이터를 저장/처리하고 관리하기 위해서는 새로운 투자가 필요
	3. 속도(Velocity) : 데이터 추출 속도 및 처리 속도를 향상시키기 위한 데이터 가공/분석 기술 확보에 대한 투자 필요
나) 비즈니스 효과(Return) 요소
- 4V는 가치를 창출한다는 의미를 가지고 있으므로 비즈니스 효과에 해당
	4. 가치(Value) : 분석 결과를 활용하거나 실질적인 실행을 통해 얻게 되는 비즈니스 효과 측면의 요소로, 기업 데이터 분석을 통해 추구하거나 달성하고자 하는 목표 가치를 의미

4) 과제 수행의 시급성및 난이도에 따른 우선순위 평가
- 데이터 분석과제의 우선순위 평가는 시급성 및 난이도에 따른 우선순위 기준을 수립하여 평가
	가) 시급성(Urgency)
	- 분석과제가 전략적 중요도와 핵심성과지표(Key Performance Indicator, KPI)에 부합하는 지가 시급성 판단의 기준이다. 판단의 핵심은 전략적 중요도이며, 이는 분석과제의 전략적 가치를 현재 관점에 둘 것인지 아니면 미래의 중장기적 관점에 둘 것인지를 고려하는 것이다. 또한 시급성 판단에는 핵심성과지표도 함께 고려함
	- 전략적 중요도와 핵심성과지표가 기업이 데이터 분석을 통해 추구하고 달성하고자 하는 목표라는 관점에서 시급성은 빅데이터의 가치(Value)와 관련된다
	나) 난이도(Level of Difficulty)
	- 난이도는 현 시점에서 과제를 추진하는 것이 비용측면(데이터를 생성/저장/가공/분석하는 비용)과 범위측면(현재 기업의 분석수준)에서 적용하기 쉬운지 또는 어려운지에 대한 판단 기준으로 데이터 분석의 적합성 여부를 보는 것
	- 과제 수행에는 데이터 획득/저장/가공 비용과 분석 적용 비용이 투입되어야 하므로 난이도는 빅데이터의 투자비용 요소(Investment)와 관련
	
![[Pasted image 20240313083553.png]]

5) 포트폴리오 사분면(Quadrant) 분석을 통한 우선순위 선정
 - 분석 과제를 난이도와 시급성에 따라 4가지 유형으로 구분하여 분석과제 적용 우선순위를 결정
![[Pasted image 20240313083727.png]] ![[Pasted image 20240313083826.png]]
![[Pasted image 20240313083844.png]]
- 위의 그림에서 볼 때, 사분면 영역에서 가장 우선적인 분석 과제 적용이 필요한 영역은 3영역. 기술/비용적인 측면에서 난이도가 낮아 큰 어려움 없이 당장 분석이 가능하며, 현재 개발할 필요가 있는 시급성이 있다고 판단되는 영역이기 때문
- 전략적 중요도가 현재 시점에는 상대적으로 낮은 편이지만 중장기적으로는 경영에 미치는 영향도가 높고, 분석 과제를 바로 적용하기 어려워 우선순위가 늦은 영역은 2영역
- ==시급성 기준== 3 -> 4 -> 2
- ==난이도 기준== 3 -> 1 -> 2
- 9번 과제와 같이 1사문면에 위치한 분석과제는 데이터 양, 데이터 특성, 분석 범위등에 따라 난이도를 조율함으로써 적용 우선순위를 조정할 수 있다. ex. 분석에 필요한 데이터 양이 테라바이트(TB)규모 라면, 분석 대상이 되는 소스 데이터를 내부 데이터 관점에서 우선 분석할 수 있도록 데이터의 양을 줄여 난이도를 낮출 수 있다. 이를 통해 궁극적으로는 1영역에서 3영역으로 분석 적용의 우선순위를 조정하여 추진할 수 있다.

다. 이행계획(로드맵) 수립
- 데이터 분석 구현을 위한 로드맵은 분석 과제에 대한 포트폴리오 사분면 분석을 통해 난이도와 시급성을 기준으로 과제의 1차적 우선순위를 결정한 후, 추가적으로 분석 과제별로 적용범위 및 방식(업무내재화 적용 수준, 분석데이터 적용 수준, 기술적용 수준 등)을 고려하여 최종적인 실행 우선 순위를 결정함
- 이후 3개의 추진단계 즉, 데이터 분석 체계 도입단계, 데이터분석 유효성 검증단계, 데이터 분석 확산 및 고도화 단계에 해당하는 각각의 단계별 추진 목표를 설정
- 목표에 대한 추진 과제별 선/후행 관계를 고려하여 단계별 추진 내용을 정렬하여 로드맵 수립함
![[Pasted image 20240313084842.png]]

라. 세부 이행계획 수립
- 데이터 분석체계는 고전적인 폭포수(Water-Fall) 방식도 있으나 반복적인 정련 과정을 통하여 프로젝트의 완성도를 높이는 방식을 주로 사용
- 반복적인 분석 체계는 모든 단계를 반복하기보다 데이터 수집 및 확보와 분석데이터를 준비하는 단계를 순차적으로 진행하고, 모델링 단계는 반복적으로 수행하는 혼합형을 많이 적용. 그리고 이러한 특성을 고려하여 세부적인 일정계획도 수립해야 함
- ![[Pasted image 20240313085143.png]]
// 참고 폭포수 모델(Water-Fall)
- 순차적인 소프트웨어 개발 프로세스로 개발의 흐름이 마치 폭포수처럼 지속적으로 아래로 향하는 것처럼 보인다하여 붙여진 임름. 소프트웨어 요구사항 기술, 소프트웨어 설계, 구현, 통합 시험과 디버깅 설치, 유지보수의 단계로 프로세스가 이루어지는데, 이 모델에서는 각 단계들이 진행되면서 이전 단계로 돌아갈 수 없다. 즉 다음 단계로 전진만 하는 것. 따라서 폭포수 모델은 요구사항 분석이 완벽히 이루어져 있고, 기존에도 여러 번 분석이 이루어졌던 조직에서 수행할 수 있는 방법. 이전 단계로 돌아가지 않기 때문에 각 단계가 끝나고 나면 완전한 문서화가 각 단계별로 이루어지는 특징이 있다

### 거버넌스 체계
가. 개요
- 기업에서 데이터를 이용한 의사결정이 강조될수록 데이터 분석과 활용을 위한 체계적인 관리가 중요해짐. 단순히 대용량 데이터를 수집/축적하는 것보다는 어떤 목적으로 어떤 데이터를 어떻게 분석에 활용할 것인가가 더욱 중요하기 때문. 그리고 조직 내 분석 관리체계를 수립해야 하는 이유는 데이터 분석을 기업의 문화로 정착하고 데이터 분석 업무를 지속적으로 고도화하기 위함

나. 구성요소
- 마스터 플랜 수립 시점에서 데이터 분석의 지속적인 적용과 확산을 위한 거버넌스 체계는 분석기획 및 관리를 수행하는 조직(Organization), 과제 기획 및 운영 프로세스(Process), 분석 관련 시스템(System), 데이터(Data), 분석 관련 교육 및 마인드 육성체계(Human Resource)로 구성
![[Pasted image 20240313091001.png]]

### 데이터 분석 수준진단
가. 개요
- 기업들은 데이터 분석의 도입 여부와 활용에 명확한 분석 수준을 점검할 필요가 있다. 데이터 분석의 수준진단을 통해 데이터 분석 기반을 구현하기 위해서는 무엇을 준비하고 보완해야 하는지 등 분석의 유형 및 분석의 방향성을 결정할 수 있다.
- 데이터 분석 수준 진단을 위한 분석 준비도(readiness)와 분석 성숙도(maturity)의 구성

분석 준비도

| 분석업무   | 분석인력, 조직 | 분석 기법  |
| ------ | -------- | ------ |
| 분석 데이터 | 분석 문화    | 분석 인프라 |
분석 성숙도

| 도입   | 활용   | 확산  | 최적화 |
| ---- | ---- | --- | --- |
| ^    | ^    | ^   | ^   |
| 비즈니스 | 조직 및 | 역량  | IT  |
![[Pasted image 20240313091645.png]]

나. 수준 진단 목표 2가지
1) 정의
- 기업의 현재 분석 수준을 명확히 이해하고, 수준진단 결과를 토대로 미래의 목표수준을 정의
- 데이터 분석을 위한 기반 또는 환경이 유사업종 또는 타 경쟁사에 비해 어느 정도 수준이고, 데이터를 활용한 분석의 경쟁력 확보를 위해 어떠한 영역에 선택과 집중을 해야 하는 지, 어떤 관점을 보완해야 하는지 등 개선 방안을 도출

2) 분석 준비도
	가) 목표 : 기업의 데이터 분석 도입의 수준을 파악하기 위한 진단방법
	나) 구성 : 총 6가지
	다) 진단과정
		1. 영역별로 세부 항목에 대한 수준 파악
		2. 진단결과 전체 요건 중 일정 수준 이상 충족하면 분석업무 도입
		3. 충족하지 못할 시 분석 환경 조성

| 분석업무 파악                                                                                    | 인력 및 조직                                                                                                       | 분석기법                                                                                                     |
| ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| - 발생한 사실 분석<br>- 예측 분석<br>- 시뮬레이션 분석<br>- 최적화 분석<br>- 분석업무 정기적 개선                          | - 분석 전문가 직무 존재<br>- 분석 전문가 교육 훈련 프로그램<br>- 관리자들의 기본적 분석 능력<br>- 전사 분석업무 총괄 조직 존재<br>- 경영진의 분석 업무 이해 능력        | - 업무별 적합한 분석기법 사용<br>- 분석업무 도입 방법론<br>- 분석기법 라이브러리<br>- 분석기법 효과성 평가<br>- 분석기법 정기적 개선                     |
| 분석 데이터                                                                                     | 분석 문화                                                                                                         | IT인프라                                                                                                    |
| - 데이터 충분성<br>- 데이터 신뢰성<br>- 데이터 적시성<br>- 비구조적 데이터 관리<br>- 외부 데이터 활용 체계<br>- 기준 데이터 관리(MDM) | - 사실에 근거한 의사결정<br>- 관리자의 데이터 중시 정도<br>- 회의 등에서 데이터 활용 상황<br>- 경영진 직관 vs <br>  데이터 기반 의사결정<br>- 데이터 공유 및 협업 문화 | - 운영시스템 데이터 통합<br>- EAL, ETL등 데이터 유통체계<br>- 분석 전용 서버 및 스토리지<br>- 빅데이터 분석 환경<br>- 통계 분석 환경<br>- 비쥬얼 분석 환경 |

3) 분석 성숙도 모델
	가) 조직의 성숙도 평가 도구
	-  CMMI(Capability Maurity Model Integration) 모델 : 소프트웨어 개발 및 전산장비 운영 업체들의 업무능력 및 조직의 성숙도를 평가하기 위한 모델
	나) 성숙도 수준 분류 : 도입단계, 활용단계, 확산단계, 최적화단계
	다) 분석 성숙도 진단 분류 : 비즈니스 부문, 조직/역량 부문, IT부문

| 단계      | 도입                                             | 활용                                          | 확산                                                        | 최적화                                                     |
| ------- | ---------------------------------------------- | ------------------------------------------- | --------------------------------------------------------- | ------------------------------------------------------- |
| 설명      | 분석을 시작하여 환경과 시스템 구축                            | 분석 결과를 실제 업무에 적용                            | 전사 차원에서 분석을 관리하고 공유                                       | 분석을 진화시켜 혁신/성과 향상에 기여                                   |
| 비지니스 부문 | - 실적 분석 및 통계<br>- 정기보고 수행<br>- 운영데이터 기반        | - 미래 결과 예측<br>- 시뮬레이션<br>- 운영 데이터 기반        | - 전사 성과 실시간 분석<br>- 프로세스 혁신 3.0<br> - 분석규칙 관리<br>- 이벤트 관리 | - 외부 환경분석 활용<br>- 최적화 업무 적용<br>- 실시간 분석<br>- 비즈니스 모델 진화 |
| 조직역량 부문 | - 일부 부서에서 수행<br>- 담당자 역량에 의존                   | - 전문 담당부서에서 수행<br>- 분석기법 도입<br>- 관리자가 분석 수행 | - 전사 모든 부서 수행<br>- 분석COE 조직 운영<br>- 데이터 사이언티스트 확보         | - 데이터사이언스 그룹<br>- 경영진 부석 활용<br>- 전략 연계                  |
| IT 부문   | - 데이터 웨어하우스<br>- 데이터 마트<br>- ETL/EAI<br>- OLAP | - 실시간 대시보드<br>- 통계분석 환경                     | - 빅데이터 관리 환경<br>- 시뮬레이션/최적화<br>- 비주얼 분석<br>-분석 전용 서버      | - 분석 협업환경<br>- 분석 SandBox<br>- 프로세스 내재화<br>- 빅데이터 분석    |

4) 분석 수준 진단 결과
- 기업의 현재 분석 수준을 객관적으로 파악
- 경쟁사의 분석 수준과 비교하여 분석 경쟁력 확보 및 강화를 위한 목표 수준 설정 가능

가) 분석 관점에서의 사분면 분석
-  분석 수준 진단결과를 구분
- 데이터 분석 수준에 대한 목표 방향을 정의
- 유형별 특성에 따른 개선방안 수립
![[Pasted image 20240313105120.png]]

![[Pasted image 20240313091628.png]]

### 분석과제 발굴 및 문제 정의
가. 분석 과제 발굴 방법론 개요
- 분석 과제는 풀어야 할 다양한 문제를 데이터 분석 문제로 변환한 후 관계자들이 이해하고 프로젝트로 수행할 수 있는 과제 정의서 형태로 도출됨
- 분석 과제를 도출하기 위한 방식 : 하향식 접근 방법(Top Down Approach) / 상향식 접근 방법(Bottom up Approach)
![[Pasted image 20240313110055.png]]

- 전통적으로 수행되었던 분석 과제 발굴 방식은 문제가 주어져 있는 상태에서 답을 구하는 하향식 집근 방식. 하지만 급변하는 경영 환경에서 대규모의 다양한 데이터가 생성되기 때문에 사전에 문제를 명확히 정의하는 것은 어려운 상황임
- 분석 과제 발굴을 두 가지 방식으로 나누긴 했지만, 실제 경영 환경에서는 새로운 상품 개발이나 전략 수립 등 중요한 의사결정을 할 때 하향식 접근 방법과 상향식 접근 방법이 혼용되어 사용되고 있으며, 분석의 가치를 높일 수 있는 최적의 의사결정은 두 접근 방식이 상호보완 관계에 있을 때 가능하다
참고 // Design Thinking
- 상향직 접근 방식의 발산 단계와 하향식 접근 방식의 수렴 단계를 반복적으로 수행하는 상호 보완적인 동적 환경을 통해 분석의 가치를 높일 수 있는 최적의 의사결정 방식

나. 하향식 접근법( Top Down Approach) *체계적 절차가 제시됨. 4단계의 각 주요 과업 중요*
- 현황분석을 통해 기회나 문제를 탐색하고. 해당 문제를 정의, 해결방안을 탐색함. 데이터 분석에 대한 타당성 평가(Feasibility Study)를 거쳐 분석과제를 도출하는 과정으로 구성
![[Pasted image 20240313112948.png]]

1) 문제 탐색단계
- 전체적인 관점의 기준 모델인 기업 내/외부 환경을 포괄하는 비즈니스 모델과 외부 참조 모델을 활용하여 기업 내 존재하는 문제를 빠짐없이 식별하고 도출해내는 것이 중요
- 과제발굴 단계에서는 문제를 해결함으로써 발생하는 가치에 중점을 두는 것이 중요

가) 비즈니스 모델 기반 문제 탐색
- 기업 내/외부 환경을 포괄하고 있는 비즈니스 모델이라는 틀(frame)을 활용하여 비즈니스 모델 캔버스의 9가지 블록을 단순화하여 업무(Operaion), 제품, 고객 단위로 문제를 발굴하고, 이를 관리하는 두 가지의 영역인 규제와 감사(Regulation&Audit)영역과 지원 인프라( IT&Human Resource) 영역에 대한 기회를 추가로 도출하는 작업을 수행
![[Pasted image 20240313125643.png]]

==업무==(Operation) : 제품 및 서비스 생산을 위해 운영하는 내부 프로세스 및 주요 자원과 관련 주제 도출 // 생산 공정 최적화, 재고량 최소화
==제품==(Product) : 생산 및 제공하는 제품/서비스를 개선하기 위한 관련 주제 도출
// 제품의 주요기능 개선, 서비스 모니터링 지표 도출
==고객==(Customer) : 제품/서비스를 제공받는 사용자 및 고객, 이를 제공하는 채널의 관점에서 관련 주제 도출 // 고객 Call 대기 시간 최소화, 영업점 위치 최적화
==규제와 감사==(Regulation & Audit) : 제품 생산 및 전달과정 프로세스 중에서 발생하는 규제 및 보안의 관점에서 주제 도출 // 제공 서비스 품질 이상 징후 관리, 새로운 환경 규제 시 예상되는 제품 추출
==지원 인프라==(IT & Human Resource) : 분석을 수행하는 시스템 영역 및 이를 운영/관리하는 인력의 관점에서 주제 도출 // EDW(Enterprice Data Warehouse) 최적화, 적정 운영 인력 도출 등

나) 분석 기회 발굴의 범위 확장
- 현재 기업의 주변 환경, 현재의 경쟁자, 현재 속한 시장, 현재 보유중인 역량의 범위를 넘어서 분석 기회 및 발굴의 범위를 확장할 필요가 있다
- 즉, 사회/기술/경제/정치/환경적 측면에서 거시적인 관점을 가질 필요가 있으며 경쟁자를 확대하여 기존의 경쟁업체 뿐만 아니라 신규 진입자 및 대체재 제공업체도 고려해야 함. 뿐만 아니라 고객/채널/이해관계자의 시장 니즈 변화에도 주목해야 하며 보유한 내/외부 역량을 새롭게 해석하여 다양한 측면에서 적용할 수 있는 새로운 관점의 접근을 통해 새로운 유형의 분석 기회 및 주제발굴을 수행해야 함
![[Pasted image 20240313132651.png]]

(1) 거시적 관점의 메가트랜드
- 조직 및 해당 산업에 폭넓게 영향을 미치는 사회/경제적 요인은 STEEP(Social, Technological, Economic,  Environmental)으로 폭넓게 나눔
- **Social(사회)** : 비즈니스 모델의 고객 영역에 존재하는 현재 고객을 확장하여 전체 시장을 대상으로 사회적, 문화적, 구조적 트렌드 변화에 기반한 분석 기회를 도출 // 노령화, 밀레니엄 세대 등장, 저출산에 따른 사업모델 변화
- **Technological(기술)** : 과학, 기술, 의학 등 최신 기술의 등장 및 변화에 따른 역량 내재화와 제품/서비스 개발에 대한 분석 기회 도출 // 나노기술, IT 융합 기술, 로봇 기술의 고도화로 인한 제품의 Smart 화
- **Economic(경제)** : 산업과 금융 전반의 변동성 및 경제 구조 변화 동향에 따른 시장의 흐름을 파악하고, 이에 대한 분석 기회 도출 // 원자재 가격, 환율,금리 변동에 따른 구매전략 변화 등
- **Environment(환경)** : 환경과 관련된 정부, 사회단체, 시민사회의 관심과 규제 동향을 파악하고 이에 대한 분석 기회 도출 // 탄소배출 규제 및 거래 시장 등장에 따른 원가 절감 및 정보 가시화 등
- **Political(정치)** : 주요 정책 방향, 정세, 지정학적 동향 등의 거시적인 흐름을 토대로 한 분석 기회 도출 // 대북관계 동향에 따른 원자재 구매 거래선의 다변화 등
(2) 경쟁자 확대 관점
- 현재 수행하고 있는 사업 영역의 직접 경쟁사 및 제품/서비스 뿐만 아니라 대체제와 신규 진입자 등으로 관점을 확대하여 위협이 될 수 있는 상황에 대한 분석 기회 발굴의 폭을 넓혀서 탐색
- **대체재(Substitute)** : 융합적인 경쟁 환경에서 현재 생산을 수행하고 있는 제품/서비스를 온라인으로 제공하는 것에 대한 탐색 및 잠재적 위험을 파악 // 오프라인 제공 서비스 -> 온라인 제공에 대한 탐색 및 잠재적 위협 파악
- **경쟁자(Comprtitor)** : 현재 생산하고 있는 제품/서비스의 주요 경쟁자에 대한 동향을 파악하여 이를 고려한 분석 기회 도출 // 식별된 주요 경쟁사의 제품/서비스 카탈로그 및 전략 분석을 통한 잠재적 위협 파악
- **신규 진입자(New Entrant)** : 향후 시장에 대해서 파괴적인 역할을 수행할 수 있는 신규 진입자에 대한 동향을 파악하여 이를 고려한 분석 기회 도출 // 새 제품에 대한 클라우드 소싱 서비스인 킥 스타터의 유사 제품을 분석하고 잠재적 위협 파악
(3) 시장의 니즈 탐색 관점
-  현재 수행하고 있는 사업에서의 직접 고객뿐만 아니라 고객과 접촉하는 역할을 수행하는 채널(Channel) 및 고객의 구매와 의사결정에 영향을 미치는 인플루언서(Influencer)에 대한 폭넓은 관점을 바탕으로 분석 기회 탐색
- **고객** : 고객의 구매 동향 및 고객의 컨텍스트를 더욱 깊게 이해하여 제품/서비스의 개선에 필요한 분석 기회 도출 // 철강 기업의 경우 조선 산업과 자동차 산업의 동향 및 주요 거래선의 경영 현황 등을 파악하고 분석 기회 도출
- **채널** : 영업사원, 직판 대리점, 홈페이지 등의 자체적으로 운영하는 채널뿐만 하니라 최종 고객에게 상품/서비스를 전달하는 것에 가능한 경로를 파악하여 해당 경로에 존재하는 채널별로 분석 기회를 확대하여 탐색 // 은행의 경우 인터넷 전문은행 등 온라인 채널의 등장에 따른 변화에 대한 전략 분석 기회 도출
- **인플루언서** : 기업 의사결정에 영향을 미치는 주주/투자자/협회 및 기타 이해 관계자의 주요 관심사항에 대해서 파악하고 분석 기회를 탐색 // M&A 시장 확대에 따른 유사 업종의 신규 기업 인수 기회 탐색
(4) 역량의 재해석 관점
- 현재 해당 조직 및 기업이 보유한 역량 뿐만 아니라 해당 조직의 비즈니스에 영향을 끼치는 파트너와 네트워크를 포함한 활용 가능한 역량을 토대로 폭넓은 분석 기회 탐색
- **내부역량(Comprtency)** : 지적 재산권, 기술력 등 기본적인 것 뿐만 아니라 중요하면서도 자칫 간과하기 쉬운 지식, 기술 등의 노하우와 인프라적인 유형 자산에 대해서 재해석하고 해당영역에서 분석 기회를 탐색 // 자사 소유 부동산을 활용한 부가 가치 창출 기회 발굴
- **파트너와 네트워크(Partner&Network)** : 자사가 직접 보유하고 있지는 않지만 밀접한 관계를 유지하고 있는 관계사와 공급사등의 역량을 활용해 수행할 수 있는 기능을 파악, 이에 대한 분석 기회 도출 // 수출입/통관/노하우를 활용한 추가 사업기회 탐색

다) 외부참조 모델기반 문제탐색
- 유사/동종 사례에 대한 벤치마킹을 통한 분석기회 발굴은 제공되는 산업별, 업무 서비스별 분석 테마 후보 그룹(pool)을 통해 "Quick & Easy" 방식으로 필요한 분석기회가 무엇인지에 대한 아이디어를 얻고 기업에 적용할 분석 테마 후보 목록을 워크숍 형태의 브레인스토밍(Brain storming)을 통해 빠르게 도출하는 방법이다
- 현재 환경에서는 데이터를 활용하지 않은 업종 및 업무 서비스가 사실상 존재하지 않기 때문에 데이터 분석을 통한 인사이트를 도출하고 업무에 화룡ㅇ하는 사례들을 발굴하고, 자사의 업종 및 업무서비스에 적용하며 평상시 지속적인 조사와 데이터 분석을 통한 가치 발굴 사례를 정리하여 풀(Pool)로 만들어 둔다면 과제 발굴 및 탐색 시 빠르고 의미있는 분석 기회도출이 가능함

라) 분석 유즈 케이스(Analytics Use Case)
- 현재의 비즈니스 모델 및 유사/동종사례 탐색을 통해서 빠짐없이 도출한 분석 기회들을 구체적인 과제로 만들기 전에 분석 유즈케이스로 표기하는 것이 필요
- 분석 유즈케이스는 풀어야 할 문제에 대한 상세한 설명과 해당 문제를 해결했을 때 발생하는 효과를 명시함으로써 향후 데이터 분석 문제로의 전환 및 적합성 평가에 활용하도록 함

2) 문제정의 단계
- 식별된 비즈니스 문제를 데이터의 문제로 변환하여 정의하는 단계. 앞서 수행한 문제 탐색의 단계가 무엇을(What)어떤 목적으로 (Why) 수행해야 하는지에 대한 관점이었다면 본 단계에서는 이를 달성하기 위해서 필요한 데이터 및 기법(How)을 정의하기 위한 데이터 분석의 문제로의 변환을 수행
//예시, 비즈니스 문제를 데이터의 문제로 변환
'고객 이탈의 증가'라는 비즈니스 문제는 '고객 이탈에 영향을 미치는 요인을 식별하고 이탈 가능성을 예측'하는 데이터 분석 문제로 변환될 수 있다.
- 데이터 분석 문제의 정의 및 요구사항 : 분석을 수행하는 당사자뿐만 아니라 해당 문제가 해결되었을 때 효용을 얻을 수 있는 최종 사용자(End User) 관점에서 이루어져야 함
- 데이터 분석 문제가 잘 정의되었을 때 필요한 데이터의 정의 및 기법 발굴이 용이하기 때문에 가능한 정확하게 분석의 관점으로 문제를 재정의할 필요가 있다

| 비즈니스 문제                                  | 변환  | 분석 문제                                                  |
| ---------------------------------------- | --- | ------------------------------------------------------ |
| 고객 이탈 증대                                 | >   | 고객의 이탈에 영향을 미치는 요인을 식별하고 이탈 가능성 예측                     |
| 설비 장애로 인한 판매량 감소                         | >   | 설비의 장애를 이끄는 신호를 감지하여 설비 장애 요인으로 식별하고 장애 발생 시점 및 가능성 예측 |
| 기존 정보 기반 영업사원의 판단 시 재고 관리 및 적정 가격 판매 어려움 | >   | 내부 판매 정보 외의 수요 예측을 수행할 수 있는 인자의 추출 및 모델링을 통한 수요 예측     |

3) 해결방안 탐색 단계
- 이 단계에서는 정의된 데이터 분석 문제를 해결하기 위한 다양한 방안이  모색됨
	가) 기존 정보 시스템의 단순한 보완으로 분석이 가능한지 고려
	나) 엑셀 등의 간단한 도구ㅗ 분석이 가능한지 고려
	다) 하둡 등 분산병렬처리를 활용한 빅데이터 분석 도구를 통해 보다 체계적이고 심도 있는 방안 고려
![[Pasted image 20240314160531.png]]
- 분석 역량을 기존에 가지고 있는지의 여부를 파악하여 보유하고 있지 않은 경우에는 교육이나 전문 인력 채용을 통한 역량을 확보하거나 분석 전문 업체를 활용하여 과제를 해결하는 방안에 대해 사전 검토를 수행

4) 타당성 검토(Feasibility Study)
- 도출된 분석 문제나 가설에 대한 대안을 과제화하기 위해서는 다음과 같은 다각적인 타당성 분석이 수행되어야 함
	가) 경제적 타당성
	- 비용대비 편익 분석 관점의 접근 필요. 비용 항목은 데이터/시스템/인력/유지보수 등과 같은 분석 비용으로 구성되고, 편익으로는 분석 결과를 적용함으로써 추정되는 실질적 비용 절감, 추가적 매출과 수익 등과 같은 경제적 가치로 산출됨
	나) 데이터 및 기술적 타당성
	- 데이터 분석에서는 데이터 존재 여부, 분석 시스템 환경, 분석 역량이 필요함. 특히 분석 역량의 경우 실제 프로젝트 수행 시 걸림돌이 되는 경우가 많이 때문에 기술적 타당성 분석 시 역량 확보 방안을 사전에 수립하고 이를 효과적으로 평가하기 위해서는 비즈니스 지식과 기술적 지식이 요구됨
	- 위의 타당성 검토를 통해 도출된 대안으로
		1)평가 과정을 거쳐 가장 우월한 대안 선택
		2)도출한 데이터 분석 문제 및 선정된 솔루션 방안을 포함
		3)분석과제 정의서의 형태로 명시하는 후속 작업 시행
		4)프로젝트 계획의 입력물로 활용

다. 상향식 접근법(Bottom up Approach)
1) 정의
- 상향식 접근 방법은 현황 분석을 통한 문제 탐색으로부터 시작해 분석 과제를 도출하는 전통적인 하향식 문제 해결 방식과는 다르게 기업에서 보유하고 있는 다양한 원천 데이터(Big Data)로 부터의 분석을 통하여 통찰력과 지식을 얻는 방법
- 다양한 원천 데이터를 대상으로 분석을 수행하여 가치있는 모든 문제를 도출하는 일련의 과정

2) 기존 하향식 접근법의 한계를 극복하기 위한 분석 방법론
- 기존 접근방법인 하향식 접근법은 문제의 구조가 명확하고 문제 해결안 도출과 관련된 권한이 데이터 분석가 및 의사결정자에게 주어져 있음을 가정하고 있기 때문에 해결방안 도출에는 유효한 논리적인 방법이지만 새로운 문제를 탐색하기에는 어느 정도 한계가 존재
- 따라서 하향식 접근법에 기반한 문제해결 방식은 최근 복잡하고 다양한 환경에서 발생하는 문제에는 적합하지 않을 수 있다.
- 이를 해결하기 위해서 스탠포드 대학의 D-school은 디자인 사고 접근법을 통해서 전통적인 분석적 사고를 극복하려고 한다
- 통상적인 관점에서는 분석적으로 사물을 인식하려는 'Why'를 강조하지만, 이는 우리가 알고 있다고 가정하는 것이기 때문에 문제와 맞지 않는 솔루션인 경우 오류가 발생할 소지가 있다 그렇기 때문에 답을 미리 내는 것이 아니라 사물을 있는 그대로 인식하는 'What' 관점에서 보아야 함
- 객관적으로 존재하는 데이터 그 자체를 관찰하고 실제적으로 행동에 옮김으로써 대상을 좀 더 잘 이해하는 방식으로의 접근을 수행하는 것
- 이와 같은 점을 고려하여 D-school에서는 첫 단계로 감정이입을 특히 강조
- ![[Pasted image 20240314162821.png]]

3) 비지도 학습과 지도학습 *구분, 특징 숙지* 
	가) 비지도 학습(Unsupervised Learning)
	- 일반적으로 상향식 접근 방식의 데이터 분석은 비지도 학습 방법에 의해 수행됨
	- 비지도 학습은 데이터 분석의 목적이 명확히 정의된 형태의 특정 필드의 값을 구하는 것이 아니라 데이터 자체의 결합/연관성/유사성 등을 중심으로 데이터의 상태를 표현하는 것
	- 비지도 학습의 데이터 마이닝 기법의 예로 장바구니 분석, 군집 분석, 기술 통계 및 프로파일링 등이 있음
	- 군집 분석 = 비지도 학습
	- 목표 값을 사전에 정의하지 않고 데이터 자체만을 가지고 그룹들을 도출함으로써 해석이 용이하지는 않지만 새로운 유형의 인사이트를 도출하기에 유용한 방식으로 활용할 수 있다.
	나) 지도 학습(supercised Learning)
	- 명확한 목적 하에 데이터 분석을 실시하는 것. 분류/추측/예측/최적화를 통해 사용자의 주도하에 분석을 실시하고 지식을 도출하는 것이 목적
	- 분류분석 = 지도학습
	- 결과로 도출되는 값에 대하여 사전에 인지하고 어떠한 데이터를 넣었을 때 어떠한 결과가 나올 지를 예측하는 것
	- 통계 분석에서는 인과관계 분석을 위해 가설을 설정하고 모집단으로부터 추출한 표본을 이용해 가설을 검정하는 방식으로 문제 해결
	- 그러나 빅데이터 환경에서는 인과관계 분석뿐만 아니라 상관관계 부넉 또는 연관분석을 통하여 다양한 문제 해결에 도움을 받을 수 있다
	- 인과관계분석으로부터 상관관계분석으로의 이동이 빅데이터 분석에서의 주요 변화라 할 수 있다. 다량의 데이터 분석을 통해서 '왜'그러한 일이 발생하는지 역으로 추적하면서 문제를 도출하거나 재정의할 수 있는 접근 방식

4) 시행착오를 통한 문제해결(프로토타이핑 방법론) *개념, 자주 사용되는 이유 숙지*
	가) 정의
	- 프로토타이핑(Prototyping) 방법론은 사용자가 요구사항이나 데이터를 정확히 규정하기 어렵고 데이터 소스도 명확히 파악하기 어려운 상황에서 일단 분석을 시도해 보고 그 결과를 확인해 가면서 점진적으로 개선해 나가는 방법을 말한다.
	- 하향식 접근방식이 문제가 정형화되어 있고 문제해결을 위한 데이터가 완벽하게 존재할 경우에 효과적인 반면 프로토타이핑 방법론은 데이터 ㅂ누석 환겨이 완벽하게 갖추어 지지 않은 경우에도 활용 가능
	- 즉, 프로토타이핑 방법론은 비록 완전하지는 못하더라도 신속하게 해결책이나 모형을 제시함으로써 이를 바탕으로 문제를 좀 더 명확하게 인식하고 필요한 데이터를 식별하여 구체화하는데 유용한 상향식 접근 방식
	- 프로토타이핑 방법론의 기본적인 프로세스는 가설의 생성, 디자인에 대한 실험, 실제 환경에서의 테스트, 테스트 결과에서의 인사이트 도출 및 가설 확인으로 구성됨
	나) 빅데이터 분석 환경에서 프로토타이핑의 필요성
		1) 문제에 대한 인식 수준
		- 문제 정의가 불명확하거나 이전에 접해보지 못한 새로운 문제알 경우 사용자 및 이해관계자는 프로토타입을 이용하여 문제를 이해하고 이를 바탕으로 구체화하는데 도움을 받을 수 있다.
		2) 필요 데이터 존재 여부의 불확실성
		- 문제 해결을 위해 필요한 데이터 집합이 모두 존재하지 않을 경우, 그 데이터의 수집을 어떻게 할 것인지 또는 그 데이터를 다른 데이터로 대체할 것인지 등에 대한 사용자와 분석가 간의 반복적이고 순환적인 협의 과정이 필요. 대체 불가능한 데이터가 존재하는지 사전에 확인한다면 불가능한 프로젝트를 수행하는 리스크를 사전에 방지 가능
		3) 데이터 사용 목적의 가변성
		- 데이터 가치는 사전에 정해진 수집 목적에 따라 확정되는 것이 아니라 지속적으로 변화할 수 있다 따라서 조직에서 보유 중인 데이터라 하더라도 기존의 데이터 정의를 재검토하여 데이터의 사용 목적과 범위를 확대할 수 있다
		// 예시. 데이터의 사용 목적과 범위의 확대
		이동통신사 사용자 위치 추적. 서울시 야간버스 올빼미 버스

라. 수요 기반 vs 데이터 주도 분석과제 도출
- 분석과제 도출에 대한 최근의 접근방법에는 수요 기반 방식(Demand-Pull Approach)과 데이터 주도 방식(Data-Driven Approach)이 있다

비즈니스 이슈 및 문제 --수요 기반 분석과제 고출-->
				<--데이터 주도 분석 과제 도출-- 데이터 및 분석 기법

1) 수요 기반 분석과제 도출
- 기업 및 조직들은 운영 및 생산 비용 절감, 효율성 향상, 의사결정 최적화 등 비즈니스 이슈들을 해결하고자 하는 노력을 꾸준히 하고 있다
- 수요기반 분석과제 도출은 이러한 비즈니스 이슈 해결을 위한 근본적 원인에 대한 근거를 제시하고, 기업에서 도출한 해결방안의 실현 가능성에 대한 판단을 위해 데이터를 수집/가공/분석하는 과정을 거치는 일련의 접근 방법을 의미
- 먼저 해결해야하는 이슈 및 문제를 정의한 후 이에 대한 원인 진단 및 해결 방안 도출을 실행하는 것으로 일련의 시나리오를 수립하는 과정이 선행된다
- 문제 해결 시나리오를 먼저 정의하고 이에 적합한 내/외부 데이터 탐색 및 분석 기법 매칭 진행

2) 데이터 주도 분석 과제 도출
- 과거 기업 데이터는 거래 처리 데이터 및 RDBMS에서 처리되는 정형 데이터였지만 최근에는 음성 및 영상 데이터 등의 정형/비정형 데이터가 다양하게 생성 및 수집되고 있다 또한 이에 적합한 새로운 분석 기법들이 등장함으로써 데이터 분석을 위해 다양한 실험적 시도를 해볼 수 있다
- 데이터 주도 분석 과제 도출은 다양한 데이터 원천의 조합과 통합적 및 시각화 분석을 통해 의미 있는 패턴을 파악하고 이를 업무에 적용함으로써, 기존 업무 수행 방식에 대한 이해도 및 효율성을 향상시키며 새로운 관점에서 경영 이슈 및 문제의 해결을 가능하게 해주는 일련의 접근방법
- 정형화된 분석기법이 아닌 다양한 분석기법의 조합 및 상호 연관성 분석 등을 통해 기존의 분석기법에서는 고려조차 하지 않은 다양한 파생정보를 파악할 수 있다. 즉 데이터를 통해 숨어 있는 패턴/정보/통찰을 추출해낼 수 있는 방법이다

3) 수요 기반 분석 과제와 데이터 주도 분석 과제와의 관계
- 일반적으로는 비즈니스 이슈 및 문제에 대한 정의를 토대로 분석 방법을 결정하고 분석을 진행하는 수요 기반 방식이 많이 활용됨
- 하지만 틀에 박힌 분석 방법만을 활용하기 보다는 빅데이터 자체의 가치에 대한 분석을 통해 역으로 업무 수행에 접목할 수 있도록 분석을 지원하는 데이터 주도 방식을 병행함으로써 비즈니스 운영에 대한 시각을 확대할 수 있다. 따라서 두 접근법의 상호 연결고리를 가질 필요가 있다

마. 분석 과제 정의
- 데이터 분석 문제와 관련된 관계자들이 과제의 내용을 명확히 이해하고 프로젝트로 수행할 수 있도록 분석 과제 정의서를 도출
- 분석과제 정의서에는 분석별로 필요한 소스테이터, 분석 방법, 데이터 입수 및 분석의 난이도와 사유, 분석 수행 주기, 분석 결과 검증 책임자 등을 기술
- 분석 데이터 소스는 내/외부의 비구조적인 데이터와 소셜미디어, 오픈 데이터까지 범위를 확정하여 고려하고, 분석 방법 또한 상세하게 정의한다

### 데이터 분석 방안
가. 분석 방법론 개요
1) 개요
 - 데이터 분석이 효과적으로 기업 내에 정착하기 위해서는 이를 체계화한 절차와 방법이 정리된 데이터 분석 방법론의 수립이 필수적
 - 프로젝트는 한 개인의 역량이나 조직의 우연한 성공에 기인해서는 안 되고 일정한 수준의 품질을 갖춘 산출물과 프로젝트의 성공 가능성을 확보하고 제시할 수 있어야 한다
 - 방법론의 상세한 절차, 방법, 도구와 기법, 템플릿과 산출물로 구성되어 어느정도의 지식만 있으면 활용이 가능해야 함

2) 데이터 기반 의사결정의 필요성
- 데이터 기반 의사결정은 급변하는 현실 상황을 감안할 때 더 이상 개인의 경험과 감에 의존하는 의사결정이 아닌 사실에 입각한 데이터에 기반한 경영의 추구를 위한 개념. 즉 현실 문제를 과학적인 방법으로 최적의 솔루션을 도출하고 이를 토대로 의사결정을 내리는 것
- 기업의 합리적 의사결정을 가로막는 장애요소로 고정 관념, 편향된 생각, 프레이밍 효과(문제의 표현 방식에 따라 동일한 사건이나 상황임에도 불구하고 개인의 판단이나 선택이 달라질 수 있는 현상) 등이 있다

3) 방법론의 생성 과정
- 방법론은 학습과 경험으로 개인에게 체화되어 겉으로는 드러나지 않는 암뭇지가 형식화를 통해 문서나 매뉴얼처럼 외부로 표출되어 여러 사람이 공유할 수 있는 형식지로 나타나고 이 과정을 짜임새 있게 조직화한 방법론을 개인은 학습과 경험을 하는데 활용하는 순환과정으로 생성됨
- ![[Pasted image 20240314174053.png]]

4) 방법론의 적용 업무의 특성에 따른 모델
	가) 폭포수 모델(Waterfall Model)
	- 고전적 수명주기라고도 하는 전통적인 개발모델로 요구분석, 설계, 구현, 테스트, 유지보수의 각 단계가 하향식으로 진행되며 병행되거나 거슬러 반복되지 않는 방법
	- 각 단계가 끝날 때마다 그 결과를 확인한 후에 다음 단계로 진행될 수 있으며, 관리가 용이하고 체계적인 문서화가 가능하다
	나) 프로토타입 모델(Prototype Model)
	- 폭포수 모델의 단점을 보완하기 위해 점진적으로 개발해 나가는 접근 방식으로, 사용자 요구를 완전히 이해하지 못하거나 완벽한 요구분석의 어려움을 해결하기 위해 사용자의 기본적 요구사항에 따른 프로토타입을  신속히 개발하여 사용자의 의견을 바탕으로 개선하고 보완해 가는 모델
	- 프로토 타입을 활용한 사용자와의 의사소통을 통해 요구사항 도출의 어려움을 해결하고, 개발의 타당성을 점검하고 성능을 평가 할 수 있다
	다) 나선형 모델(spiral Model)
	- 진화적 프로토타입 모델의 대표적 형태로 사용자의 초기 요구분석 후 위험분석 단꼐를 거쳐 프로토타입 개발하고, 사용자 평가 후 추가 또는 수정 요구를 받아들여 다시 위험분석을 거쳐 2차 프로토타입을 만든다. 이와 동일한 과정을 수차례 거치는 동안 사용자의 요구가 충분히 반영되어 만족할만한 결과물이 산출된다
	- 폭포수 모델과 프로토타입 모델의 장점에 위험분석 단계를 추가하여 위험에 대한 문제를 식별하고 그 해결방법을 강조한 반복적 개발 모델
	- 처음 시도하는 프로젝트에 적용이 용이하지만 관리 체계를 효과적으로 갖추지 못한 경우에는 복잡도가 상승하여 프로젝트 진행이 어려울 수있다

5) 빅데이터 분석 방법론의 계층적 프로세스
![[Pasted image 20240315084923.png]]
가) 단계(Phase)
- 프로세스 그룹(Process Group)을 통하여 완성된 단계별 산출물이 생성되며, 각 단계는 기준선(Baseline)으로 설정되어 관리되어야 하고 버전 관리(Configuration management)등을 통하여 통제가 이루어져야 한다

나) 태스크(Task)
- 각 단계는 여러 개의 태스크로 구성되며, 각 태스크는 단계를 구성하는 단위 활동으로 물리적 또는 논리적 단위로 품질 검토의 항목이 될 수 있다

다) 스텝(Step)
- WBS(Work Breakdown Structure)의 워크 패키지에 해당되고 입력자료, 처리및 도구, 출력자료로 구성된 단위 프로세스이다

나. 일반적인 빅데이터 분석 방법론 *단계의 내용, 순서, 방향의 의미까지 학습*
- ![[Pasted image 20240315085658.png]]

1) 분석기획
- 비즈니스 도메인과 문제점을 인식하고 분석 계획 및 프로젝트 수행계획을 수립
- 프로젝트 수행시 발생가능한 위험 상황에 대처하기 위한 계획도 함께 수립할 수 있다

2) 데이터 준비
- 비즈니스 요구사항과 데이터 분석에 필요한 원천 데이터를 정의하고 준비하는 단계
- 필요한 데이터를 수집하고 수집한 데이터에 대한 정합성을 점검

3) 데이터 분석
- 원천 데이터를 분석용 데이터 셋으로 편성하고 다양한 부석 기법과 알고리즘을 이용하여 데이터를 분석하는 단계
- 분석 모델을 설정하고, 설정된 모델을 평가하며, 검증된 모델을 이용하여 데이터 분석을 수행
- 분석 단계를 수행하는 과정에서 추가적인 데이터 확보가 필요한 경우 데이터 준비 단계로 피드백하여 두 단계를 반복하여 진행

4) 시스템 구현
- 분석 기획에 맞는 모델을 도출하고 이를 운영중인 가동 시스템에 적용하거나 시스템 개발을 위한 사전 검증으로 프로토 타입 시스템 구현
 - 프로토 타입을 통해 검증한 후 시스템 수정 및 보완을 반복하여 최종 시스템 구현

5) 평가 및 전개
- 데이터 분석 및 시스템 구현 단계를 수행한 후 프로젝트의 성과를 평가하고 정리하거나 모델의 발전 계획을 수립하여 차기 분석 기획으로 전달하고 프로젝트를 종료하는 단계

다. KDD 분석방법론
1) 개요
- KDD(Knowledge Discovery in Databases) 는 1996년 Fayyad가 프로파일링 기술을 기반으로 데이터로부터 통계적 패턴이나 지식을 찾기 위해 활용할 수 있도록 체계적으로 정리한 데이터 마이닝 프로세스로 데이터마이닝/기계학습/인공지능/패턴인식/데이터 시각화 등에서 응용될 수 있는 구조를 갖고 있다

2) KDD분석 절차
![[Pasted image 20240315090658.png]]

가) 데이터셋 선택
- 분석 대상의 비즈니스 도메인에 대한 이해와 프로젝트 목표 설정이 완료된 상태라면, 그 이후 첫 단계는 데이터 베이스 또는 원시 데이터에서 분석에 필요한 데이터를 선택하는 것
- 데이터 마이닝에 필요한 목표데이터(Target data)를 구성하여 분석에 활용

나) 데이터 전처리
- 추출된 분석 대상용 데이터셋에 포함되어 있는 잡음과 이상치, 결측치를 식별하고 필요시 제거하거나 의미 있는 데이터로 재처리하여 데이터셋을 정제하는 과정
- 데이터 전처리 단계에서 추가로 요구되는 데이터셋이 파악된다면, 데이터셋 선택 프로세스를 재실행한 후 전처리 과정을 수행

다) 데이터 변환
- 데이터 전처리 과정을 통해 정제된 데이터셋에서 분석 목적에 맞게 변수를 생성, 선택하고 데이터의 차원을 축소하여 효율적인 데이터 마이닝을 실행할 수 있도록 데이터를 변경하는 단계
- 데이터 마이닝 프로세스를 진행하기 위해 학습용데이터와 검증용 데이터로 데이터를 분리하는 과정도 포함

라) 데이터 마이닝
- 학습용 데이터를 이용해서 분석 목적에 맞는 데이터 마이닝 기법을 선택하고 적절한 알고리즘을 적용하여 데이터 마이닝 작업을 실행하는 단계
- 필요에 따라 데이터 전처리와 데이터 변환 프로세스를 추가로 실행하여 최적의 결과를 산출

마) 데이터 마이닝 결과 평가
- 데이터 마이닝 결과에 대한 해석과 평가, 분석 목적과의 일치성 확인
- 데이터 마이닝을 통해 발견한 지식을 업무에 활용하기 위한 방안을 마련하는 단계
- 필요에 따라 데이터에 선택 프로세스에서 데이터 마이닝 프로세스를 반복 수행

라. CRISP-DM 분석 방법론
1) 개요
- CRISP-DM(Cross Industry Standard Process fot Data Mining)은 1996년 유럽연합의 ESPRIT에서 있었던 프로젝트에서 시작되었으며, 주요한 5개의 업체들이 주도. CRISP-DM은 계층적 프로세스 모델로써 4개의 레벨로 구성됨

2) CRISP-DM의 4레벨 구조![[Pasted image 20240315091959.png]]
- 최상위 레벨은 여러 개의 단계로 구성되고 각 단계는 일반화 태스크를 포함함. 일반화 태스크는 데이터 마이닝의 단일 프로세스를 완전하게 수행하는 단위이며, 일반화 태스크는 구체적으로 수행하는 레벨인 세분화 태스크로 구성된다.
- 예를 들어 데이터정제라는 일반화 태스크에는 범주형 데이터 정제와 연속형 데이터 정제와 같은 세분화 태스크로 구성된다
- 마지막 레벨인 프로세스 실행은 데이터 마이닝을 위한 구체적 실행을 포함한다

3) CRISP-DM의 프로세스
- CRISP-DM 프로세스는 6단계로 구성되어 있으며 각 단계는 KDD 방법론과는 달리 단방향으로 구성되어 있지않고 단계 간 피드백을 통하여 단계별 완성도를 높이게 되어 있다
![[Pasted image 20240315094727.png]]

| 단계     | 내용                                                                                                                                                                                                              | 수행업무                                                |
| ------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |
| 업무이해   | - 비즈니스 관점에서 프로젝트의 목적과 요구사항을 이해하기 위한 단계<br>- 도메인 지식을 데이터 분석을 위한 문제정의로 변경하고 초기 프로젝트 계획을 수립하는 단계                                                                                                                   | 업무 목적 파악, 상황 파악, 데이터 마이닝 목표 설정, 프로젝트 계획 수립          |
| 데이터 이해 | - 분석을 위한 데이터를 수집하고 데이터 속성을 이해하기 위한 과정<br>- 데이터 품질에 대한 문제점을 식별하고 숨겨져 있는 인사이트를 발견하는 단계                                                                                                                            | 초기 데이터 수집, 데이터 기술 분석, 데이터 탐색, 데이터 품질 확인             |
| 데이터 준비 | - 분석을 위하여 수집된 데이터에서 분석 기법에 적합한 데이터를 편성하는 단계(많은 시간이 소요될 수 있음)                                                                                                                                                    | 분석용 데이터 셋 선택, 데이터 정제, 분석용 데이터 셋 편성, 데이터 통합, 데이터 포맷팅 |
| 모델링    | - 다양한 모델링 기법과 알고리즘을 선택하고 모델링 과정에서 사용되는 파라미터를 최적화해 나가는 단계<br>- 모델링 과정에서 데이터 셋이 추가로 필요한 경우 데이터 준비 단계를 반복 수행, 모델링 결과를 태스크용 데이터 셋으로 평가하여 모델의 과적합의 문제를 확인                                                            | 모델링 기법 선택, 모델 테스트 계획 설계, 모델 작성, 모델 평가               |
| 평가     | - 모델링 결과가 프로젝트 목적에 부합하는지 평가하는 단계로 데이터 마이닝 결과에 최종적으로 수용할 것인지 판단                                                                                                                                                  | 분석결과 평가, 모델링 과정 평가, 모델 적용성 평가                       |
| 전개     | - 모델링과 평가 단계를 통하여 완성된 모델은 실 업무에 적용하기 위한 계획 수립<br>- 모니터링과 모델의 유지보수 계획 마련 > 모델은 적용되는 비즈니스 도메인 특성, 입력되는 데이터의 품질 편차, 운영모델의 평가기준에 따라 생명주기가 다양하므로 상세한 전개 계획이 필요<br>- CRISP-DM의 마지막 단계, 프로젝트 종료 관련 프로세스를 수행하여 프로젝트 마무리 | 전개 계획 수립, 모니터링과 유지보수 계획 수립, 프로젝트 종료 보고서 작성, 프로젝트 리뷰 |

마. KDD와 CRISP-DM의 단계 비교 *각 단계에 포함되는 유사 과업, 각 단계 과업과 매치*

| KDD           | CRISP-DM |
| ------------- | -------- |
| 분석대상 비즈니스 이해  | 업무 이해    |
| 데이터셋 선택       | 데이터의 이해  |
| 데이터 전처리       | 데이터의 이해  |
| 데이터 변환        | 데이터 준비   |
| 데이터 마이닝       | 모델링      |
| 데이터 마이닝 결과 평가 | 평가       |
| 데이터 마이닝 활용    | 전개       |

바. SEMMA 분석 방법론
1) 개요
- SEMMA(Sampling Exploration Modification Modeling Assessmant)은 SAS사의 주도로 만들어진 데이터 마이닝 방법론으로 기술 중심통계 중심의 방법론. 자사의 기술로 데이터 마이닝 기능을 구성하여 쉽게 데이터 마이닝이 되도록 하는 특징이 있다
- 주요 5단계는 샘플링 > 탐색 > 수정 > 모델링 > 검증으로 이루어져 있다

2) SEMMA 분석 절차

| 단계  | 내용                                                        | 세부요소/산출물                            |
| --- | --------------------------------------------------------- | ----------------------------------- |
| 샘플링 | 분석 데이터의 생성<br>모델평가용 데이터 준비                                | 통계적 추출<br>조건 추출                     |
| 탐색  | 분석 데이터 탐색<br>데이터 오류 검색<br>비즈니스에 대한 이해<br>이상 현상 및 변화 탐색    | 그래프, 기초통계<br>클러스터링<br>변수 유의성 및 상관분석 |
| 수정  | 분석 데이터 수정 및 변환<br>데이터 정보 표현의 극대화<br>다양한 형태의 변수 생성, 선택, 변형 | 수량화<br>표준화<br>변환<br>그룹화             |
| 모델링 | 다양한 통계 기법을 이용한 모델 구축<br>패턴 발견<br>모델링과 알고리즘 적용             | 신경망<br>의사결정나무<br>로지스틱 회귀<br>통계기법    |
| 검증  | 모델 평가 및 검증<br>서로 다른 모델 동시 비교<br>다음단계(추가 분석) 결정            | 보고서<br>피드백<br>모델 검증 자료              |

## 분석 작업 계획

### 데이터 확보 계획
가. 데이터 확보 계획 수립 절차 및 단계별 유의 사항 *고려 사항 숙지*
- 빅데이터 분석 목표에 맞는 데이터 확보 계획을 수립하기 위해서 체계적인 절차가 필요
- 데이터 확보 계획은 데이터 분석이 왜 필요한지(목표 정의) > 어떠한 데이터가 필요한지(요구사항 도출) > 어떤 방법으로 데이터를 확보할 것인지(예산안 수립) > 어떻게 진행할 것인지(구체적 계획 수립)의 과정으로 이어진다

1) 목표 정의
- 구체적인 성과 목표를 정의함
- 성과목표 달성 여부를 측정하기 위한 성과 지표를 개발함

2) 요구사항 도출
- 요구사항을 반영하여 필요 데이터에 대한 확보 계획을 설정
- 데이터의 전처리 및 정제 수준, 데이터의 저장 및 관리 형태를 정의함
- 기존의 시스템 및 분석 도구에 대한 활용 가능성을 파악하고, 필요한 경우 추가적으로 장비 및 서비스 이용에 대한 계획안을 마련함

3) 예산안 수립
- 데이터 확보에 필요한 비용 계산
- 데이터 확보 및 관리 등에 필요한 하드웨어, 소프트 웨어 운영 예산안 수립
- 인력 및 관리 예산을 비롯하여 외부 컨설팅 비용 등을 고려

4) 계획 수립
- 일반적인 프로젝트 관리 방침을 기반으로 인력 및 자원 활용에 대한 방안 마련
- 추진 일정 수립 시 프로젝트 범위 정의서(SOW)와 빅데이터 분석 프로젝트 지시서, 소요비용 배분계획 등을 중심으로 데이터 분석 작업 절차를 고려하는 것이 바람직함
- 위험 관리 및 데이터의 품질 관리 방안과 원활한 커뮤니케이션 실행 방안을 마련

나. 확보해야 할 분석 데이터에 대한 이해
- 분석 데이터 확보를 위해서는 우선적으로 수집 대상 데이터의 유형을 고려해야 함
- 데이터 유형에 따라 이용하는 통계분석 기법이 달라지므로 분석 목표를 달성하기 위해 어떤 데이터를 이용하고, 어떤 분석 기법을 사용하여 분석을 수행할 것인지, 계획에 따라 데이터의 유형을 선택하고 분석 변수를 정의하도록 함
- 분석에 사용되는 데이터는 형태에 따라 정형데이터와 비정형/반정형 데이터로 분류됨

다. 빅데이터 분석 데이터에 대한 이해
- 효과적인 빅데이터 분석을 위해서는 요구 정의에서 도출된 활용 시나리오에 적용할 수 있는 다양한 분석 데이터셋을 수립할 수 있다면 보다 의미 있는 분석 결과를 도출할 수 있다

1) 빅데이터 분석 데이터 셋
- 빅데이터 분석을 위한 분석변수 데이터와 분석결과 검증을 위한 데이터의 집합
- 기존의 빅데이터 분석은 일반적으로 테스트용과 검증용 2개의 데이터셋으로 구성된 데이터 집합을 통해 분석하고 결과를 검증하여 왔다. 하지만 최근에는 인공지능 학습과 융합하여 빅데이터 분석을 하는 경우가 증가함으로써, 현재는 학습용 셋을 활용하여 총 3종류로 구분된 데이터셋을 활용하는 것이 더욱 일반적임

| 구분             | 내용                                      |
| -------------- | --------------------------------------- |
| Training Set   | 모형 구축을 위해 학습에 사용되는 데이터 집합               |
| Test Set       | 구축된 모형의 성과 평가에 사용되는 데이터 집합              |
| Validation Set | 최적 모형을 선택하기 위해 각 모형의 성과 평가에 사용되는 데이터 집합 |

2) 분석 데이터셋의 활용
- 분석 결과의 일반화 요류를 예방하기 위하여 교차타당성 검증(Cross validation) 기법을 적용하여 Test Set, Validation Set, Training Set를 혼합하여 빅데이터 분석 변수로 활용함

| 구분     | 내용                                                 |
| ------ | -------------------------------------------------- |
| 데이터 분리 | Training Set, Test Set와 Validation Set가 섞이지 않도록 분리 |
| 교차 반복  | Data Set를 교차 반복 측정                                 |

라. 데이터 확보 계획 시 주요 단계
(1) 분석 변수 및 필요 데이터 정의
(2) 분석 변수 출처 확인 및 생성 프로세스 정의

1) 활용 시나리오에 맞는 빅데이터 분석에 필요한 분석 변수 및 데이터를 정의

기업 내부 데이터(ERP, CRM, SCM, MES 등)----------
										 | -> 분석 데이터 확보
외부 데이터(데이터 거래소 / 공공데이터)------------

가) 기업내부/외부 시스템의 데이터를 수집
- 데이터 수집 기법을 활용하여 필요 데이터를 배치 자동화 수집한다
	(1) 데이터 수집 타깃 시스템 또는 사이트를 선별함
	(2) 수집 대상 화면, 텍스트를 위해 인덱스 생성을 기획
	(3) 대상 시스템 별 데이터 수집을 위한 크롤러를 준비하고 저장소를 기획함
	(4)크롤링 주기, 대상 범위를 확정하고 데이터 수집을 기획

- 데이터 거래소, 공공 데이터에 적재된 분야별 데이터를 분류하고 식별함
	(1) 공공 데이터 사이트에 접속하여 필요한 도메인의 데이터를 검색
	(2) 검색한 공공 데이터 중 분석 대상이 되는 도메인의 우선 순위를 정의
	(3) 필요한 데이터를다운로드 받아 저장할 수 있도록 계획
	(4) 저장한 데이터를 NoSQL 데이터에 적재할 수 있도록 설계
	(5) NoSQL에 적재한 데이터를 정제할 수 있도록 기획

나) 빅데이터의 특징과 분석 요건 정의에 따라 도출된 분석 항목을 고려하여 분석 변수를 정의
- 빅데이터의 특징, 즉 용량/다양성/속도/정확성/시각화/가치 및 연속형 또는 범주형 데이터를 고려하여 분석 변수를 정의
- 변수의 유형 및 형성 알고리즘을 이용하여 분석 유형을 도출
// 참고. 분석 변수 유형에 따른 형성 알고리즘
- 범주형(빈도수 기반) : 카이제곱 검정에 대한 P값, 지니 지수, 엔트로피
- 연속형(통계적 접근) : 분산 분석에서의 F-검정, 분산의 감소량 등

2) 변수의 출처를 확인하고 목적에 적합한 분석 변수를 생성할 수 있는 프로세스를 정의
가) 사실 중심의 문제접근을 통해 분석 변수를 정의
- 가정에 의한 Why 접근 방법과 문제의 본질이 무엇인지를 파악하는 What 관점을 함께 사용하여 객관적 관팔 데이터 유형을 식별
// 예시. Fact 기반 분석 변수 도출 예시
1) 디자인 사고를 통한 시각적/행위적 접근법 활용
2) 존재하는 데이터에 대한 객관적 관찰 및 분석
3) 실험 검증 등을 통한 문제의 본질 분석
4) 창의성이 요구되는 Why 관점 접근과 본질로 접근하는 What 접근법을 혼합하여 빅데이터 분석에 필요한 변수 도출
나) 연관성 분석을 통해 데이터 집합 간의 통계적 관련성을 분석할 수 있는 변수를 생성하고 변수의 척도를 분류함
- 상관분석은 데이터 간의 숨겨진 관계 및 패턴을 찾고 데이터의 가치를 도출하는 핵심 방법. 데이터 간의 상관성은 하나의 데이터 값이 변할 때 다른 데이터 값도 변할 가능성이 높아지는 데이터의 관계성을 의미
- 변수 척도에 따라 연관성 분석 기법이 달라짐. 명목/서열 척도는 교차분석, 등간/비율 척도는 상관분석 이용
- ![[Pasted image 20240315114559.png]]

### 데이터 확보 방안
가. 필요 데이터의 정의
- 기업 및 조직의 업무 문제 해결을 위한 인터뷰 등을 통해 빅데이터 분석 목적에 적합한 데이터 목록을 작성하고 데이터별로 확보 가능 여부를 점검
- 이 과정에서는 기업의 비즈니스 활동을 위해 관련된 기관, 파트너 기업, 지자체, 실무자 및 외부 전문가 등 다양한 이해관계자들의 의견을 수렴할 수 있도록 함

나. 내부 데이터 확보 방안
1) 보유 데이터 현황 조사
- 조직이 보유하고 있는 데이터 중에서 분석을 위해 필요한 데이터의 데이터명, 데이터 설명, 데이터 형태 및 용량 등의 현황 조사를 수행
- 데이터의 품질, 지속적인 업데이트 여부, 충분한 기간의 데이터 적재 여부, 데이터의 과거 변경 이력 등에 대한 사항도 파악해야 함

2) 부서간 공유 가능성 파악
- 데이터의 관리 권한을 파악하여 주관부서 이외의 타 부서에 데이터 관리 권한이 있다면 관련 부서간 협의를 통해 데이터 공유의 가능 여부를 확인해야 한다

3) 관련 법/제도 확인
- 관련 법, 보안 체계, 개인정보보호 문제 등과 관련하여 데이터의 사용이 어렵거나 불가능하지 않은 지 확인이 필요
- 또한 법적인 제재가 있는 개인정보의 경우 비식별화 등의 방법을 통해 데이터 활용이 가능한지 파악할 필요가 있다

다. 외부 데이터 확보 방안
- 조직이 보유하고 있지 않지만 분석에 필요한 데이터의 데이터 보유기관, 데이터명, 데이터 설명, 데이터 형태 및 용량 등의 현황 조사를 수행
- 분석대상 데이터의 수집 시 법률상의 제약 여부를 확인
- 법률상 제약이 없는 데이터는 해당 데이터를 보유한 기관과의 협의를 통해 데이터 공유 가능 여부를 확인하고 활용 대상 범위 즉, 데이터 종류 및 사용 가능 기간 등을 확인
- 무료로 공개되는 데이터가 아닌 경우 데이터의 구매 비용을 고려해야 함
- 기타 공공데이터포털 및 오픈 API 등에서 수집 가능한 데이터를 검토해봄
//알아두기. 공공데이터포털에서 얻을 수 있는 데이터의 종류
(1) 파일 데이터
(2) Open API
(3) 시각화 데이터

라. 데이터 확보 계획을 위한 점검사항
1) 빅데이터 분석을 다양한 데이터 원천을 파악하고 있는가?
- 분석 목표 달성을 위한 데이터의 적절성검토
- 데이터 품질의 신뢰성 확인
- 원하는 기간 내에 데이터 확보 가능 여부 검토

2) 외부 데이터 확보를 위한 기관간 협의가 되어 있는가?
- 조직의 내/외부 협력체계 및 절차 확인

3) 확보한 외부 데이터는 조직 내부 데이터와 통합하여 분석 가능한가?

4) 데이터 수집과 관련된 보안사항 및 개인정보보호 문제 등을 체크하였는가?

### 분석 절차 및 작업 계획
가. 빅데이터 분석 절차 *분석 과정의 각 단계별 주요 업무가 중요*
- 빅데이터 분석은 아래의 그림과 같이 부석 기획, 데이터 준비, 데이터 분석, 시스템 구현, 평가 및 전개 순으로 진행

![[Pasted image 20240315130032.png]]

나. 빅데이터 분석 작업 계획
- 5단계의 빅데이터 분석 절차의 각 세부 단계별로 작업 계획을 수립할 때는 작업 분할 구조도를 활용
- WBS는 설정된 목표를 정해진 기간과 주어진 자원 내에서 달성하는  형태의 업무를 효율적으로 관리하기 위해 큰 단위의 업무를 여러 세부 업무로 나누고, 세부 업무를 다시 상세 업무로 쪼개는 작업을 의미. 이는 수행해야 할 일을 10일 또는 2주 이내로 나눈 구조로, 프로젝트 관리 시 가장 많이 활용하는 기법임

1) WBS 작성 방법
- 전체를 큰 단위로 분할
- 각각의 부분 단위에 대해 좀 더 작은 단위로 분해하여, 이를 계층적으로 구성함
- 부분을 구성하는 가장 작은 단위인 워크 패키지로 분할
- 각 워크 패키지에 담당 인원을 배치하여 구성도 완성

2) WBS의 역할
- 전체 업무를 큰 단위, 세부 단위로 분류하여 구성 요소를 만든 후 각 요소를 평가하고 일정별로 계획하며 그것을 완수할 수 있는사람에게 할당해주는 역할을 함

| 주요 역할              | 내용                                                                                |
| ------------------ | --------------------------------------------------------------------------------- |
| 수행업무 식별            | 프로젝트 관리자(PM)는 WBS에 근거하여 업무를 식별하고 전체 프로젝트를 관리함                                     |
| 일정, 원가, 자원 요구사항 파악 | WBS는 프로젝트의 작업에 대한 일정 및 원가를 산정하는 기초자료가 되며, 예상치 못한 작업이나 누락된 작업들로 인한 일정지연 및 비용지출을 예방 |
| 일정계획 산정            | WBS는 어떠한 업무를 누가 어떤 순서로 진행해야 하는지 설정할 때 근거자료가 됨                                     |
| 전체 일정 진행사항 파악      | 작업자들은 자신에게 할당된 업무를 쉽게 식별<br> PM은 WBS를 체크리스트로 사용함으로써 업무의 진행상황을 쉽게 파악할 수 있다         |
| 정보 추적 통제           | 프로젝트 진행 중 변경 사항이 발생하였을 때 통제관리 도구로 사용                                              |
| 고객, 팀 간의 의사소통 링크   | 프로젝트 참여자 전원에게 프로젝트 전체를 볼 수 있는 안목을 제공, 요구 사항의 변경 시 좋은 의사소통 도구로서 활용 가능              |

다. 단계별 세부단계 및 실제 업무
1) 분석 기획

| 단계              |                | 내용                                                                                                                 | 입력자료                                                  | 프로세스 및 도구                                          | 출력자료                                        |
| --------------- | -------------- | ------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------- | -------------------------------------------------- | ------------------------------------------- |
| 비즈니스 이해 및 범위 설정 | 비즈니스 이해        | *내부 업무매뉴얼*과 관련 자료, 외부의 관련 비즈니스 자료를 조사하고 향후 프로젝트 진행을 위한 방향을 설정함                                                     | -업무매뉴얼<br>- 전문가 지식<br>-빅데이터 분석 대상 도메인의 관련 자료          | - 자료 수집 및 비즈니스 이해                                  | - 비즈니스 이해 및 도메인 문제점                         |
|                 | 프로젝트 범위 설정     | 빅데이터 분석 프로젝트의 대상인 비즈니스에 대한 이해와 *프로젝트 목적에 부합하는 범위를 설정*하고 프로젝트 범위 정의서의 SOW(Statement Of Work)를 작성                    | - 중장기 계획서<br>- 빅데이터 분석 프로젝트 지시서<br>-비즈니스 이해 및 도메인 문제점 | - 자료 수집 및 비즈니스 이해<br>- 프로젝트 범위 정의서 작성 절차           | - 프로젝트 범위 정의서(SOW)                          |
| 프로젝트 정의및 계획 수립  | 데이터 분석 프로젝트 정의 | 프로젝트의 *목표 및 KPI, 목표 수준 등을 구체화*하여 상세 프로젝트 정의서를 작성하고 프로젝트 목표를 명확화하기 위한 모델 운영 이미지 및 평가 기준을 설정                         | - 프로젝트 범위 정의서(SOW)<br>- 빅데이터 분석 프로젝트 지시서              | - 프로젝트 목표 구체화<br>- 모델 운영 이미지 설계                    | - 프로젝트 정의서<br>- 모델 운영 이미지 설계서<br>- 모델 평가 기준 |
|                 | 프로젝트 수행 계획 수립  | 프로젝트의 목적 및 배경, 기대효과, 수행방법, 일정 및 추진조직, *프로젝트 관리 방안을 작성*하고 WBS는 프로젝트 산출물 위주로 작성되어 프로젝트 산출물 위주로 작성되어 프로젝트의 범위를 명확하게 함 | - 프로젝트 범위 정의서<br>-모델 운영 이미지 설계서<br>-모델 평가 기준          | - 프로젝트 범위 정의서<br>- WBS자성                           | - 프로젝트 수행 계획서<br>- WBS                      |
| 프로젝트 위험계획 수립    | 데이터 분석 위험 식별   | 앞서 진행된 프로젝트 산출물과 정리 자료를 참조하고 전문가의 판단을 활용해 프로젝트를 진행하며 *발생가능한 위험을 식별*한다 식별된 위험은 위험의 영향도와 빈도, 발생가능성에 따라 위험의 우선순위를 설정함 | -프로젝트 범위 정의서<br>- 프로젝트 수행 계획서<br>선행 프로젝트 산출물 및 정리 자료  | - 위험 식별 절차<br>- 위험 영향도 및 발생 가능성 분석<br>- 위험 우선순위 판단 | - 식별된 위험 목록                                 |
|                 | 위험 대응 계획 수립    | 식별된 위험은 상세한 정량적, 정성적 분석을 통해 *위험 대응방안을 수립*한다. 예상되는 위험에 대해 회피, 전이, 완화, 수용으로 구분하여 위험 관리 계획서 작성                        | - 식별된 위험 목록<br>- 프로젝트 범위 정의서<br>-프로젝트 수행 계획서          | - 위험 정량적 분석<br>- 위험 정성적 분석                         | -위험관리 계획서                                   |

2) 데이터 준비

| 단계              |                | 내용                                                                                                                | 입력자료                                                              | 프로세스 및 도구                                | 출력자료                              |
| --------------- | -------------- | ----------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | ---------------------------------------- | --------------------------------- |
| 필요 데이터 정의       | 데이터 정의         | 시스템, 데이터베이스, 파일, 문서 등의 다양한 내/외부 원천 데이터 소스로 부터 *분석에 필요한 데이터를 정의*                                                   | - 프로젝트 수행 계획서<br>- 시스템 설계서<br>- ERD<br>-메타데이터 정의서<br>- 문서 자료      | -내/외부 데이터 정의<br>- 정형/비정형/반정형 데이터 정의      | - 데이터 정의서                         |
|                 | 데이터 획득방안 수립    | 내/외부의 다양한 데이터 소스로부터 정형/비정형/반정형 *데이터를 수집*하기 위한 구체적인 방안을 수립                                                         | - 데이터 정의서<br>- 시스템 설계서<br>-ERD<br>메타데이터 정의서<br>- 문서자료<br>- 데이터 구입 | - 데이터 획득 방안 수립                           | - 데이터 획득 계획서                      |
|                 |                | 내부 데이터 획득에는 부서 간 업무협조와 개인정보보호 및 정보 보안과 관련한 문제점을사전에 점검하고, 외부 데이터의 획득은 다양한 인터페이스 및 *법적인 문제점을 고려하여 상세한 데이터 획득*계획을 수립 |                                                                   |                                          |                                   |
| 데이터 스토어 설계      | 정형 데이터 스토어 설계  | 정형 데이터는 일반적으로 관계형 데이터베이스인 RDBMS를 사용하고 *데이터의 효율적인 저장과 활용*을 위해 데이터 스토어의 논리적, 물리적 설계를 구분하여 설계                        | - 데이터 정의서<br>- 데이터 획득 설계서                                         | - 데이터베이스 논리, 물리 설계<br>- 데이터 매핑           | - 정형 데이터 스토어 설계서<br>- 데이터 매핑 정의서  |
|                 | 비정형 데이터 스토어 설계 | 하둡, NoSQL등을 이용하여 비정형 또는 반정형 데이터를 저장하기 위한 *논리적, 물리적 데이터 스토어*를 설계                                                   | - 데이터 정의서<br>- 데이터 획득 계획서                                         | - 비정형/반정형 데이터 논리, 물리 설계                  | - 비정형 데이터 스토어 설계서<br>- 데이터 매핑 정의서 |
| 데이터 수집 및 정합성 점검 | 데이터 수집 및 저장    | 크롤링 등의 데이터 수집을 위한 ETL등의 다양한 도구와 API, 스크립트 프로그램 등을 이용하여 데이터를 수집하고, 수집된 데이터를 설계된 데이터 스토어에 저장함                       | - 데이터 정의서<br>- 데이터 획득 계획서<br>- 데이터 스토어 설계서                        | - 데이터 크롤링 도구<br>- ETL도구<br>- 데이터 수집 스크립트 | - 수집된 분석요 데이터                     |
|                 | 데이터 정합성 점검     | 데이터 스토어의 품질 점검을 통하여 데이터의 정합성을 확보하고 데이터 품질 개선이 필요한 부분에 대하여 *보완 작업*을 함                                              | - 수집된 분석용 데이터                                                     | - 데이터 품질 확인<br>- 정합성 점검 리스트              | - 정합성 점검 보고사                      |

3) 데이터 분석

| 단계         |                 | 내용                                                                                                                                                       | 입력자료                                                  | 프로세스 및 도구                                    | 출력자료                         |
| ---------- | --------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------- | -------------------------------------------- | ---------------------------- |
| 분석용 데이터 준비 | 비즈니스 룰 확인       | 비즈니스 이해, 도메인 문제점 인식, 프로젝트 정의 등을 이용하여 *프로젝트의 목표를 정확하게 인식*함                                                                                                | - 프로젝트 정의서<br>- 프로젝트 수행 계획서<br>- 데이터 정의서<br>- 데이터 스토어 | - 프로젝트 목표 확인<br>- 비즈니스 룰 확인                  | - 비즈니스 룰<br>- 분석에 필요한 데이터 범위 |
|            |                 | 세부적인 비즈니스 룰을 파악하고 분석에 필요한 *데이터의 범위*를 확인                                                                                                                  |                                                       |                                              |                              |
|            | 분석용 데이터 셋 준비    | 데이터 스토어로부터 분석에 필요한 *정형/비정형 데이터를 추출*함. 필요시 적절한 가공을 통하여 분석도구 입력 자료료 사용될 수 있도록 편성함                                                                          | - 데이터 정의서<br>- 데이터 스토어                                | - 데이선 선정<br>- 데이터 변환<br>- ETL도구              | - 분석용 데이터 셋                  |
|            |                 | 추출된 데이터는 데이터베이스나 구조화된 형태로 구성하고 필요시 분석을 위한 작업 공간(Play Ground, Sandbox 등)과 전사차원의 데이터 스토어로 분리할 수도 있다                                                        |                                                       |                                              |                              |
| 텍스트 분석     | 텍스트 데이터 확인 및 추출 | 데이터 스토어에서 필요한 *텍스트 데이터 추출*                                                                                                                               | - 비정형 데이터 스토어                                         | - 분석용 텍스트 데이터 확인<br>- 텍스트 데이터 추출             | -분석용 텍스트 데이터                 |
|            | 텍스트 데이터 분석      | 추출된 텍스트 데이터를 분석도구로 적재하여 다양한 기법을 분석하고 *모델을 구축*함                                                                                                           | - 분석용 텍스트 데이터<br>- 용어사전                               | - 분류체계 설계<br>- 형태소 분석<br>- 키워드 도출            | - 텍스트 분석 보고서                 |
|            |                 | 텍스트 분석을 위해 *용어사전*을 사전에 확보하고 업무 도메인에 맞도록 작성해야 함                                                                                                           | (유의어 사전, 불용어 사전 등)                                    | - 토픽 분석<br>- 감정분석, 의견분석<br>- 네트워크 분석         |                              |
|            |                 | 구축된 모델은 *시각화 도구를 이용*하여 모델의 의미 전달을 명확하게 함                                                                                                                 |                                                       |                                              |                              |
| 탐색적 분석     | 탐색적 데이터 분석      | 다양한 관점 별로 *기초통계량*(평균, 분사느 표준편차, 최대값, 최소값)을 산출하고, 데이터의 분포와 변수간의 관계 등 데이터 자체의 특성 및 데이터의 *통계적 특성을 이해하고 모델링*을 위한 기초자료로 활용                                    | - 분석용 데이터 셋                                           | - EDA 도구<br>- 통계분석<br>-연관성 분석<br>- 데이터 분포 확인 | - 데이터 탐색 보고서                 |
|            | 데이터 시각화         | *탐색적 데이터 분석을 위한 도구*로 활용. 그러나 모델의 시스템화를 위한 시각화를 목적으로 활용할 경우 시각화 기획, 설계, 구현 등의 별도의 프로세스를 따라 진행되어야 함                                                        | -분석용 데이터 셋                                            | - 시각화 도구<br>- 시각화 패키지                        | - 데이터 시각화 보고서                |
|            |                 | 탐색적 데이터 분석을 진행하면 수행된 데이터 시각화는 모델링 또는 향후 시스템 구현을 위한 사용자 인터페이스 또는 *프로토타입*으로 활용될 수도 있다                                                                      |                                                       | - 인포그래픽<br>- 시각화 방법론                         |                              |
| 모델링        | 데이터 분할          | *모델의 과적합과 일반화*를 위해 분석용 데이터 셋을 모델 개발을 위한 훈련용 데이터와 모델의 검증력을 테스트하기 위한 테스트용 데이터로 분할. 모델에 적용하는 기법에 따라 *데이터 분할* 또는 *검증 횟수, 생성 모델 개수* 등을 설정                     | - 분석용 데이터셋                                            | - 데이터 분할 패키지                                 | - 훈련용 데이터<br>- 테스트용 데이터      |
|            | 데이터 모델링         | 기계학습 등을 이용한 데이터 모델링은 훈련용 데이터를 활용하여 *분류, 예측, 군집*등의 모델을 만들어 가동중인 운영 시스템에 적용함. 필요시 비정형 데이터 분석결과를 통합적으로 활용하여 *프로젝트 목적*에 맞는 통합 모델 수행                          | - 분석용 데이터 셋                                           | - 통계 모델링 기법<br>- 기계 학습<br>- 모델 테스트           | - 모델링 결과 보고서                 |
|            | 모델 적용 및 운영 방안   | 모델을 가동중인 운영시스템에 적용하기 위해서는 모델에 대한 상세한 *알고리즘 설명서 작성*이 필요. 알고리즘 설명서는 시스템 구현 단계에서 중요한 입력 자료로 활용되므로 필요시 의사코드 수준의 상세한 작성이 필요. 또한 모델의 안정적 운영을 *모니터링*하는 방안도 수립함. | - 모델링 결과 보고서                                          | - 모니터링 방안 수립<br>- 알고리즘 설명서 작성                | - 알고리즘 설명서<br>- 모니터링 방안      |
| 모델 평가 및 검증 | 모델 평가           | 프로젝트 정의서의 모델 평가 기준에 따라 모델을 객관적으로 평가하고 품질관리 차원에서 모델 평가 프로세스를 진행함. 모델 평가를 위해 모델 결과 보고서 내의 *알고리즘을 파악*하고 테스트용 데이터나 필요시 *모델 검증*을 위한 별도의 데이터를 활용함              | - 모델링 결과 보고서<br>- 평가용 데이터                             | - 모델 평가<br>- 모델 품질관리<br>- 모델 개선 작업           | - 모델 평가 보고서                  |
|            | 모델 검증           | *모델의 실적용성을 검증*하기 위해 검증용 데이터를 이용해 모델 검증 작업을 실시하고 *모델링 검증 보고서*를 작성<br>검증용 데이터는 모델 개발 및 평가에 활용된 훈련용이나 테스트용 데이터가 아닌 실 운영용 데이터를 확보하여 *모델의 품질을 최종 검증*함         | - 모델링 결과 보고서<br>- 모델 평가 보고서<br>- 검증용 데이터              | - 모델 검증                                      | - 모델 검증 보고서                  |

4) 시스템 구현

| 단계           |             | 내용                                                                                                      | 입력자료                         | 프로세스 및 도구                                | 출력자료                                   |
| ------------ | ----------- | ------------------------------------------------------------------------------------------------------- | ---------------------------- | ---------------------------------------- | -------------------------------------- |
| 설계 및 구현      | 시스템 분석 및 설계 | 가동중인 시스템을 분석하고 알고리즘 설명서에 근거하여 *응용시스템 구축* 설계 프로세스를 진행함. 시스템 부석과 설계는 사용중인 정보시스템 개발 방법론을 커스터마이징하여 적용할 수 있다 | - 알고리즘 설명서<br>- 운영중인 시스템 설계서 | - 정보시스템 개발방법론                            | - 시스템 분석 및 설계서                         |
|              | 시스템 구현      | 시스템 분석 및 설계서에 따라 BI 패키지를 활용하거나 새롭게 시스템을 구축하거나 가동중인 운영 시스템의 커스터마이징 등을 통해 *설계된 모델을 구현*함                   | - 시스템 분석 및 설계서<br>- 알고리즘 설명서 | - 시스템 통합 개발도구(IDE)<br>- 프로그램 언어<br>- 패키지 | - 구현 시스템                               |
| 시스템 테스트 및 운영 | 시스템 테스트     | 구축된 *시스템의 검증*을 위해 단위 테스트. 통합 테스트, 시스템 테스트 등을 실시. 시스템 테스트는 품질 관리 차원에서 진행함으로써 적용된 시스템의 객관성과 완전성을 확보       | - 구현 시스템<br>- 시스템 테스트 계획서    | - 품질관리 활동                                | - 시스템 테스트 결과보고서                        |
|              | 시스템 운영 계획   | 구현된 시스템을 지속적으로 활용하기 위해 시스템 운영자, 사용자를 대상으로 필요한 *교육 실시*, *시스템 운영 계획 수립*                                   | - 시스템 분석 및 설계서<br>- 구현 시스템   | - 운영계획 수립<br>- 운영자 및 사용자 교육              | - 운영자 매뉴얼<br>- 사용자 매뉴얼<br>- 시스템 운영 계획서 |

5) 평가 및 전개

| 단계           |           | 내용                                                                   | 입력자료                                                                    | 프로세스 및 도구                                     | 출력자료          |
| ------------ | --------- | -------------------------------------------------------------------- | ----------------------------------------------------------------------- | --------------------------------------------- | ------------- |
| 모델 발전 계획 수립  | 모델 발전 계획  | 개발된 모델의 지속적인 운영과 기능 향상을 위한 *발전계획을 상세하게 수립*하여 모델의 계속성 확보              | - 구현 시스템 <br>- 프로젝트 산출물                                                 | - 모델 발전 계획 수립                                 | - 모델 발전 계획서   |
| 프로젝트 평가 및 보고 | 프로젝트 성과평가 | 프로젝트의 정량적 성과와 정성적 성과로 나누어 *성과 평가서를 작성*                               | - 프로젝트 산출물<br>- 품질관리 산출물<br>- 프로젝트 정의서<br>- 프로젝트 수행 계획서                 | - 프로젝트 평가기준<br>- 프로젝트 정량적 평가<br>- 프로젝트 정성적 평가 | - 프로젝트 성과 평가서 |
|              | 프로젝트 종료   | 프로젝트 진행과정의 모든 산출물 및 프로세스를 *지식자산화*하고 최종 보고서를 작성하여 의사소통 절차에 따라 보고하고 종료 | - 프로젝트 산출물<br>- 품질관리 산출물<br>- 프로젝트 정의서<br>- 프로젝트 수행계획서<br>- 프로젝트 성과 평가서 | - 프로젝트 지식자산화 작업<br>- 프로젝트 종료                  | - 프로젝트 최종보고서  |
