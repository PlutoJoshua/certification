3) 매개변수와 초매개변수의 비교

|       | 딥러닝 모델의 매개변수                                            | 초매개변수                              |
| ----- | ------------------------------------------------------- | ---------------------------------- |
| 사용목적  | 최적화된 ㅈ딥러닝 모델 구현                                         | 모델링 최적화 파라미터값의 도출                  |
| 생성 주체 | 데이터 학습 모델이 생성함                                          | 사용자 판단 기반 생성                       |
| 조정 여부 | 임의 조정 불가                                                | 조정 가능                              |
| 활용사례  | - 인공 신경망의 가중치<br>- SVM의 Sopprt vecter<br>- 선형회귀에서의 결정계수 | - 학습률<br>- 경사하강법 반복 횟수<br>- 활성화 함수 |
- 초매개변수의 적절한 튜닝을 통해 최적인 딥러닝 모델의 매개변수를 도출할 수 있다

나. 매개변수 최적화 기법
- 매개변수 최적화에는 2차원(x축 가중치와 y축 손실값) 손실함수 그래프를 이용한다
- 매개변수 최적화 기법에는 경사하강법을 기반으로 한 방법들, 모멘텀 방식을 도입한 학습방법, 그 외 AdaGrad, RMSProp, Adam 등이 있다

// 알아두기. 딥러닝 주요 용어
1. bacth_size
- 한 번에 처리하는 데이터의 수
- 100이라고 하면, 한 번에 100개의 데이터를 처리한다는 의미
2. max_iter
- 몇 개의 배치를 사용할 것인지를 의미
- 머신러닝의 학습 과정에서 반복을 몇 번 것인지를 정하는 것
- 60000이라고 하면, 배치 사이즈 100이기 때문에 학습을 한 번에 사진 100장씩 60,000번하겠다는 의미. 총 사진 6,000,000장으로 학습이 이루어짐
3. test_iter
- 모델 평가를 위해 몇 개의 배치를 사용할 겟인지를 의미
- 배치사이즈100, test_iter 100이면 한 번에 데이터 100개씩 100번, 총 10,000개의 데이터로 학습 결과를 평가하겠다는 뜻
4. 에포크(epoch)
- 전체 데이터에 대한 한 번의 학습을 의미
- iteration은 정해진 배치 사이즈를 이용하여 학습을 반복하는 횟수로 epoch와는 다른 의미. 한번의 에포크 를 위해 수번의 iteration이 필요
- 높은 에포크는 데이터 자체를 머신에 하급시키는 것이므로 과적합의 문제 발생

1) 경사 하강법 기반 방식들
- 매개변수 최적화 방법으로 가장 널리 알려진 방법
- 최적의 매개변수 값을 찾는 방법으로 미분을 함
- 현재의 기울기(미분값)를 기반으로 매개변수가 갱신해야 할 방향과 크기를 설정함
- 매개변수를 갱신할 때 기존 매개변수에서 반대방향으로 학습률 x (손실함수의 기울기) 크기만큼 이동
- 기울어진 방향으로 매개변수 값을 갱신하는 일을 반복하여 최적의 값에 다가가는 방법이 확률적 경사 하강법(SGD)

	가) 배치 경사 하강법
	- 배치는 한 번에 처리하는 데이터 수
	- 배치경사 하강법은 모든 데이터셋을 하나의 배치로 보고 전체의 미분값을 평균하여 1 epoch 동안 한번만 갱신을 수행하는 방식
	- 한 스텝에 모든 학습 데이터를 사용하기 때문에 학습속도가 느리다는 단점이 있지만, 전체 연산횟수가 적으로 최적값을 찾을 수 있다는 장점이 있다

	나) 확률적 경사 하강법
	- 손실함수의 기울기를 구하여 그 기울기를 따라 조금씩 아래로 내려가 최종적으로는 손실함수가 가장 작은 지점에 도닥하도록 하는 알고리즘
	- 기울기를 구하는데 학습 시 필요한 한 개의 데이터가 무작위로 선택되므로 확률적이라 함
	- 각 반복에서 하나의 데이터만을 뽑아서 학습시키는 방법
	- 랜덤하게 n개의 데이터를 뽑아 갱신시키는 MGD 방식 대신 SGD로 표현해서 사용하기도 함
	- SGD 사용의 특징
	- 기울기가 줄어드는 최적점 근처에서 느리게 진행함
	- BGD방식에 비해 최적화로 가는 과정에서 노이즈가 많이 발생할 수 있다
	- 탐색 경로가 지그재그로 크게 변한다. 
	- 이러한 단점을 개선하는 방법으로 모멘텀, AdaGrad, Adam등이 있다

2) 모멘텀(Momentum)
가) 개념
- 원래 물리학 용어로 물체의 속도와 질량에 관련된 운동량을 뜻한다
- 모멘텀은 기울기 방향으로 힘을 받으면 물체가 가속된다는 물리법칙을 적용한 알고리즘
- 확률적 하강경사법에 속도라는 개념을 적용함
- 기울기가 줄어들더라도 누적된 기울기 값으로 인해 빠르게 최적점으로 수렴하게 됨
- 모멘텀 방식을 따르면 위 아래 반복적인 움직임은 여전히 보여주지만 오른쪽으로 지속적인 움직임이 누적되어 더욱 빠르게 최적화가 되는 것을 확인할 수 있다

나) 특징
- 모멘텀의 최적점 탐색 경로를 보면, 갱신 경로는 공이 그릇 바닥을 구르듯 움직인다
- 모멘텀은 관성의 방향을 고려해 진동과 폭을 줄이는 효과가 있다
- 탐색 경로의 변위가 줄어들어 빠르게 최적점으로 수렴함
- c축 한 방향으로 일정하게 가속하지만 y축 방향의 속도는 일정하지 않다

3) Per-매개변수 조정 학습률
*앞의 매개변수 최적화 방법과 Per 매개변수 조정 학습률과의 명확한 차이점 밒 특징 숙지*
- 이상의 매개변수 최적화 방법들은 모든 매개변수에 대해 동일한 학습 속도를 적용하였다. 그러나 Per-매개변수 조정 학습률 방법에서는 각 매개변수에 대해 조정된 학습 속도를 적용한다

가) AdaGrad
- 조정된 경사기반 방식으로 이전 갱신에서 갱신이 많이 된 매개변수들에 대해서는 학습량을 줄임
- 손실함수의 기울기가 큰 첫 부분에서는 크게 학습하다가 최적점에 가까워질수록 학습률을 줄여 조심씩 적게 학습하는 방식
- 학습을 진행하면서 학습률을 점차 줄여나가는 학습률 감소기법을 적용한 최적화 알고리즘
- 매개변수 전체의 학습률 값을 일괄적으로 낮추는 것이 아니라 각각의 매개변수에 맞는 학습률 값을 만들어주는 방식이다
- 매개변수를 갱신할 때마다 1/root h을 곱해 학습률을 조정함
- 코드 상에는 학습률을 조정하는 1/root h eps라는 변수가 더해져 있다. 이 값은 h가 0이 되거나 0에 너무 가깝게 되어서 전체값이 너무 커져버리는 상황을 방지하기 위한 변수로 주로 1e-4에서 1e-8 정도의 값을 준다
- 하지만 이 방법은 지나치게 학습률을 낮추는 경향이 잇어 딥러닝 모델에 적용 시 잘 학습이 되지 않는 경향이 있어 자주 사용하지 않음
- 특징
1. 최적점 탐색 경로를 보면, 최적점을 향해 매우 효율적으로 움직인다. 체음에는 큰 폭으로 움직이지만 큰 움직임에 비례하여 갱신 정도도 큰 폭으로 작아진다
2. 갱신 강도가 빠르게 약해지고, 지그재그 움직임이 눈에 띄게 줄어들어 빠르게 최적점으로 수렴
3. y축 방향은 기울기가 커서 처음엔 크게 움직이지만 큰 움직임에 비례하여 갱신 정도도 큰 폭으로 작아지도록 조정되어 y축 방향으로 갱신 강도가 빠르게 약해지고 지그재그 움직임도 줄어듬

나) Adam(Adaptive Moment Estimation)
- 모멘텀 방식과 AdaGrad 방식을 합친 것. 즉, 운동량에 착안한 모멘텀 기법과 각각의 매개변수에 맞는 학습률 값을 만들어주는 AdaGrad 방식의 장점을 합친 알고리즘
- 이론은 다소 복잡하나 실전에서 가장 기본적으로 사용, 성능이 좋아 많이 사용함
- 특징
1. 최적점 탐색 경로 또한 이 두 방식을 합친 것과 같은 양상으로 나타남. Adam의 갱신 과정은 모멘텀 방식처럼 공이 굴러가는 듯하고, AdaGrad로 인해 갱신 강도가 조정되므로 좌우 흔들림과 지그재그 움직임도 덜함
![[Pasted image 20240325084151.png]]![[Pasted image 20240325084201.png]]![[Pasted image 20240325084301.png]]![[Pasted image 20240325084310.png]]

나. 매개변수 최적화 기법 비교
- 최적화 방법에 따라 최적화까지의 시간 차가 매우 크다
- SGD는 이해와 구현이 쉽지만 실제로 모멘텀, AdaGrad, Adam이 더 좋은 성능을 발휘함
- 문제에 따라 하이퍼 파라미터나 학습률 등이 달라지지만 대체적으로 모멘텀, AdaGrad, Adam이 빠르게 학습하고, 정확도도 높게 나타난다

다. 초매개변수 최적화 기법
1) 그리드 서치
- 하이퍼파라미터를 일정한 간격으로 변경하며 최적의 파라미터를 찾아가는 기법
- 특정 범위 내에서 하이퍼파라미터를 일정 값만큼 일일이 변경하며 출력값을 비교하는 방식으로 동작
- 한계점
1. 최적의 솔루션을 찾을 수 있다는 보장이 없음
2. 지정한 모든 구간을 탐색해야 하기 때문에 굳이 탐색하지 않아도 되는 하이퍼파라미터 값에 대해서도 탐색하는 경우가 생김
3. 최댓값을 구하는 문제의 경우 아래로 볼록한 구간은 출력값이 음수이기 때문에 탐색할 필요가 없지만 그리드 서치는 이러한 구간까지 탐색함

2) 랜덤 서치
- 임의의 하이퍼파라미터를 선정하는 과정을 통해 최적의 해를 찾아가는 기법
- 그리드 서치에서는 선정되지 않은 하이퍼파라미터에 대해 탐색할 수도 있고, 그리드 서치에 비해 최적의 해를 확률적으로 더 빨리 찾을 수 있다

3) 베이지안 최적화
- 최적의 해 근처의 하이퍼파라미처를 위주로 탐색하는 작업과 임의의 새로운 하이퍼파라미터를 탐색하는 과정을 반복하여 최적의 해를 탐색하는 기법이다
- 최적의 해가 근처에 있을 가능성이 높은 구간을 위주로 탐색하며, 해당 구간 외에도 최적의 해가 있을 가능성을 열어두고 임의의 새로운 하이퍼파라미터에 대해서도 탐색을 이어나감
- 초기에 A와 B 위치의 하이퍼 파라미터를 탐색한다고 가정했을 때, 목표 함수의 최댓값을 찾는 문제라면 최적의 해가 근처에 있을 가능성이 높은 B구간을 위주로 탐색함

### 분석 모형 융합
- 강력한 단일의 모델보다는 복수의 여러 모델을 종합적으로 이용할 때 더 뛰어날 수 있다는 생각에 기반을 두는 방법
- 예측 모형의 경우 여러 개의 분류기를 생성하고 그 예측을 결합함으로써 보다 정확한 최종 예측을 도출할 수 있다

가. 배깅과 부스팅의 비교
- 배깅은 학습 데이터에 대해 여러 개의 붓스트랩 데이터를 생성하고 각 붓스트랩 데이터에 여러 알고리즘으로 학습시킨 후 산출된 결과 중 다수결에 의해 최종 결과를 선정한다
- 투표 방식에는 직접 투표와 간접 투표 방식이 있다

| 직접 투표                                                    | 간접 투표                                                                               |
| -------------------------------------------------------- | ----------------------------------------------------------------------------------- |
| 개발모형의 결과를 기준으로 투표를 통해 다수의 분류기가 예측한 결과값을 최종 결과로 선정(다수결원칙) | 각 알고리즘이 예측한 레이블 값 결정 확률을 예측해서 이것의 가중 평균을 구한뒤 가장 확률이 높은 레이블 값을 최종 결과로 선정함(가중치 투표 방식) |
- 배깅이 일반적인 모델을 만드는 데 집중되어 있다면, 부스팅은 맞히기 어려운 문제를 맞히는데 초점이 맞추어져 있다. 예를 들어 특정 문제가 어려워 계속 틀릴 때 그 문제에 가중치를 주어 그 문젤ㄹ 잘 맞히는 모델을 최종 모델로 선정한다
- 부스티은 여러 개의 약한 학습기를 순차적으로 학습시켜 예측하면서 잘못 예측한 데이터에 가중치를 부여하여 오류를 개선하나가며 학습하는 방식
- 부스팅도 배깅과 동일하게 복원 랜덤 샘플링을 하지만 가중치를 부여한다는 차이가 있고, 또한 배깅은 병렬로 학습하는 반면에 부스팅은 순차적으로 학습한다는 점에서 차이가 있다
- 이를 통해 부스팅이 훈련 오차를 빨리 쉽게 줄일 수 있고 배깅에 비해 많은 경우 예측오차가 향상되어 대표적 알고리즘 Adaboost의 성능이 배깅보다 뛰어난 경우가 많다

나. 랜덤포레스트
- 의사결정나무의 특징인 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 주 그리뫄 같이 여러 개의 약한 학습기(의사결정트리 모형)들을 생성하고 이를 결합해 최종적으로 종속변수를 분류하거나 예측함
- 이때 분류에 대해서는 투표 바업븡ㄹ 적용하고, 예측에 대해서는 평균화 방법을 적용
- 수천 개의 변수를 통해 변수 제거 없이 실행되므로 정확도 측면에서 좋은 성과를 보이며, 이론적 설명이나 최종 결과의 해석이 어렵다는 단점이 있으나 트리의 다양성을 극대화하여 예측력이 우수하고 많은 트리의 예측 결과를 종합하기 때문에 안정성이 높다. 특히 입력변수가 많은 경우 배깅과 부스팅과 비슷하거나 좋은 예측력을 보인다

### 최종모형 선명
*선정 과정을 중심으로*
- 분석 모델의 매개변수 최적화를 위해 반복적으로 수행했던 모델학습이 완료되면 모델 개발은 절차에 따라 모델 성능 평가를 진행하고 그 결과들을 검토하여 최종 모형을 선정하는 단계
- 최종 모형 선정 단계에서는 모델 학습에 이용되었던 분석 알고리즘의 성능을 비교 평가할 수 있는 기준을 선정해야 하고, 분석 결과에 대한 검토도 이루어져야 한다. 그리고 평가 기준들에 맞춰 분석 알고리즘별 성능 비교도 실시한다. 이와 같이 성능 평가와 검토를 통해 최종 모형을 선정함

가. 최종모형 평가 기준선정
- 빅데이터 개선 모형에 대한 개발이 완료되면 평가 데이터셋에 의한 모델 성능평가도 지표에 따라 측정되지만, 그동안 모델 학습에 이용되었던 분석 알고리즘 수행 결과 기록을 검토하여 최종 모형을 선정함
- 일반적으로는 모델링 기법에 관계없이 정확도를 기준으로 삼고 재현율이나 정밀도 등의 모델 성능 평가지표를 이용하지만 기법별로 고려 요소가 다를 수 있다

| 구분             | 평가기준                            |
| -------------- | ------------------------------- |
| 지도학습(분류형 모델)   | - 분류 정확도<br>- 평균오차율<br>- 오류 재현율 |
| 비지도 학습(설명형 모델) | - 집도 소속률<br>- 데이터 밀도 및 군집도      |
| 기타(텍스트 마이닝 등)  | - 텍스트 매칭률<br>- 문서 분류율           |
- 머신러닝 모형을 선정할 때에는 컴퓨터 복잡성, 예측 용이성, 해석 편이성을 고혀하여 모형을 선정한다. 머신러닝 모형을 최종모형으로 선정할 때 해석 용이성은 떨어지지만, 가장 성능이 좋은 부스팅 나무모형이나 서포트벡터머신을 최종 모형으로 선정하기도 한다. 그러나 비선형 SVM이나 핸덤포레스트는 상대적으로 데이터에 대한 적합도는 높은 편이지만 실제 운영 환경으로 배포하기가 그다지 좋지는 못한 특징이 있다
- 가장 성능이 좋은 모델이 최종 모델 성능의 상한을 제시하게 되고 이를 기반으로 최적의 성능에 버금가는 해석이 용이한 모형을 최종 모형으로 탐색하기도 한다
- 예를 들어, 다변량 적응휘귀스플라인, 부분 최소 제곱회귀 분석, 일반화가법모델, 나이브 베이즈 모형이 대표적임
- 한편 분류예측 모델에서 데이터에 대한 정분류율을 비교하지만 우/불량 변별을 제대로 하는 모형이 좋은 예측 모형의 기준이 될 수 있고, 구축된 모형에 새로운 데이터를 적용했을 때 분류성능 측면에서 차이가 크지 않아야 한다는 안정성 조건을 만족하는 것도 필요함

나. 최종모형 분석결과 검토
- 최종 모형을 선정할 때에는 다양한 이해관계자(분석가, 데이터 처리자, 고객 등)가 모여 분석 모델에 대한 결과를 리뷰하고 검토 회의를 통해 최적의 분석 모델을 선정하는 과정이 필요하다
- 최적의 분석 모델 선정을 위해서는 분석 모델에 대한 성능 평가 기준과 함께 해당 모델의 현업에서의 실질적인 활용가능성 또한 중요한 요소로 검토되엉 한다
- 해당 모델의 성능이 좋더라도 분석 알고리즘을 수행할 때 활용한 데이터셋이 한정적이거나 해당 데이터를 실제로 확보하기 어려운 경우에는 다음 순위의 분석 모델을 선정할 수밖에 없기 때문

다. 분석 알고리즘 결과 비교
- 최종 모형을 선정하기 위해서는 분석 목적에 부합하는 여러 알고리즘별로 동일한 데이터에 학습시켜 모델 성능을 최종 선정 기준에 의해 평가를 실시한다
- 각 평가기준에 따라 분석 알고리즘별 성능 값은 차이를 보이므로 정량적인 기준에서 최종 선정에 효율적일 것이다. 또한 정분류율이 높아 분류 목적에서 부합하는 알고리즘도 우/불량 변별력이 떨어지는 경우를 확인할 수 있고, 데이터에 대한 반응률 역전 현상이 나타나는 분석 알고리즘도 있다
- 선정된 최종평가 기준과 분석 결과 검토를 종합하면 분석 목적에 가장 부합하는 분류 예측 성능이 가장 우수한 모형을 선정할 수 있고, 이를 이용하여 분석 모형을 구축할 수 있다

라. 챔피언 모델 등록
- 분석 모델에 대하여 최종 검토한 후 최종 모델을 선정한다. 해당 빅데이터 분석 모델은 챔피언 모델로 등록되며, 추후 빅데이터 분석 모델 개선 작업을 통해 업데이트 및 교체될 수 있다

## 분석 결과 해석
### 분석모형 해석
- 실제 현업에서 알고 싶어 하는 다음의 질문 유형에 대한 답을 구하는데 어떤 부넉 모델링이 적합하며 또 분석 결과를 가장 효율적이면서 효과적으로 해석할 수 있는 방법을 모색해 볼 수 있다

|          | 서술적 분석                                            | 진단분석                                            | 예측분석                                                            | 규범분석                                                               |
| -------- | ------------------------------------------------- | ----------------------------------------------- | --------------------------------------------------------------- | ------------------------------------------------------------------ |
| 질문       | - 무슨 일이 일어났는가?(탐구적 분석)<br>- 무슨일이 일어나고 있는가?(이상 탐지) | 왜, 어떻게 일어났는가?(모델링, 실험)                          | 무슨 일이 일어날 것인가?(예측 기법)                                           | - 최선의 대응은 무엇인가?(실시간 대응)<br>- 최선의 상황을 위해 필요한 조치는 무엇인가?(개인화 추천, 최적화) |
| 설명       | 과거 또는 현재 데이터를 통해 무엇이 일어났고 일어나고 있는지를 파악하기 위한 분석    | 과거 데이터를 통해 왜 일어났는지 찾기 위한 분석                     | 현재 생성되는 데이터를 통해 무엇이 일어날 것인지 예측하는 분석                             | 조직이 원하는 결과를 달성하기 위해 최적솔루션을 도출하고 작업을 제시하는 분석                        |
| 분석 모델링   | 기술통계량, 확률분포, 상관관계, 회귀분석                           | 군집분석, 요인분석, 다중회귀분석, 베이지안군집, KNN, 주성분분석          | 시계열분석, 의사결정나무, 앙상블, 부스팅, SVM, 신경망, 나이브 베이즈                      | 민감도 및 시나리오 분석, 선형 및 비선형 프로그래밍, 몬테카를로 시뮬레이션                         |
| 분석 결과 해석 | 특정 시점 또는 특정 기간에 발생한 결과를 보여주는 간단한 보고서 및 기술통계 시각화   | 발생 패턴을 파악하거나 데이터 분류 또는 원인의 요인을 찾는 특성요인도, 친화도 제시 | ㅣ간에 따른 변화값은 꺽은선 그래프, 비슷한 성질의 개체가 서로 묶이는 과정을 계통도로 표현해 데이터 구조를 제시 | 불확실성의 효과를  측정하기 위해 확률분포, 난수를 이용해 반복계산시 특정 확률분포도 제시                 |

가. 데이터 시각화
1) 개요
- 많은 조직이 앞서 살펴본 것처엄 분석 결과의 효과적인 해석방법으로 또는 당면한 문제에 대해 효과적인 답을 찾고자 데이터 시각화를 활용한다
- 데이터 시각화는 방대한 양의 데이터에 대한 이해를 돕기 위해 그림이나 도형 등의 그래픽 요소들을 이용하여 데이터를 묘사하고 표현하는 과정
- 분석을 바탕으로 한 시각화는 사용자가 방대한 양의 ㄷ이터를 탐색하고 이해하도록하는 시각적 표현 방법과 인터랙션 기술을 이용해 추상적 정보를 직관적으로 전달하기 위한 시각화 접근법 모두에 초점을 맞추고 있다
- 따라서 데이터를 바탕으로 한 시각화는 데이터에 감춰진 의미를 발견하여 데이터를 논리적으로 이해하는 데 도움을 주며, 데이터로부터 정보를 습득하는 시간 절감으로 즉각적인 상황 판단과 빠른 의사결정을 내릴 수 있는 수단이 된다
- 분석 결과를 시각화하는 주요 목적은 그래픽 의미를 이용해 명확하고 효과적으로 의사소통하기 위함이고, 정보전달과 설득을 위해 활용됨

| 정보전달                                                                                                                                            | 설득                                                                                                                                        |
| ----------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| - 데이터에 내재된 정보를 간단하고 정확하게 전달, 분석할 수 있는 실용적이고 과학적 측면의 목적<br>- 정보형 메시지의 객관적 표현에 초점<br>- 최근 방대한 데이터에서 중요한 정보를 선택해 시각적 효과를 극대화시키는 데이터 저널리즘으로써 역할을 수행 | - 데이터를 통해 전달하고자 하는 메시지에 대한 공감, 설득 등의 반응을 유도하는 추상적이고 예술적 측면의 목적<br>- 데이터 자체보다 데이터를 기초로 해석된 의미 전달에 초점<br>- 한장의 그림이 책 한권의 설명보다 더 설득력 있을 수 있음 |

2) 시각화 기능
	가) 설명/탐색/표현

| 기능  | 설명                                                                                                                                                                                  |
| --- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 설명  | - 시각화를 통해 전달하려는 메시지와 주요 분석 결과를 설명하는 기능<br>- 설명적 시각화는 데이터의 유의미하고 흥미로운 요소를 명확하게 보여주어야 함                                                                                               |
| 탐색  | - 데이터에 숨겨져 있는 관계와 패턴을 찾기위한 시각적 분석 기능<br>- 데이터의 유의미하고 흥미로운 요소를 사용자가 직접 탐색 가능<br>- 탐색적 시각화는 다양하지만 유한한 경험 제공<br>- 머신러닝 알고리즘을 접목해 데이터를 파악하고 이를 통해 사람이 파악할 수 없었던 결과를 자동으로 시각 추출하는 방법 연구중 |
| 표현  | - 데이터 활용 개인 작품이나 예술적 표현으로 스토리 전달과 공감을 일으키기 위한 기능<br>- 표현적 시각화: 심미적 측면에서 감정적 반응, 데이터에 대한 다양하고 풍부한 해석 제공<br>- 인포그래픽, 워드 클라우드                                                          |
	나) 데이터의 규칙과 패턴 검증
	

| 분석결과   | 검증대상  | 검증 내용                              |
| ------ | ----- | ---------------------------------- |
| 범주, 비율 | 범위    | 값의 범위 파악                           |
|        | 분포    | 개별 변수, 변수의 조합이 갖는 분포 형태 파악         |
|        | 순위    | 크기 기준 데이터 순서 확인 / 최댓값, 사분위수 등      |
|        | 측정    | 값이 갖는 중요성 파악                       |
| 추세, 패턴 | 방향    | 값이 증가하거나 감소하는 등 변화 확인              |
|        | 패턴    | 선형이나 지수형 또는 순환형으로 변하는지 확인          |
|        | 속도    | 추세가 어느정도로 급한지 파악                   |
|        | 변동패턴  | 반복 패편, 변동, 폭, 무작위 패턴 등 확인          |
|        | 중요도   | 확인한 패턴이 중요한 신호인지, 잡음인지 파악          |
|        | 교차    | 변수 사이 교차, 중헙 발생 여부 / 교차점이 발생하는지 확인 |
| 관계, 연결 | 예외    | 이상값 또는 극한값과 같은 정상범위를 벗어난 변수 파악     |
|        | 상관성   | 변수 간 관련성이 강하거나 약한 상관관계 존재 확인       |
|        | 연관성   | 변수와 값의 조합 간 의미있는 관계 파악             |
|        | 계층 관계 | 데이터 범주의 구성, 분포, 관련성 파악             |

다) 데이터의 시각적 표현
- 데이터에 따라서 변할 수 있는 일종의 시각적 차원으로 주로 크기, 색상, 위치, 네트워크, 시간, 다중표현기법을 기준으로 함

| 형식    | 표현 방법                                     |
| ----- | ----------------------------------------- |
| 크기    | 면적이나 도형 모양의 확대/축소 이용/ 직관적 구별 가능해 가장 많이 사용 |
| 색상    | 데이터 셋이 클 때 효과적. 규칙성과 특이성 구분               |
| 위치    | 장소와 데이터를 연결하거나 잔소와 연결된 시각화에 이용            |
| 네트워크  | 데이터 사이의 관계, 데이터를 노드로 연결하여 표현              |
| 시간    | 시간 순서에 따른 데이터 표현                          |
| 다중 표현 | 크기, 색상, 위치 등의 표현을 혼합 사용                   |

3) 시각화 요건
*시각화 기능과 혼동하지 말기*
- 분석결과의 의미를 효과적으로 전달하기 위해서는 시각적 결과물이 심미적인 형태와 기능적인 요소가 조화를 이루어야 한다
- 이상적인 시각화란 단지 명확하게 의사를 전달하는 데 머물러서는 안되고 보는 사람을 집중/참여하게 만들어야 한다

| 구분          | 설명                                                                                                                                                                                                                                                                      |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 기능적  <br>측면 | - 시각화를 정보전달과 설득에 효율적으로 적용하기 위한 원칙에 관한것<br>- 데이터로부터 정보 습득 시간 절감으로 즉각적 상황 판단을 가능하게 하려는 의도<br>1. 단순하게 시각화<br>2. 시각화 차트는 의사결정 문제의 근거로 사용됨<br>3. 의사결정 효율화를 위해 불필요한 정보 배제<br>4. 핵심 메시지가 담겨야 함                                                                                 |
| 심미적<br>측면   | - 시각화를 전보전달과 설득에 효과적으로 적용하기 위한 요건에 관한것<br>- 보는 사람들이 시각적 결과물에 집중하게 하고 참여하게 만드려는 의도<br>1. 정보 혹은 메시지를 직관적 이해 가능해야 함<br>2. 흥미 유발, 주목성을 높일 수 있어야 함<br>3. 정보를 쉽고 친근하게 전달 -> 보다 다양한 사람이 접근하도록 해야함<br>4. 관계와 비교를 명확히 표시 -> 추가 정보, 스토리 제공<br>5. 데이터를 입체화하여 거시/미시적 시각 등 수직적 구조 부여 |

4) 시각화 유형
*유형과 그래프 매칭은 기본이므로 반드시 숙지*

| 유형        | 설명                                                                                                 | 기법                                                     |
| --------- | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| 시간<br>시각화 | - 시계열 데이터의 변화에 대한 패턴을 찾고 표현<br>- 장기간 걸쳐 나타나는 값의 변화나 경향을 추적<br>- 시간의 전후관계를 감안하면 값의 의미를 더 분명하게 이해 가능 | - (누적)막대 그래프<br>- 산점도<br>- 선그래프<br>- 계단식 그래프<br>- 영역차트 |
| 분포<br>시각화 | - 분류에 따른 변화를 최대, 최소, 전체 분포 등으로 구분<br>- 전체에서 부분 간 관계 설명                                             | - 파이 차트<br>- 도넛 차트<br>- 트리맵                            |
| 관계<br>시각화 | - 집단 간 상관관계를 확인하여 다른 수치의 변화 예측                                                                     | - 산점도<br>- 버블차트<br>- 히스토그램                             |
| 비교<br>시각화 | - 각각의 데이터 간 차이점과 유사성 관계 확인 가능                                                                      | - 히트맵<br>- 평행좌표 그래프<br>- 페르노프 페이스                      |
| 공간<br>시각화 | - 지도를 통해 시점에 따른 경향, 차이 등 확인 가능                                                                     | - 등치선도<br>- 도트맵<br>- 카토그램                              |

5) 시각화 절차
*프로세스 3단계와 특징*

| 구조화                                                                        | 시각화                                               | 시각표현                                                                  |
| -------------------------------------------------------------------------- | ------------------------------------------------- | --------------------------------------------------------------------- |
| - 시각화 목표 설정<br>- 데이터 표현 규칙과 패턴 탐색 및 도출<br>- 시각화 요건 정의<br>- 사용자 시나리오/스토리 작성 | - 시간<br>- 분포<br>- 관계<br>- 비교<br>- 공간시각화<br>-인포그래픽 | - 그래프 보정<br>- 전달 요소 강조<br>- 그래프 품질 향상<br>- 인터렉션 기능 적용<br>- 시각화 결과물 검증 |

| 단계   | 설명                                                                                                                                                                                                                             |
| ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 구조화  | - 데이터 시각화 목표를 설정하고 분석 결과를 토대로 데이터 표현 규칙과 패턴 탐색<br>- 시각화를 위한 요건을 정의한 후 사용자에 따른 시나리오를 작성하고 스토리를 구성<br>- 데이터 수집, 정제하는 과정을 수집 및 탐색 > 분류>배열>재배열의 4단계로 나눈 뒤 시각화를 위한 구조화에 초점을 맞춤                                                      |
| 시각화  | - 주로 분석 도구에서 제공하는 그래프나 분석 도구의 특성에 따른 시각화<br>- 구조화 단계에서 정의된 시각화 요건, 스토리를 기반을 ㅗ적절한 시각화 도구와 기술을 선택하여 데이터 분석 정보의 시각화를 구현하는 단계<br>- 각종 시각화 툴에서 일반적으로 제공하는 그래프 스타일의 원리, 쓰임새 숙지가 중요                                                   |
| 시각표현 | - 시각화 의도를 강화해 전달하기 위해 분석 도구에서 만든 결과물에 별도 그래픽 요ㅗ를 추가해 완성<br>- 최종 시각화 결과물이 구조화 단계에서 정한 목적과 의도에 맞체 구현되었는지 확인<br>- 세부 데이터 시각화를 위한 그래픽 7요소. 전체적인 시각화 완성을 위한 그래픽 디자인의 기본 원리, 인터렉션 디자인을 통해 방대한 양의 데이터 시각화를 탐험헐 수 있게 하는 다양한 방법을 습득해야 함 |

6) 시각화 도구
- 시각화 구현을 위해 사용되는 시각화 도구에는 분석 플랫폼 및 라이브러리 등이 있다.
- 시각화 구현 도구는 단순한 그래프 형태로 제공하는 것에서부터 데이터의 분석과 시각화 결과물을 보고서 형식으로 제공하는 기능, 디자인이 강화된 인포그래픽 형태로 표현해주는 솔루션까지 매우 다양하다
시각화 구현 도구들 읽고 넘어감

### 비즈니스 기여도 평가
가. 개요
- 데이터 분석 결과를 활용하거나 실질적인 실행을 통해 얻게 되는 비즈니스 영향도와 효과의 긍정적 측면을 말함
- 일반적으로 데이터 분석을 통해 효율 증대, 비용 절감, 위험 감지, 빠르고 더 나은 의사결정 지원 등의 효과를 거든다고 알려져 있지만, 비즈니스 기여도에 대한 이해는 기업에서 수행하는 데이터 분석 목적을 통해 살펴보는 것이 타당함
- 기업의 데이터 분석 목적은 운영 효율 향상(생산성 향상과 리스크 감소)과 매출 증대(기존 매출 증대와 새로운 매출 창출)로 크게 구분할 수 있다
- ![[Pasted image 20240325140325.png]]
- 기업의 데이터 분석 목적은 사실상 사업과 관련한 6가지 근본적인 질문에 대한 답을 구하고자 하는 것이며, 이 질문들에 대한 인사이트를 분석 결과로부터 도출하여 이를 경영전략 수립과 의사결정에 적극 활용해야만 달성할 수 있다

- ![[Pasted image 20240325140317.png]]
- 어떤 일이 어디에서, 얼마나 많이 일어났는지에 대한 관찰과 보고는 대부분 기업에서 일상적인 보고에 초함돼 있지만, 그 사건이 왜 어떻게 일어났는지에 대한 분석은 덜 이루어짐. 나아가 리스크를 줄이기 위해서 현재 무슨 일이 있어나고 있는지를 탐지해 실시간 대응을 위한 분석은 약 30% 정도, 미래에 무슨 일이 일어날 것인지를 예측해 최선의 결과가 나오도록 최적화하는 분석은 10% 미만의 기업에서 수행된다는 조사결과가 있다

나. 비즈니스 기여도 평가
1) 필요성
- 기여도 분석이란 분석 결과가 기업 비즈니스 성과와 가치 창출의 향상에 얼마나 기여했는지를 이해하는 과정을 말함
- 기여도 분석의 목적은 분석 모델링의 다양화에 따른 데이터 분석의 비즈니스 가치 효율을 증대 시키는 것
- 기여도 분석은 데이터 분석 결과가 업무 수행의 정확성을 높여 비용이나 만족도를 개선하거나 추가 수익을 창출한다는 것을 객관적인 지표로 입증해야 하므로 쉽지 않다. 비즈니스 관점에서 성공여부를 판단할 수 있도록 기준을  설정해야 하며, 해당 기준은 구체적이고 측저 가능해야 한다
- 기여도 산출에는 해당 업무 전문가의 도움이 절대적으로 필요하며 재무정보 입수를 위해서는 재무팀과의 논의가 필요함

2) 평가 기법 *각 기법과 해당 설명 매치*
- 투자 대비 효과를 정량화함으로써 평가할 수 있다
- 정량화 기법

| 기법          | 설명                                                                                                            |
| ----------- | ------------------------------------------------------------------------------------------------------------- |
| 총소유비용(TCO)  | - 하나의 자산을 획득하려 할 때 주어진 기간동안 모든 연관 비용을 고려할 수 있도록 확인하기 위해 사용                                                    |
| 투자대비효과(ROI) | - 자본 투자에 따른 순 효과의 비율<br>- 투자타당성                                                                               |
| 순현재가치(NPV)  | - 특정 시점의 투자금액과 매출금액의 차이를 이자율을 고려하여 계산한 값<br>- 예상 투자비용의 할인가치를 예상 수익의 할인가치에서 공제했을 때, 나온 값을 합한 금액(미래 시점의 순이익 규모) |
| 내부수익률(IRR)  | - 순 현재가치를 '0'으로 만드는 할인율<br>- 연 단위 기대수익 규모                                                                     |
| 투자회수기간(PP)  | - 누계 투자금액과 매출금액의 합이 같아지는 기간<br>- 프로젝트의 시작 시점부터 누적 현금흐름이 흑자로 돌아서는 시점까지의 기간                                     |

다. 비즈니스 기여도 평가 수행 준거
- 성과 측정을 위해 두 가지 기준이 제시됨
1) 모델링 기법별 정량적 효과 측정

| 모델링     | 측정 항목                                                                                                                 |
| ------- | --------------------------------------------------------------------------------------------------------------------- |
| 데이터 마이닝 | - 검출률이 증가하거나 향상도가 개선돼 발생되는 정량적 효과를 제시<br>- 매출 증가, 주가 상승                                                               |
| 시뮬레이션   | - 처리량, 대기시간, 대기행렬의 감소를 통한 정량적 효과 제시<br>- 공징시간 단축, 수율 증가로 연매출 증가                                                       |
| 최적화     | - 인력, 설비, 예산 등 기업이 현재 보유한 자원으로 최대 성능을 낼 수 있는 최적의 해결책 도출<br>- 목적함수가 증가한 만큼의 정량적 효과 제시<br>- 최적 대안으로 별도 라인 증설없이 연간 비용 절감 |

2) 비즈니스 수행 시 비용 요소 고려
- 해당 빅데이터 프로젝트의 비용-효과 분석을 구축하여 프로젝트의 비용과 비즈니스에 대한 잠재적 효과를 비교하며, 이 비교는 재무적 측정치를 사용하여 가능한한 구체적이어야 한다
- 사업 특성에 따라 비용요소가 이미 영업이익률이나 공헌이익에 반영됐을 수 있으므로 중복으로 비용 요소를 차감하면 안됨
- 타 사업부문과의 중복적인 측면을 고려해야 하나 단위 프로젝트에서의 수익과 비용으로 평가하는 것이 원칙이며, 투자비용이 과다한 경우 타 과제와의 분배를 협의해야 함

## 분석결과 시각화
### 시공간 시각화
*이산형, 연속형 구분 문제*
가. 시간 시각화
- 시간단위 등으로 된 시계열 데이터는 가장 특징적 요소가 트렌드(경향성)로, 장기간에 걸쳐 진행되는 변화 또는 추적에 주로 사용
- 시간 시각화는 시계열의 데이터 값의 변화에 대한 패턴을 찾고 표현하는 방법

1) 이산형 시계열 데이터로 시간 시각화 구현
	가) 막대그래프
	- 시간축은 시간 순서대로 정렬된 시간의 특정 시점을 나타내고, 값축은 그래프의 크기 범위를 나타내어 시간에 다라 변화하는 양의 상대적인 차이를 비교하기위해 사용
	- 시각적 차이 강조를 위해 다양한 색을 적용할 수 있으나 모든 막대가 동일한 범위나 상태에 있는 경우엔 일관성 유지를 위해 색상을 사용하지 않는 것이 시각적으로 도움이 됨
	나) 누적 막대 그래프
	- 한 구간이 몇 개의 세부 항목으로 구분되면서 전체 합이 의미가 있을 때 사용
	- 가로축 표현은 동일하나 셀축은 한 구각ㄴ에 해당하는 막대가 몇개의 세부 항목이 누적됨
	다) 점그래프
	- 값의 크기에 해당하는 위치에 점으로 표시. 각 점의 위치 변화를 통해 데이터 크기 변화 파악
	- 각점을 선으료 연결하면 선그래프
	- 가로축이 시간이 아니라 다른 변수면 산점도로 사용됨
2) 연속형 시계열 데이터로 시간 시각화 구현
	가) 히스토그램
	- 가로축에 정량적인 값으로 표현된 특정한 간격을 표시하고 세로축에 각 구간에 대응하는 값의 빈도를 막대의 높이로 표현하는 분포그래프
	나) 선그래프
	시간에 따른 값의 지속적인 변화율 또는 추세를 선으로 표현하므로 변수의 변화를 명확히 표시하거나 트렌드 또는 변화율 정보가 중요한 경우에 적합함
	다) 계단식 그래프
	- 연속된 두 시점에서 값의 변화가 전혀 없거나 급격하게 증가하거나 감소하는 경우라면 선 그래프는 적절하지 않음
	- 두 지점 사이를 선분으로 연결하기보다는 변화가 생길 때가지 가로축과 평행하게 일정한 선을 유지하다가 다음 값으로 변하는 지점에서 급격하게 뛰어오르는 계단형으로 그리는 것이 적절함
	라) 영역형 차트
	- 시간에 따라 값의 크기 변화를 나타낸다는점에서는 선 그래프와 동일하지만, 색을 채운 영역으로 보여준다는 점과 y축의 값은 0부터 시작해야 한다는 점이 차이

나, 공간 시각화
*지리-공간 데이터 매핑하는 방법, 등치선도*
- 공간데이터는 지구 표면에 위치하는 객체와 사건, 현상을 기록한 것으로 실세계에서 위치 정보를 포함한 형태로 존재함
- 공간 시각화는 지도상에 해당하는 위치 정보를 표현하는 방법. 모든 데이터에 시간을 적용하면 지도 하나는 한 지점의 한순간을 나타내고, 여러 장의 지도를 통해 다양한 시점의 자료 표현 가능
- 구글 지오차트는 지명만 알아도 쉽게 그려볼 수 있음
1) 지리-공간 데이터 매핑 방법
	가) 등치 지역도
	- 지도상에서 지리적 단위로 데이터에 대한 의미를 색상으로 구분하여 표시
	- 색상은 정략적인 값어 근거하여 채도나 밝기를 차례로 변화시켜 적용. 시간에 따라 증가하는 값을 표현할 경우는 신중히 선택
	- 등치 지역도는 지리적 단위별로 인구가 균등하게 배분되지 않으면 단점이 됨. 데이터가 나타내는 값에 의해서가 아니라 지리적으로 차지하는 면적이 큰 경우 실제 값을 왜곡 시킬 수 있기 때문임
	나) 도트 플롯맵
	- 지도상의 위도와 경도에 해당하는 지리적 좌표에 산점도 같이 점을 찍어 표현
	- 시간 경과에 따라 점진적으로 지리적 확산을 나타내는 경우 자주 사용
	다) 버블 플롯맵
	- 지리적 좌표 위에 정량적인 데이터 값의 크기를 나타내는 서로 다른 크기의 원형 표기
	- 도트 플롯맵이 지리적 산점도라면 버블 플롯맵은 버블 차트에 가까움
	라) 등치선도
	- 등치 지역도의 데이터 왜곡 결점을 극복하기 위해 색상의 농도를 활용하여 표현한 방법
	마) 카도그램
	- 지역의 값을 표현하기 위해 지리적 형상 크기를 조절하여 재구성된 지도와 같이 왜고되고 비꿀어진 화면으로 나타냄
	- 위치, 형태, 크기를 사전에 익숙하게 알고잇ㄴ느 것을 이용하여 해당 정보를 전달하는 효과

### 관계 시각화
*특징, 설명*
- 다변량 데이터 사이에 존재하는 연관성, 분포와 패턴을 찾는 시각화 방법
- 한 수치의 변화를 통해 다른 수치의 변화를 예측하는데 산점도, 산점도 행렬, 버블 차트 등이 적합

가. 유형
1) 산점도 행렬
- 산점도는 시간적인 변화를 알아보는 것 외에도 데이터의 관계를 시각화하는 데 적합한 방법이며, 군집화와 이상치 패터을 파악하기에 유용함
- 산점도 행렬은 다변량 변수를 갖는 데이터에서 가능한 모든 변수 쌍에 대한 산점도들을 행렬 형태로 표현한 그래프
- 데이터 분포와 변수들의 밀접고, 자료 분포에 존재하는 패턴을 신속하게 식별할 수 있게 해줌. 데이터 탐색 과정에서 유용함
- 산점도 행렬의 대각선 위치는 동일한 변수에 대한 산점도 위치이므로 비워두거나 변수 이름을 표기한 레이블 표시
2) 버블 차트
- 산점도에서 데이터 값을 나타내는 점 또는 마크에 여러 가지 의미를 부여하여 확장된 차트.
- 세 가지 요소(가로축, 세로축 변수/버블의 크기)의 상관관계를 표현할 수 있는 방법
- 수십개 또는 수백 개의 값을 갖거나 값들이 몇 자리씩 차이가 있는 데이터셋에 유용하며, 다양한 크기의 버블로 특정 값들을 시각적으로 표한하고자 할 대도 사용 가능

### 비교 시각화
*그림과 설명 함께 숙지. 출제 가능성 높음*
- 많은 다변량 변수를 포함하는 자료의 경우 관심 있는 변수를 선택하여 변수 관계를 살펴보거나 모든 변수를 고려한 상황에서 개체들을 비교하기는 쉽지 않다
- 비교 시각화는 이를 해결하기 위해 다변량 변수를 갖는 자료를 제한된 2차원에 효과적으로 표현하는 방법.

가. 비교시각화 유형
1) 플로팅 바 차트
- = 간트 차트. 막대가 가장 낮은 수치에서부터 가장 높은 수칚지 걸쳐있는 것으로 표현됨. 축의 시작점은 0이 아닐 수 있다
- 범주 내 값의 다양성을 파악할 수 있으며, 범주간 중복이나 이상치 파악도 가능
2) 히트맵
- 표와 같은 형태로 행 방향은 곽측 개체, 열 방향은 각각의 변수를 나타냄. 표의 각 칸은 값, 수치로 나타내지 않고 색상을 이용하여 값을 표현함
- 한 행을 왼쪽에서 오른쪽으로 보는 경우는 하나의 관측 개체에 대하여 모든 변수를 파악, 한 변수에 대응하는 한 열을 위에서 아래로 보는 경우는 한 변수 관점에서 관측 대상 전체를 비교하는 것이 가능함
- 데이터가 지나치게 많은 경우 더 혼란스러울 수 있으므로 적당한 색상을 선택하여 정렬을 통해 데이터에 대한 가독성을 높이도록 해야 함

3) 평행좌표 그래프
- 2차원 평면에 각 변수를 나타내는 축을 평행으로 배치해서 다변량 데이터를  표현하는데 매우 효율적인 방법
- 하나의 축은 하나의 변수를 나타내며 각각의 축을 평행하게 배치하고, 한 축에서 윗부분은 변숫값의 최댓값, 아래는 최솟값
- 한 데이터의 주어진 값을 해당 변수 축의 위치로 대응시키고 이 지점들을 선으로 연결하면, 연결선 하나는 데이터 하나를 의미하며 데이터 수만큼 연결선이 생성됨
- 연결선들이 변수에 해당하는 각 축에서 띠는 모양을 통해 데이터의 집단적인 경향성과 변수간의 관련성을 파악할 수 있게 해준다

4) 체르노프 페이스
- 데이터의 당ㅇ한 변수를 사람의 얼굴 하나로 표현하는 방법
- 보는 사람에 따라 데이터가 의미하는바와 다른 해석이 될 수 있다는단점이 있음
- 통상 유용성 보다는 전문가의 흥미가 주 목적

5) 스타 차트
- 중앙에서 외부 링까지 이어지는 몇개의 축을 그리고, 전체 공간에서 하나의 변수마다 축 위의 중앙으로부터의 거리로 수치를 나타냄. 변수마다 축 하나씩을 대응시켜 해당 변수의 크기에 따라 축의 길이를 만들며, 각 축의 끝을 연결하여 별 모양의 다각형을 만든다
- 이 때 각 축츼 중심점 = 해당 변수 최솟값, 바깥 점 = 최댓값
- 데이터 수만큼의 다각형을 생성해 각 다각형 모양 비교 가능
- = 레이터 차트, 거미 차트

6) 다차원 척도법
- 데이터셋상의 개별 데이터 간의 유사도를 바탕으로 시각화하는 방법
- 대상 간의 유사성 또는 ㅓㄴ호도에 의거해 대상을 다차원 공간 속에 유사성이 작은 대상끼리는 멀리, 유사성이 큰 대상끼리는 가까이 위치 시킴
- 다차원 척도법은 표현하고자 하는 객체 간 간격이 발생하는, 즉 거리행렬을 포함하는데이터 시각화에 유용
### 인포그래픽 *개념과 유형*
가. 개념
- 인포메이션 + 그래픽의 합성어. 중요한 핵심 정보를 하나의 그래픽으로 표현해 사람들이 손쉽게 해당 정보를 이해할 수 있도록 만든 그래픽 메시지
- 정보를 구체적, 표면적, 실용적으로 전달한다는 점에서 일반 그림이나 사진 등과는구별되며, 스토리텔링이 가능하다는 점에서 데이터 시각화 기존 도표나 그래픽과 다르다

나. 활용
- 신문, 방송 등의 미디어에서 활용도가 높다. 뉴스 그래픽이라 불리기도 한다
- 주목받는 이유 = 소셜 큐레이션의 수단으로 이용되기 때문
- 독자의 마우스 움직임에 따라 쌍방향성을 구현한 '인터랙티브 인포그래픽' 시도중

다. 유형
1) 전달 메시지
-  정보형 메시지와 설득형 메시지로 나뉨

2) 메시지 전달 형태

| 지도형        | - 특정 국가나 지역의 지도 안에 정보를 담는 방식               |
| ---------- | ------------------------------------------ |
| 도표형        | - 다양한 표와 그래프를 사용해 방대한 정보를 함축적으로 표현하는 방식    |
| 타임라인/프로세스형 | - 주제 관련 히스토리 또는 일련의 과정을 한 눈에 들어오도록 나타내는 방식 |
| 스토리텔링형     | - 하나의 사건이나 주제에 대해 이야기로 구성하는 방식             |
| 비교분석형      | - 두 가지 이상의 제품이나 개념을 비교하는 방식                |
| 만화형        | - 만화적 요소를 활용해 흥미성 자료에 적용한 방식               |

라. 인포그래픽 디자인 프로세스
데이터 분석 단계 > 시각하 단계 > 검증 단계

## 분석결과 활용
### 분석 모형 전개
*단계에서 수행해햐 하는 활동들을 전반적으로 파악*
- 분석 모형 개발 및 운영 절차에 따라 모델 성능 평가가 완료되면 이 프로세스의 마지막 과정은 완성된 모형을 실제 업무에 적용하기 위한 전개 단계임
- 이 단계에서는 분석모형을 업무에 적용 시킬 뿐만 아니라 모니터링과 유지보수를 통한 지속적인 운영과 개선시키는 과정을 다루는 만큼 방대한 업무가 수행된다

가. 분석모델 배포
- 배포는 분석 모델을 운영계 환경과 통합하고 이를 실행하는 것을 의미
- 빅데이터 기반을 ㅗ도출된 분석 모델을 비즈니스 의사결정에 활용하기 위해서는 운영시스템과의 통합이 요구되며, 통합은 분석모델을 운영 시스템에 적용시키는 방식으로 구현된다. 통합은 분석 모델을 운영 시스템에 적용시키는 방식으로 구현됨
- 모델을 개발하는 조직과 배포하는 조직이 다르기 때문이고 ,결국 개발계와 운영계 간 서로 다른 환경으로 인한 프로세스 단절이 가장 큰 원인임
- 이상적인 상황은 조직이 동일한 프로젝트에서 다양한 언어로 개발된 모델의 성능을 평가하여 챔피언 모델을 선택 및 배포하는 것

나. 모델 배포 과정 이슈

| 이슈          | 설명                                                                                                                                                                                                          |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 서로 다른 환경    | - 모델 개발에 사용한느 언어가 운영계에서 평소 사용하는 언어가 아니므로 다른 언어로 변환, 호환을 위해 추가적 인터페이스 개발이 필요할 수 있다<br> ex. 파이썬 > 자바 변환은 매우 어렵고 성능 문제 발생 가능성<br>- 하나의 모델을 적용하기까지 통상적으로 수주-수개월 필요하므로 이같은 변환 작업 중에 모델이 변경되거나 유효성이 떨어져 파기될 수도 있다 |
| 모델 저장소 부재   | - 모델을 저장하는 저장소가 없다면 개발된 수많은 모델 제작자, 사용자, 수정 내용 추척 불가<br>- 우녕ㅇ계에 배포된 모델이 가장 적절한 모델인지 파악도 어려움<br>- 결국 옛 모델이 계속 사용되고 그리 인해 전체적인 성능 떨어짐                                                                         |
| 성능 모니터링 부재  | - 지속적 모니터링은 비즈니스에 매우 중요함<br>- 모바일 중심으로 변화 > 데이터 속성이 매일 추가 수정 삭제됨. 이러한 환경에서 비즈니스 기회를 잃지 않기 위해서는 끊임없이 변화하는 데이터 속성으로 인해 기존 모델의 예측력이 떨어지지는 않는지 지속적으로 확인해야 함                                                     |
| 규제 요구 사항 준수 | - 많은 산업에서 분석 모델과 해당 모델에 대한 통제를 더욱 투명하게 설명해야 하는 규제 압력의 증가<br>- 조직은 모델 입력, 모델링, 작동 방식, 영향을 받는 결정 등을 문서로 만들고 설명해야 함<br>- 특히 최근 데이터 은닉 알고리즘과 AI 활용이 늘면서 이러한 설명이 더욱 어려워지고 있다                                     |

다. 분석 모델 배포 과정
1) 분석 모형 적용 모듈 결정
- 가장 먼저 기존 운영 시스템 구성을 파락하여 분석 모델을 시스템의 어떤 모듈에 적용할 것인지 판단해야 함
- 통계 기반 분석 모델의 경우 개발 초기 단계부터 모델에 활용될 독립변수 데이터를 어떻게 운영 시스템으로부터 전달받을 것인지, 분석 결과는 전체 비즈니스 프로세스 및 운영시스템에서 어떠한 방식으로 활용할 것인지 명확하게 정의해야 함

2) 분석 모형 적용 방식 결정 및 구현
- 분석 모델과 운영 시스템과의 통합을 위한 방식 결정
- 모델 개발언어 혹은 통계 패키지 등을 고려하여 운영시스템 내 모듈과 어떠한 방식으로 통합할지를 결정하고 구현함. 그에 맞춰 모델에 해당하는 모듈과 웅영 시스템상의 모듈 간 인터페이스를 위한 추가적인 작업을 통해 모델과 운영 시스템 간의 통합을 구현할 수 있다
- 분석모델은 배치 시스템, 온디멘드 시스템, 스트리밍 등을 통해  실시간 시스템에 배포 가능

### 분석결과 활용 시나리오 개발
- 기업들은 강력한 분석 모델을 개발하여 중요한 의사결정에서 분석결과를 활용하고자 한다
- 이를 위해 그동안의 빅데이터 비즈니스가 실패한 주요 요인들을 분석하는 것은 새로운 분석 서비스 비즈니스 모델을 개발하는 과정에서 매우 유용함
- 주로 빅데이터 비즈니스가 실패하는 경우는 빅데이터의 ㅂ누석 목적이나 서비스 목적이 불명확하고, 분석 결과를 이용할 사용자 및 활용방안이 불명확하며, 분석 대상 데이터의 품질이 떨어지는 경우, 그리고 분석 모델에 대한 정의없이 분석에 쓸 인프라를 우선 도입할 때 발생
- 또한 분석 인사이트를 운영 환경의 적재적소에 적용하여 운영계에서 발생한 복잡하고 다양한 문제를 해결할 수 있도록 하고, 나아가 새로운 비즈니스 가치 창출에 기여할 수 있는 활용 분야를 탐색하고 개발하는 과정은 필수적이다
- 분석 결과 활용 시나리오 개발 과정

> 분석결과 활용 가능 분야 파악 →활용가능 분야 분류 → 활용 가능 서비스영역 도출→ 빅데이터 분석 서비스 모형 개발

가. 분석 결과 및 인사이트 활용 분야 발굴
- 운영 환경에서 분석 결과 및 인사이트를 적재적소에 활용할 수 있는 기회를 탐색하는 데에는 가치사슬모형을 이용할 수 있다
- 가치사슬 모형은 기업의 부가가치 생성 과정을 연결된 활동으로 나타낸 것으로 기업의 경쟁적 지위를 파악하고 향상시킬 수 있는 포인트를 차즌ㄴ데 유용함
- 가치사슬 상에서 가치가 전달되고 생성되는 과정에 함께 연결된 활동들은 분석 결과와 그로부터 도출한 분석 인사이트를 적용하기에 가장 적합한 관계에 있다고 할 수 있다

1) 활용 가능 분야 파악
- 가치사슬 관섬에서 분석 결과 및 인사이트를 적용하는데 가장 적합한 분야는 일차적으로 해당 업무와 여기에 연결된 가치사슬의 활동들이다. 이 경우 해당 분석 모델로 서비스를 개발한다면, 이미 서비스 대상이 특정되었다고 해도 무방하다
- 분석 결과ㅏ으 ㅣ일차적 활용이 가능한 활동들을 토대로 활동과 연관된 업무와 그 가치사슬에서 파생활용이 가능한 분야를 찾을 수 있다. 이는 분석 목표 정의서에 명시되어 있는활용 방안을 확대 시행하거나 해당 분석모형과 유사 혹은 연관 업무의 가치사슬에서 새로운 비즈니스 기회를 발굴할 수 있다.
- 또한 가치사슬은 총 가치의 관점에서 연결된 각 개별활동의 가치에 관심을 두기 때문에 개별 활동의 경쟁력을 높이기 위해서 수직적으로 통합하거나 확대해서 새로운 가치사실을 발견하는 틀로도 이용 가능

2) 활용 가능 분야 분류
- 분석 결과나 분석 인사이트를 활용할 수 있는 적재적소의 분야들이 발굴되었다면 다음은 분류기법을 이용하여 분야들을 적절하게 분류한다. 이는 향후 비즈니스 가능한 서비스 영역의 도출을 효율적을 ㅗ수행하는데 이용될 수 있다
- 마인드맵, 친화도, 피라미드구조도와 같은 분류기법은 업무 특성이나 요구 자원이 유사한 업무 활동끼리 묶어 붐류할 수 있도록 해주어 주로 아이디어를 분류하는ㄷ 이용
- => 토대로 서비스할 수 있는 새로운 비즈니스 기회 발견

3) 활용 가능 서비스영역 도출
- 서비스 간으 영역은 앞선 활용 가능 분야들의 ㅂ누류 결과를 기준으로 하거나 가치사슬의 통합 및 확대 관점에서 재구성하여 도출할 수 있으며, ㅇㅣ는 아래의 두 가지 유형으로 구분
- 1 유형 : 기존 분석 결과 또는 분석 인사이트를 직접 적용할 수 있는 서비스 영역. 도출한 영역을 가치사슬 상 해당 활동과 매핑함
- 2 유형 : 분석 결과를 이차적으로 활용. 일반적으로 파생 활용의 경우 분석 결과가 2개 이상의 영역에 공통적으로 활용되는 경향이 있으므로 융합 활용할 수 있도록 영역 간의 상호작용을 파악하는 것이 필요

나. 분석 서비스 모델 개발
-  신규 도출한 서비스 영역에서 새로운 수익을 창출할 수 있는 분석 모델을 개발하기 위해서는 서비스 개념을 도출할 필요가 있다
- 여기서 가장 중요한 사항은 해당 신규 분석 서비스의 사용자와 제공 가치를 정의하는 것

1) 신규 분석 서비스의 사용자와 제공 가치 정의

| 제공가치 기반                                                                                                                                                                                                     | 사용자 정의 기반                                                                                                                                                                                                         |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| - 제공 가치를 통해 사용자를 정의한 후 새로운 서비스 모형 개념 도출<br>- 분석 결과를 바탕으로 현재 제공되는 서비스를 개선할 수 있는 경우에 적합<br>- 신규 분석 서비스 모형에 대한 사용자는 기존 서비스와 동일하지만 제공가치는 달라질 수 있다<br>- 서비스 품질 관점에서 신규 데이터 분석 서비스가 제공할 가치는 신뢰성/확신성/반응성/공감성/유형성이다 | - 사용자 정의를 통해 제공가치를 정의한 후 새로운 서비스 모형 개념 도출<br>- 분석 결과를 바탕으로 새루운 사용자 그룹이나 유형 발굴에 적용<br>- 기존 서비스와 비교할 때 신규 서비스 모형에 대한 사용자와 제공 가치가 모두 달라질 수 있다<br>- 사용자 또는 고객 분류는 비즈니스 도메인에 따라 다르지만 일반적으로 인구통계학점 관점이나 라이프스타일을 고려해서 분류 |
2) 신규 분석 서비스 모형에 대한 정의
- 사용자와 제공가치가 정의되고 신규 서비스의 개념이 명확해지면 이를 바탕으로 새로운 서비스 모형 정의
- 일반적으로 서비스 명칭, 서비스 개념 설명, 사용자, 제공 가치 및 주요 기능 등의 항목을 기술하는 것으로 이행됨

3) 신규 분석 세비스 제공을 위한 채널 구축 방안
- 사용자에게 서비스를 제공하는 채널 정의

| 기존 시스템 활용                                                                   | 신규 시스템 도입                                                                              |
| --------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| - 운영 시스템에 새로운 기능을 추가하는 것으므로 운영 부서 및 유지보수 조직과 협의를 거쳐 분석 서비스 기능의 추가 방안 수립해야 함 | - 향후 해당 분석 서비스를 제공할 부서에서 시스템 개발 조직과 협의하여 분석 서비스 기능을 자체 개발하거나 외주를 통해 서비스시스템을 도입하는 계획 수립 |

다. 분석 서비스 비즈니스 모델 개발
1) 정의
- 분석 결과 및 인사이트를 토대로 새롭게 서비스할 분석에 대한 비즈니스 모델을 정의하는데 비즈니스 모델 캔버스를 이용할 수 있다
- 비즈니스 모델 캔버스는 조직이 어떻게 가치를 창출하고 어떻게 고객에게 전달하는가를 이론적으로 도식화한 조직의 설계도이다

2) 분석 서비스 시나리오 개발
- 분석을 통한 인사이트를 사용자에게 효과적으로 전달하기 위해 도입하는 일종의 스토리텔링
- 향후 제공되는 분석 서비스는 사용자의 서로 다른 이해 수준을 고려하여 사용자에게 맞춤화된 정보 수준과 내용이어야 하며 가장 효과적이면서도 이해하기 쉬운 방법으로 시각화 해야 함
	가) 활용 시나리오 도출 과정
	1. 분석 결과를 활용할 사용자 별로 필요 데이터셋 정보 기술
	2. 활용 시나리오는 기업내/외부 사용자 별로 작성
	3. 활용 시나리오에 적용할 스토리보드 기획

	나) 활용 시나리오의 스토리텔링
	분석 결과에 대한 이해와 함께 사용자와 원활한 의사소통을 하는 데 도움을 준다
	고려사항 : 사용자 데이터 정의, 시나리오 작성, 스토리보드 기획

### 분석결과 보고서 작성
가. 개요
- 데이터 분석 숳ㅇ 후 결과물들은 다양한 형태의 보고서로 작성됨
- 최종 보고서에는 이전 결과물이 모두 포함되어 결과를 요약하고 구성되어야 한다

나. 분석 보고서 유형(읽고 넘어감)

### 분석모형 모니터링
가. 개요
- 모델의 성능을 향상시키기 위해 모델 결과를 지속적으로 분석하고 모니터링 해야 함
- 분석 결과 및 인샅이트가 운영 환경의 일부가 되는 경우 모델 성능을 지속적으로 모니터링 하는 일은 비즈니스에서 매우 중요함
- 끊임없이 변화하는 데이터 속성으로 인해 기존 모델의 예측력이 떨어지지 않는지 확인
- 주기적 모니터링 > 성능 저하, 수준 낮은 분석결과 활용 방지 > 이로 인한 비즈니스 성과 악영향 예방

나. 척도
1) 범주형 분류 모델
- 정확도, 민감도, 재현율, 정밀도

2) 범주형 예측 모델
- 계속적으로 예측 오차를 추적하여 예측 오파 성향 파악. 예측 오차가 주기성을 가지는지 검토
- 일반적으로 추적신호(TS) 이용
- TS는 우선 0 부근에 이는 것이 정상. 일반적으로 -4 ~4면 정상 성능 유지 판단
- 분석 모델 점검여부 > 관리도를 활용해 결정
- 추적신호들이 상한 또는 하한 벗어남 + 추적신호들이 일정 간격에서 주기성을 가지고 상승이 지속되거나 하강이 지속되는 추이 또한 성능 저하를 의미

3) 연속형 데이터 모델
- 평균제곱오차 사용

다. 분석 모델 성능 모니터닝
- 수작업 시 개발된 모델이 많아질수록 과업 증가 > 성능 데이터 DB화하여 자동 모니터링 + 이상 시 관리 프로세스 ㅜ립이 효율적
- 원활한 운영을 위해 서브시스템별로 관리 도구와 모니터링 도구를 구현하는 것이 필요함
- 시스템의 예측을 샘플링해서 평가. 성능 저하 시 알람 코드를 작성함.
- 시스템 입력 데이터 품질 평가. 

1) 주요 성능 측정 항목
- 주요 성능 측정 항목을 정의하고 데이터를 수집하여 모니터링 실시
- 서응 모니터링은 측정 항목별 임계치와 이벤트 등급별로 알람을 통해 이벤트 모니터링에서 성능을 관리할 수 있도록 한다

가) 주기별 성능 분석 및 모니터링
나) 측정 항목별 영향 요소
(둘다 읽고 넘어감)

라. 분석 모델 모니터링 솔루션(일곡 넘어감)
- 성능 관리 전문 도구 활용

### 분석 모형 리모델링
*개념, 주기, 방안, 절차 등 숙지*
가. 필요성
1) 기존 모델 성능 저하
- 새로운 데이터를 사용해 주기적으로 훈련시키지 않으면 데이터가 오래됨에 따라 모델도 함께 성능이 저하되는 것이 일반적임
- - 비즈니스 항황의 변화나 분석 결과 적용에 따른 주변 요인들의 변화, 때로 고객에게 적용하는 경우 고객의 행동 패턴도 변화함. 빅데이터 분석은 이런 자연스러운 변화에 대응할 수 있어야 한다
- 모니터링 단계에서 모델 성능이 지속적으로 하락하는 경우 리모델링을 주기적으로 수행해야 하며, 이 과정은 자동화가 바람직함

2) 비즈니스 측면
- 데이버 분석 수행 조직은 비즈니스 측면에서 기존 분석 모델을 개선해야 함. 전사적 또는 개별 업무별로 비즈니스 상 중요한 의사결정 시점에서 활용할 수 있는 분석모델의 적합성을 체크함
- 이를 위해 자사의 각 비즈니스 모델에 대한 분석을 수행하고, 이를 기반으로 빅데이터 분석 모델 개선에 대한결정을 수행함
- 모델에 대한 학습 프로세스를 우녕앟여 창출된 가치를 지속시켜야 한다. 더 이상 유효하지 않은 모델의 매립 시기를 최적화하는 작업도 중요함

나. 모형 리모델링 주기와 방안
1) 주기
- 모형 리모델링 작업 : 기존 분석모델에 대해 데이터마이닝이나 시뮬레이션 또는 최적화를 추가적용하는과정을 진행
- 데이이터 분석 기법별 모델의 리모델링 주기는 초단기가 필요한 특수 분야를 제외하고는 대해 분기 반기 연 단위로 수행

| 분석기법   | 주기                   | 수행업무                                                              |
| ------ | -------------------- | ----------------------------------------------------------------- |
| 데이터마이닝 | 분기                   | - 동일한 데이터를 이용해 학습을 다시 하거나 변수를 추가해 학습하는 방법 사용                      |
| 시뮬레이션  | 주요 변경이 이뤄지는 시점 또는 반기 | 이벤트 발생 패턴의 변화, 시간 지연의 변화, 이벤트 처리 리소스 증가, 대기 우선순위, 자원할당 규칙 변화등을 처리 |
| 최적화    | 연 단위                 | - 목적함수계수 값 조정 또는 제약 조건 추가                                         |
2) 모형 리모델링 방안
- 모델 성능 저하 발견 시

| 방법  | 설명                                 |
| --- | ---------------------------------- |
| 재학습 | - 신규 데이터를 통한 기존 모델 재학습. 가장 일반적인 방법 |
| 수정  | - 새로운 알고리즘, 기술, 데이터로 모델 수정         |
| 교체  | - 기존 모델과는 전혀 다른 신규 모델로 교체          |
1) 기존 모델의 성능 검토
- 기존 분석모델의 활용성을 분석하여 정확도/재현율/오분류율 등 모델 평가 지표에 대한 최근 변화 여부를 점검하고, 산점도 등을 통해 현황을 분석한다
- 분석 모델에 대한 성능을 검토할 때는 특이점은 제외하고 평균적인 성능을 확인하여 최근 성능에 대한 변동성 여부를 집중적으로 관찰한 후 리모델링의 필요성을 결정한다

2) 개선용 데이터 선정
- 분석 모델 개선을 위해서는 기존 모델을 개발할 때 사용한 데이터와 함께 추가하거나 제외할 데이터가 있는지 점검하여 개선 데이터로 선정한다
- 기존 데이터 중 제외시킬 데이터가 있는지도 추가적으로 검토하여 결정한다
- 분석 모델 리모델링을 위한 데이터 선정 시 고려사항

| 주요 항목    | 고려사항                                 |
| -------- | ------------------------------------ |
| 데이터 활용도  | 분석 모델에 해당 데이터가 얼마나 활용되고 있는지 파악       |
| 데이터 변경도  | 데이터의 주기적인 변경 및 업데이트 비율               |
| 신규영향 데이터 | 분석 목적에 맞는 신규 영향 데이터가 있는지 검토          |
| 데이터 오류율  | 기존 데이터 집합에 대한 데이터 오율유 점검             |
| 기타       | 분석가의 판단 시 분석 모델에 영향이 있을 것으로 판단되는 데이터 |
- 모델 리모델링 데이터가 선정되면 해당 데이터에 대한 기본적인 형황 조사 수행
- 조사된 형황은 기록하고 선정된 데이터를 수집 및 정제하여 리모델링 모델을 분석할 수있는 데이터 형태로 변환함

3) 개선 모델 개발 위한 알고리즘 적용
- 이 단계에서 수행되는 알고리즘 적용은 기존 분석 모델을 개발할 때와 동일한 절차로 수행하며 그 절차는 다음과 같다
- 다만 개선 모델은 기존 모델보다 높은 성능을 갖는 모델로 선정될 수 있도록 파라미터를 조정하여 수행한다

	가) 개선 목적에 맞는 분석 알고리즘 선정
	
| 단계                     | 설명                                                                                                                                                                                                                                                    |
| ---------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 모델 개선에 대한<br>명확한 목적 선정 | - 분석 모델을 개선할 때에는 개선 필요성에 대한 목적을 명확히 함<br>- 본석 모델의 성능이 떨어져 개선 모델을 만드는 것인지 현업 업무 적용 가능성을 높이기 위해 개선 모델을 만드는 것인지에 대한 목적 구분<br>- 모델 개선 시 분석 모델의 성능과 함께 비즈니스 영향도 고려<br>- 비즈니스 영향도는 현업 담당자와인 인터뷰 및 모델 적용 업무 형태를 파악하여 반영                                      |
| 개선 데이터 선정 및 유형 구분      | - 개선 데이터 선정 시에는 기존에 고려되지 않았던 데이터에 대한 적용 가능성도 파악하여 데이터 선정<br>- 특히, 정형 데이터와 비정형 데이터를 혼용하여 작용하는 방안도 고려<br>- 개선 데이터 선정 시 파생 데이터의 적정성을 파악하여 검토<br>- 분석 모델에 해당 데이터가 어떤 영향을 주는지 평가 지표를 활용하여 평가                                                               |
| 기존 데이터 변경 내역 파악        | - 기존 분석 모델을 만들 때 활용한 데이터에 대한 변경 내역 현황 조사 수행<br>- 기존 데이터 현황 조사서를 참고 하며 기초적인 통계 정보에 대한 업데이트 수행<br>- 데이터 볼륨이 어느 정도 증가하였는지도 파악하여 데이터 변화 요인 파악<br>-기존 데이터 변경 내역은 값에 대한 변경 내역과 함께 업데이트 주기를 파악하는 것이 중요<br>- 신규 데이터에 대한 현황 분석을 수행하여 분석 모델의 성능 개선에 활용될 수 있도록 함 |
	나) 알고리즘 수행 및 분석 결과 기록
	- 기존 데이터 및 신규 데이터에 대한 현황 조사가 완료되면 분석 알고리즘을 수행하여 분석 모델을 리모델링 함
	- 분석 수행 절차는 분석 모델 개발 절차와 동일하게 진행됨. 다만 훈련/검증/평가로 데이터를 분할할 때 신규로 추가된 데이터가 반영될 수 있도록 해야 함

4) 분석 모델 평가 및 등록
- 빅데이터 개선 모델에 대한 개발이 완료되면 분석 알고리즘 수행 결과 검토
- 알고리즘 성능 검토에는 다양한 이해관계자가 분석 모델에 대한 결과를 리뷰하고, 검토 회의를 진행하여 최종 분석 모델을 선정함
- 개선 모델 분석 결과 평가와 최종 모델 등록 절차

| 단계       | 설명                                                                 |
| -------- | ------------------------------------------------------------------ |
| 개선 모델 평가 | - 분석 모델 평가 기준에 따라 알고리즘 성능 평가                                       |
| 분석 결과 검토 | - 해당 모델의 실질적인 활용 가능성 검토<br> 개선 목적에 맞는 분석 모델인지 검토<br>- 현업 적욕 가능성 고려 |
| 최종 모델 등록 | - 성능 평가, 분석 결과 검토에 모두 부합하면 최종 모델로 등록                               |

라. 분석 모형의 전면 리모델링
- 기존 분석 모델이 비즈니스 수익 모델에 대해 적합하지 않다고 판단될 경우 기존 모형의 전면 리모델링을 위한 독립 프로젝프를 계획할 수 있다
*접근 방식 구분*
1) 모델 개선을 위한 접근 방식
	가) 하향식 접근 방식
	
| 절차                    | 설명                                                                |
| --------------------- | ----------------------------------------------------------------- |
| 비지니스 상황 파악            | - 시장, 산업, 주요 트렌드, 거시 경제 요인에 대한 분석을 통해 비즈니스가 당연한 환경 변화 요소를 파악      |
| 주요 요구사항 파악            | - 비즈니스 가치 창출 분석을 위해 비즈니스 요구 사항을 정확히 파악하고 쥬요 분석 요구 사항 분류           |
| 경쟁요인 및 제공<br>가치 수준 설정 | - 경쟁 요소별로 제공되는 가치 수준을 시각적인 형태로 표현하여 빅데이터 분석 모델 구축의 전략 목표 및 방향성 설정 |
| 전략테마 및 실행활동 관계 분석     | - 전략적으로 접근할 테마를 정의하고. 이를 실현하기 위한 빅데이터 분석 과제 도출                    |
| 비즈니스 운영 <br>시나리오 상세화  | - 도출된 전략 케마와 실행 활동을 기반으로 비즈니스 운영 시나리오를 명세화 함                      |
| 빅데이터 분석 <br>사례 발굴     | - 비즈니스 운영 시나리오의 이론을 분석하여 선진 사례 발굴                                 |
| 빅데이터 분석 <br>사례 정의     | - 도출된 사례를 구체적으로 명세화                                               |
| 빅데이터 분석 <br>모델 평가     | - 분석 사례 기반 해당 모델이 구축되었을 때 결과를 평가함                                 |

나) 상향식 접근 방식
- 빅데이터 분석 모델 개선의 기회를 특정 업무 영역에서 주제를 정하여 발굴함
- 이 방식은 비즈니스 프로세스에 정의된 주요 프로세스를 선정하여 분석 대상으로 식별하고, 프로세스 분석을 통해 분석 기회를 발굴함

| 절차         | 설명                                                      |
| ---------- | ------------------------------------------------------- |
| 프로세스 분류    | - 메가 프로세스 > 메이저 프로세스 > 프로세스 단계로 구조화해서 정의함               |
| 프로세스 흐름 분석 | - 프로세스 별로 프로세스 맵을 통해 업무 흐름을 상세히 표현함                     |
| 분석 요건 식별   | - 각 프로세스 맵 상의 주요 의사 결정 지점 식별                            |
| 분석 요건 정의   | - 각 의사 결정 시점에 무엇을 알아야 의사 결정을 할 수 있는지, 즉 분석 요건을 정의하고 기획함 |

다) 분석 사례 벤치마킹을 통한 접근 방식
- 산업/서비스 별 분석 테마 후보 그룹을 통해 분석 기회에 대한 아이디어를 얻고, 브레인 스토밍을 통해 적용할 기회를 도출하는 방법
- 분석 사례를 벤치마킹할 때 해당 비즈니스에 적합한 사례를 조사하고 해당 사례의 장/단점을 분석하여 빅데이터 부석 모델을 개선하는 것

2) 분석 모델의 전면 리모델링 절차

| 절차       | 설명                                                                                                                                                                                                                                                                                           |
| -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 개선 요건 정의 | - 비즈니스 수익 증가나  비용 증가, 상황의 변화, 처리 속도의 지연 등을 확인하여 개선되어야 할 사항을 구체적으로 정의함<br>- 특히 사업적으로 의미가 낮거나 실행에 대한 타당성이 부족할 때 해당 요건은 제외함<br>- 전사 관점의 ROI를 고려하여 개선 요건 파악<br>- 간단한 선행 분석을 수행하여 분석 모델 개선에 대한 타당성을 가늠할 수 있으며, 본 개선에 대한 구체적 방법을 사전에 학습함으로써 분석 모델 개선의 생산성을 높일 수 있음<br>- 작업 수행 시 WBS를 성의하여 체계적으로 관리 |
| 개선 모델링   | - 상세 분석 알고리즘을 적용하여 분석 모델 개발<br>- 분석 모델링을 위한 데이터를 준비하며 필요 데이터 마트를 설계하고 테이블을 구성<br>- 비즈니스 분석 요건에 대한 구체적인 사실을 발견하기 위해 유의미한 변수를 탐색하고 목표값을 정의하며, 해당 변수에 대한 기초 현황 분석을 통해 해당 변수의 상태를 정확히 이해함<br>- 이를 기반으로 데이터마이닝, 소셜 분석, 시뮬레이션, 최적화 등의 데이터 분석 알고리즘을 수행하여 분석 모델링을 수행함                                |
| 개선 모델 적용 | - 모델 리모델링 후 운영 시스템에 적용하기 위해서는 실시간 또는 배치 스케줄러를 등록하여 주기적으로 분석 모델을 모니터링 할 수 있도록 설정<br>- 분석 모델에 입력되는 데이터가 효과적으로 입력되는지 모니터링하며, 이상 현상이 발생하면 각 이해관계자에게 통보될 수 있는 알람 기능을 구성<br>- R이나 전문 도구를 사용하여 분석 결과를 모니터링하고 외부와의 데이터 연계를 단순화하여 배치 스커줄러를 설정할 수 있음                                                   |

마. 분석 모형 리모델링 고려 사항
- 데이터마이닝, 최적화, 모델링 결과를 정기적으로 재평가하여 결과에 따라 필요시 분석 모델 재조정
- 업무 특성에 따라 차이가 있으나 일반적으로 초기에는 모형 재조정을 자주 수행하고 점진적으로 그 주기를 길게 설정함
- 관리 대상 모델이 월 20개 이상이거나 기타 업무와 함께 수행해야 하는 경우 수작업이 아는 자동화 수행을 권고함

| 기법      | 고려 사항                                                                     |
| ------- | ------------------------------------------------------------------------- |
| 데이터 마이닝 | - 최신 데이터 적용이나 변수 추가 방식으로 분석모형 재조정                                         |
| 시뮬레이션   | - 업무 프로세스 KPI의 변경 또는 주요 시스템 원칙 변경, 발생 이벤트 <br>건수 증가에 따라 성능 평가를 하고 필요시 재조정 |
| 최적화     | 조건 변화나 가중치 변화 시 계수값 조정 또는 제약 조건 추가로 재조정                                   |
